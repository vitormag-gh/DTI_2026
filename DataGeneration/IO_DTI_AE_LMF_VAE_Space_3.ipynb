{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend as K\n",
    "\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def build_encoder(latent_dim=20):\n",
    "    encoder_inputs = layers.Input(shape=(100,)) #change here features*2\n",
    "    x = layers.Dense(256, activation='relu')(encoder_inputs)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    z_mean = layers.Dense(latent_dim)(x)\n",
    "    z_log_var = layers.Dense(latent_dim)(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    encoder = models.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "    return encoder\n",
    "\n",
    "def build_decoder(latent_dim=20):\n",
    "    latent_inputs = layers.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(64, activation='relu')(latent_inputs)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    decoder_outputs = layers.Dense(100, activation='linear')(x) #change here features*2\n",
    "    decoder = models.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "    return decoder\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        # Initialize trackers for monitoring losses\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # Return list of metrics to be updated during training\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(z)\n",
    "        # Compute KL divergence loss even during inference to track loss correctly\n",
    "        kl_loss = -0.5 * tf.reduce_mean(\n",
    "            1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\n",
    "        # Only add KL loss during training\n",
    "        if training:\n",
    "            self.add_loss(kl_loss)\n",
    "        return reconstructed\n",
    "\n",
    "    def train_step(self, data):\n",
    "    # Unpack the data\n",
    "        x = data[0] if isinstance(data, tuple) else data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(x, training=True)\n",
    "            reconstruction = self.decoder(z, training=True)\n",
    "\n",
    "            # If  data is flat (e.g., shape=(batch_size, features)), adjust axis accordingly\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(x, reconstruction), axis=-1\n",
    "            )\n",
    "            reconstruction_loss = tf.reduce_sum(reconstruction_loss)  # Sum over all dimensions\n",
    "\n",
    "            kl_loss = -0.5 * tf.reduce_mean(\n",
    "                1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1\n",
    "            )\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        return {'loss': total_loss, 'reconstruction_loss': reconstruction_loss, 'kl_loss': kl_loss}\n",
    "\n",
    "# Example usage:\n",
    "latent_dim = 16  \n",
    "encoder = build_encoder(latent_dim)\n",
    "decoder = build_decoder(latent_dim)\n",
    "vae = VAE(encoder, decoder)\n",
    "#vae.compile(optimizer='adam')\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relative paths. # Set directory paths for later use.\n",
    "# Get the directory of the script file\n",
    "base_dir = os.getcwd()\n",
    "base_dir\n",
    "ligants_type=['enzyme','GPCR','ion_channel','nuclear_receptor']\n",
    "ltype=ligants_type[2]\n",
    "file_name='final_new_par_LMF_50.csv'\n",
    "file_path = os.path.join(base_dir,'data','split',ltype, file_name)\n",
    "output_path = file_path\n",
    "data_frame = pd.read_csv(file_path, header=None, skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include instances with label 1 (interactions)\n",
    "# Separate features and labels\n",
    "filtered_df = data_frame[data_frame.iloc[:, -1] == 1]  # All rows, all columns except the last one\n",
    "features_new = filtered_df.iloc[:, :-1]     # All rows, just the last column\n",
    "\n",
    "# Convert features DataFrame to a NumPy array if necessary\n",
    "x_train = features_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1476, 101)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para\n",
    "epochs=4\n",
    "batch_size=82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "18/18 [==============================] - 1s 2ms/step - loss: -0.2429 - reconstruction_loss: -0.5274 - kl_loss: 0.0703\n",
      "Epoch 2/4\n",
      "18/18 [==============================] - 0s 2ms/step - loss: -0.7958 - reconstruction_loss: -0.6718 - kl_loss: 0.0341\n",
      "Epoch 3/4\n",
      "18/18 [==============================] - 0s 1ms/step - loss: -0.8894 - reconstruction_loss: -0.8672 - kl_loss: 0.0357\n",
      "Epoch 4/4\n",
      "18/18 [==============================] - 0s 1ms/step - loss: -0.9974 - reconstruction_loss: -1.2075 - kl_loss: 0.0455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f29f6a9d50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "vae.fit(x_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include instances with label 1 (interactions)\n",
    "filtered_df = data_frame[data_frame.iloc[:, -1] == 1]\n",
    "\n",
    "# Separate features\n",
    "features_new = filtered_df.iloc[:, :-1]  # Assuming the last column is the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = features_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 704us/step\n"
     ]
    }
   ],
   "source": [
    "z_mean, z_log_var, z = vae.encoder.predict(x_new)\n",
    "# Now, z contains the latent representations of  filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 717us/step\n"
     ]
    }
   ],
   "source": [
    "reconstructed_new = vae.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6   \\\n",
      "0     0.436501  0.250856  0.356307 -0.226115 -0.308184 -0.403182  0.140159   \n",
      "1     0.436501  0.250856  0.356307 -0.226115 -0.308184 -0.403182  0.140159   \n",
      "2     0.514852  0.162007  0.227619 -0.040816 -0.410620 -0.276363  0.228057   \n",
      "3     0.676194  0.008535  0.514052  0.701031 -0.009285 -0.074659  0.460639   \n",
      "4     0.676194  0.008535  0.514052  0.701031 -0.009285 -0.074659  0.460639   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1471  0.288869  0.503765  0.441279 -0.534502 -0.192024 -0.500892  0.039972   \n",
      "1472  0.288869  0.503765  0.441279 -0.534502 -0.192024 -0.500892  0.039972   \n",
      "1473  0.288869  0.503765  0.441279 -0.534502 -0.192024 -0.500892  0.039972   \n",
      "1474  0.434229  0.250592  0.354392 -0.229408 -0.308570 -0.406938  0.132189   \n",
      "1475  0.434229  0.250592  0.354392 -0.229408 -0.308570 -0.406938  0.132189   \n",
      "\n",
      "            7         8         9   ...        90        91        92  \\\n",
      "0     0.360367 -0.081909  0.415986  ... -1.166565  1.258800  0.708176   \n",
      "1     0.360367 -0.081909  0.415986  ... -0.344612  1.148299  0.557485   \n",
      "2     0.298155 -0.182172  0.346475  ... -0.344612  1.148299  0.557485   \n",
      "3     0.421309 -0.127276  0.121375  ...  0.805820  0.582419  0.291529   \n",
      "4     0.421309 -0.127276  0.121375  ...  0.790192  0.840845  0.071496   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1471  0.434224  0.127463  0.622538  ...  0.075344  0.541613  0.358180   \n",
      "1472  0.434224  0.127463  0.622538  ...  0.385995  0.077377  0.551626   \n",
      "1473  0.434224  0.127463  0.622538  ... -0.344612  1.148299  0.557485   \n",
      "1474  0.365334 -0.080880  0.413553  ... -1.166565  1.258800  0.708176   \n",
      "1475  0.365334 -0.080880  0.413553  ... -0.344612  1.148299  0.557485   \n",
      "\n",
      "            93        94        95        96        97        98        99  \n",
      "0    -1.071881 -0.645687 -2.077623 -0.483994 -0.237565 -0.744694  0.126791  \n",
      "1    -0.383505  0.112881 -0.142585  0.621746  0.783535  0.107520  1.392855  \n",
      "2    -0.383505  0.112881 -0.142585  0.621746  0.783535  0.107520  1.392855  \n",
      "3     0.306652  0.610322  1.117330  0.966446  0.760531  0.569553  0.768026  \n",
      "4     0.153391  0.591395  1.262455  0.651125  0.374226  0.397660  0.144997  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "1471 -0.205228  0.076331 -0.044422  0.109991  0.003790  0.067739 -0.179894  \n",
      "1472  0.261409  0.103007 -0.772997  0.032977  0.145172  0.388435 -0.292114  \n",
      "1473 -0.383505  0.112881 -0.142585  0.621746  0.783535  0.107520  1.392855  \n",
      "1474 -1.071881 -0.645687 -2.077623 -0.483994 -0.237565 -0.744694  0.126791  \n",
      "1475 -0.383505  0.112881 -0.142585  0.621746  0.783535  0.107520  1.392855  \n",
      "\n",
      "[1476 rows x 100 columns]\n",
      "            0         1         2         3         4         5         6   \\\n",
      "0     0.260056  0.032919  0.220767 -0.174872 -0.577334 -0.354179 -0.159857   \n",
      "1     0.311456  0.311386  0.049271 -0.164750 -0.285451 -0.241821  0.082974   \n",
      "2     0.427149  0.202444  0.270143 -0.160114 -0.400416 -0.312203  0.115293   \n",
      "3     0.225288  0.507207  0.354201 -0.446345 -0.689936 -0.443923  0.243075   \n",
      "4     0.154052  0.104310  0.162548 -0.200826 -0.381189 -0.248847 -0.006547   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1471  0.208486  0.333081  0.298599 -0.249837 -0.429221 -0.415114  0.370281   \n",
      "1472  0.227795  0.065290 -0.052575 -0.164822 -0.552701 -0.675598  0.128948   \n",
      "1473  0.254661  0.156680  0.131697 -0.481790 -0.809304 -0.747788  0.454176   \n",
      "1474  0.233225  0.705873  0.318373 -0.518587 -0.745387 -0.939084  0.649157   \n",
      "1475  0.328624 -0.122379  0.262246 -0.400238 -0.587388 -0.345697  0.399097   \n",
      "\n",
      "            7         8         9   ...        90        91        92  \\\n",
      "0     0.201504 -0.423579  0.167946  ...  0.249287  0.409579  0.304660   \n",
      "1     0.096748 -0.195403  0.212971  ...  0.287987  0.132413  0.180624   \n",
      "2     0.239834 -0.248102  0.285630  ...  0.291085  0.345915  0.262240   \n",
      "3     0.383184 -0.207545  0.416541  ...  0.614213  0.556569  0.396708   \n",
      "4     0.273231 -0.205433  0.420272  ...  0.211985  0.390809  0.268016   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1471  0.323128 -0.485751  0.131724  ...  0.426351  0.411923  0.275141   \n",
      "1472  0.186835 -0.512928  0.127662  ...  0.400959  0.273761  0.198175   \n",
      "1473  0.363449 -0.772681  0.495699  ...  0.509275  0.558826  0.271513   \n",
      "1474  0.549662 -0.488971  0.563656  ...  0.319377  0.554915  0.513235   \n",
      "1475  0.415805 -0.488959  0.702254  ...  0.259249  0.605214  0.430495   \n",
      "\n",
      "            93        94        95        96        97        98        99  \n",
      "0    -0.380151  0.254628 -0.025620  0.241035 -0.070010  0.184192 -0.253948  \n",
      "1    -0.363533  0.485360 -0.006014  0.362899 -0.450375  0.379954 -0.354699  \n",
      "2    -0.496873  0.515612  0.150788  0.461286 -0.558918  0.271647 -0.495145  \n",
      "3    -0.447489  0.471658  0.326434  0.459856 -0.604582  0.372173 -0.632871  \n",
      "4    -0.438787  0.271697  0.020856  0.088107 -0.291656  0.181058 -0.222247  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "1471 -0.402882  0.163461  0.006107  0.114210 -0.280228  0.357098 -0.624288  \n",
      "1472 -0.198600  0.185402  0.151927  0.090587 -0.342587  0.010384 -0.355880  \n",
      "1473 -0.576639  0.169702  0.049440  0.155627 -0.098316  0.339095 -0.517034  \n",
      "1474 -0.486867 -0.066497  0.018314  0.023944 -0.503984  0.532659 -0.829791  \n",
      "1475 -0.573521  0.381191  0.219658  0.395010  0.018234  0.217668 -0.367315  \n",
      "\n",
      "[1476 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the reconstructed data to a DataFrame\n",
    "reconstructed_df = pd.DataFrame(reconstructed_new)\n",
    "\n",
    "# Display the first few rows of the reconstructed DataFrame\n",
    "print(pd.DataFrame(x_new))\n",
    "print(reconstructed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0  0.260056  0.032919  0.220767 -0.174872 -0.577334 -0.354179 -0.159857   \n",
      "1  0.311456  0.311386  0.049271 -0.164750 -0.285451 -0.241821  0.082974   \n",
      "2  0.427149  0.202444  0.270143 -0.160114 -0.400416 -0.312203  0.115293   \n",
      "3  0.225288  0.507207  0.354201 -0.446345 -0.689936 -0.443923  0.243075   \n",
      "4  0.154052  0.104310  0.162548 -0.200826 -0.381189 -0.248847 -0.006547   \n",
      "\n",
      "        7         8         9    ...       91        92        93        94   \\\n",
      "0  0.201504 -0.423579  0.167946  ...  0.409579  0.304660 -0.380151  0.254628   \n",
      "1  0.096748 -0.195403  0.212971  ...  0.132413  0.180624 -0.363533  0.485360   \n",
      "2  0.239834 -0.248102  0.285630  ...  0.345915  0.262240 -0.496873  0.515612   \n",
      "3  0.383184 -0.207545  0.416541  ...  0.556569  0.396708 -0.447489  0.471658   \n",
      "4  0.273231 -0.205433  0.420272  ...  0.390809  0.268016 -0.438787  0.271697   \n",
      "\n",
      "        95        96        97        98        99   100  \n",
      "0 -0.025620  0.241035 -0.070010  0.184192 -0.253948    1  \n",
      "1 -0.006014  0.362899 -0.450375  0.379954 -0.354699    1  \n",
      "2  0.150788  0.461286 -0.558918  0.271647 -0.495145    1  \n",
      "3  0.326434  0.459856 -0.604582  0.372173 -0.632871    1  \n",
      "4  0.020856  0.088107 -0.291656  0.181058 -0.222247    1  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "# Add a new column 'Label' with all values set to 1\n",
    "reconstructed_df[100] = 1\n",
    "\n",
    "# Display the first few rows to verify the new column\n",
    "print(reconstructed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1247/1247 [==============================] - 1s 607us/step\n"
     ]
    }
   ],
   "source": [
    "num_samples_to_generate = 39888  # The number of new rows want to generate\n",
    "\n",
    "# Generate random samples from the latent space\n",
    "latent_dim = 16  # Ensure this matches the latent dimension size of  VAE\n",
    "z_new_samples = np.random.normal(size=(num_samples_to_generate, latent_dim))\n",
    "\n",
    "# Use the decoder to generate new data\n",
    "new_data_generated = vae.decoder.predict(z_new_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16624707,  0.29759887,  0.53056234, ..., -0.49889925,\n",
       "         0.2630684 , -0.64932287],\n",
       "       [ 0.20755067,  0.13869058,  0.25071073, ..., -0.04014296,\n",
       "         0.24108227, -0.3225715 ],\n",
       "       [ 0.2546986 ,  0.29284146,  0.14377859, ..., -0.09342064,\n",
       "         0.10958147, -0.33785632],\n",
       "       ...,\n",
       "       [ 0.27393532,  0.4019966 ,  0.3602587 , ..., -0.43873608,\n",
       "         0.42941418, -0.77376765],\n",
       "       [ 0.29083395,  0.3167049 , -0.25092044, ..., -0.3186695 ,\n",
       "         0.14984392, -0.18940362],\n",
       "       [ 0.30585042,  0.36540723,  0.42428488, ..., -0.567862  ,\n",
       "         0.4792341 , -0.8947423 ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the generated data to a DataFrame\n",
    "new_data_df = pd.DataFrame(new_data_generated)\n",
    "\n",
    "# Add a column 'Label' with all values set to 1\n",
    "new_data_df[100] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_df = pd.concat([data_frame, new_data_df], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.436501</td>\n",
       "      <td>0.250856</td>\n",
       "      <td>0.356307</td>\n",
       "      <td>-0.226115</td>\n",
       "      <td>-0.308184</td>\n",
       "      <td>-0.403182</td>\n",
       "      <td>0.140159</td>\n",
       "      <td>0.360367</td>\n",
       "      <td>-0.081909</td>\n",
       "      <td>0.415986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335263</td>\n",
       "      <td>0.225140</td>\n",
       "      <td>-0.156722</td>\n",
       "      <td>0.190285</td>\n",
       "      <td>0.008524</td>\n",
       "      <td>0.009117</td>\n",
       "      <td>-0.155599</td>\n",
       "      <td>0.202474</td>\n",
       "      <td>-0.597380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.436501</td>\n",
       "      <td>0.250856</td>\n",
       "      <td>0.356307</td>\n",
       "      <td>-0.226115</td>\n",
       "      <td>-0.308184</td>\n",
       "      <td>-0.403182</td>\n",
       "      <td>0.140159</td>\n",
       "      <td>0.360367</td>\n",
       "      <td>-0.081909</td>\n",
       "      <td>0.415986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168198</td>\n",
       "      <td>0.166573</td>\n",
       "      <td>0.020867</td>\n",
       "      <td>0.135056</td>\n",
       "      <td>0.069828</td>\n",
       "      <td>0.127377</td>\n",
       "      <td>-0.028108</td>\n",
       "      <td>0.284480</td>\n",
       "      <td>-0.377469</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.436501</td>\n",
       "      <td>0.250856</td>\n",
       "      <td>0.356307</td>\n",
       "      <td>-0.226115</td>\n",
       "      <td>-0.308184</td>\n",
       "      <td>-0.403182</td>\n",
       "      <td>0.140159</td>\n",
       "      <td>0.360367</td>\n",
       "      <td>-0.081909</td>\n",
       "      <td>0.415986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087902</td>\n",
       "      <td>-0.010726</td>\n",
       "      <td>-0.042239</td>\n",
       "      <td>0.053999</td>\n",
       "      <td>0.127199</td>\n",
       "      <td>0.019528</td>\n",
       "      <td>-0.133650</td>\n",
       "      <td>0.263689</td>\n",
       "      <td>-0.532280</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.436501</td>\n",
       "      <td>0.250856</td>\n",
       "      <td>0.356307</td>\n",
       "      <td>-0.226115</td>\n",
       "      <td>-0.308184</td>\n",
       "      <td>-0.403182</td>\n",
       "      <td>0.140159</td>\n",
       "      <td>0.360367</td>\n",
       "      <td>-0.081909</td>\n",
       "      <td>0.415986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419669</td>\n",
       "      <td>0.350892</td>\n",
       "      <td>-0.941822</td>\n",
       "      <td>0.227727</td>\n",
       "      <td>-0.656873</td>\n",
       "      <td>-0.281764</td>\n",
       "      <td>-0.346049</td>\n",
       "      <td>0.647751</td>\n",
       "      <td>-1.395413</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.436501</td>\n",
       "      <td>0.250856</td>\n",
       "      <td>0.356307</td>\n",
       "      <td>-0.226115</td>\n",
       "      <td>-0.308184</td>\n",
       "      <td>-0.403182</td>\n",
       "      <td>0.140159</td>\n",
       "      <td>0.360367</td>\n",
       "      <td>-0.081909</td>\n",
       "      <td>0.415986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623031</td>\n",
       "      <td>0.373050</td>\n",
       "      <td>-0.321666</td>\n",
       "      <td>0.190634</td>\n",
       "      <td>-0.144257</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>-0.188413</td>\n",
       "      <td>0.209063</td>\n",
       "      <td>-0.761995</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82723</th>\n",
       "      <td>0.214274</td>\n",
       "      <td>0.253449</td>\n",
       "      <td>0.056102</td>\n",
       "      <td>-0.412751</td>\n",
       "      <td>-0.546540</td>\n",
       "      <td>-0.769365</td>\n",
       "      <td>0.444553</td>\n",
       "      <td>0.379777</td>\n",
       "      <td>-0.349331</td>\n",
       "      <td>0.259023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448116</td>\n",
       "      <td>0.394092</td>\n",
       "      <td>-0.273721</td>\n",
       "      <td>0.142124</td>\n",
       "      <td>-0.144411</td>\n",
       "      <td>-0.000833</td>\n",
       "      <td>-0.397974</td>\n",
       "      <td>0.332621</td>\n",
       "      <td>-0.672570</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82724</th>\n",
       "      <td>0.103813</td>\n",
       "      <td>0.272143</td>\n",
       "      <td>0.062918</td>\n",
       "      <td>-0.098133</td>\n",
       "      <td>-0.253508</td>\n",
       "      <td>-0.419124</td>\n",
       "      <td>0.084841</td>\n",
       "      <td>0.123391</td>\n",
       "      <td>-0.405554</td>\n",
       "      <td>0.260061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414758</td>\n",
       "      <td>0.189580</td>\n",
       "      <td>-0.471439</td>\n",
       "      <td>0.007842</td>\n",
       "      <td>0.297609</td>\n",
       "      <td>-0.014151</td>\n",
       "      <td>-0.307918</td>\n",
       "      <td>0.186485</td>\n",
       "      <td>-0.439076</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82725</th>\n",
       "      <td>0.273935</td>\n",
       "      <td>0.401997</td>\n",
       "      <td>0.360259</td>\n",
       "      <td>-0.291193</td>\n",
       "      <td>-0.478230</td>\n",
       "      <td>-0.555575</td>\n",
       "      <td>0.347580</td>\n",
       "      <td>0.509088</td>\n",
       "      <td>-0.487198</td>\n",
       "      <td>0.324044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662839</td>\n",
       "      <td>0.347305</td>\n",
       "      <td>-0.633611</td>\n",
       "      <td>0.138337</td>\n",
       "      <td>0.228748</td>\n",
       "      <td>0.017370</td>\n",
       "      <td>-0.438736</td>\n",
       "      <td>0.429414</td>\n",
       "      <td>-0.773768</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82726</th>\n",
       "      <td>0.290834</td>\n",
       "      <td>0.316705</td>\n",
       "      <td>-0.250920</td>\n",
       "      <td>-0.361791</td>\n",
       "      <td>-0.598988</td>\n",
       "      <td>-0.352805</td>\n",
       "      <td>-0.114390</td>\n",
       "      <td>0.197087</td>\n",
       "      <td>-0.033816</td>\n",
       "      <td>0.607952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438913</td>\n",
       "      <td>0.329630</td>\n",
       "      <td>-0.676932</td>\n",
       "      <td>0.292915</td>\n",
       "      <td>-0.130853</td>\n",
       "      <td>0.281016</td>\n",
       "      <td>-0.318669</td>\n",
       "      <td>0.149844</td>\n",
       "      <td>-0.189404</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82727</th>\n",
       "      <td>0.305850</td>\n",
       "      <td>0.365407</td>\n",
       "      <td>0.424285</td>\n",
       "      <td>-0.339501</td>\n",
       "      <td>-0.736716</td>\n",
       "      <td>-0.525396</td>\n",
       "      <td>0.640738</td>\n",
       "      <td>0.707424</td>\n",
       "      <td>-0.418128</td>\n",
       "      <td>0.507497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519454</td>\n",
       "      <td>0.385876</td>\n",
       "      <td>-0.537287</td>\n",
       "      <td>0.221076</td>\n",
       "      <td>0.076945</td>\n",
       "      <td>0.252530</td>\n",
       "      <td>-0.567862</td>\n",
       "      <td>0.479234</td>\n",
       "      <td>-0.894742</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82728 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "0      0.436501  0.250856  0.356307 -0.226115 -0.308184 -0.403182  0.140159   \n",
       "1      0.436501  0.250856  0.356307 -0.226115 -0.308184 -0.403182  0.140159   \n",
       "2      0.436501  0.250856  0.356307 -0.226115 -0.308184 -0.403182  0.140159   \n",
       "3      0.436501  0.250856  0.356307 -0.226115 -0.308184 -0.403182  0.140159   \n",
       "4      0.436501  0.250856  0.356307 -0.226115 -0.308184 -0.403182  0.140159   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "82723  0.214274  0.253449  0.056102 -0.412751 -0.546540 -0.769365  0.444553   \n",
       "82724  0.103813  0.272143  0.062918 -0.098133 -0.253508 -0.419124  0.084841   \n",
       "82725  0.273935  0.401997  0.360259 -0.291193 -0.478230 -0.555575  0.347580   \n",
       "82726  0.290834  0.316705 -0.250920 -0.361791 -0.598988 -0.352805 -0.114390   \n",
       "82727  0.305850  0.365407  0.424285 -0.339501 -0.736716 -0.525396  0.640738   \n",
       "\n",
       "            7         8         9    ...       91        92        93   \\\n",
       "0      0.360367 -0.081909  0.415986  ...  0.335263  0.225140 -0.156722   \n",
       "1      0.360367 -0.081909  0.415986  ...  0.168198  0.166573  0.020867   \n",
       "2      0.360367 -0.081909  0.415986  ...  0.087902 -0.010726 -0.042239   \n",
       "3      0.360367 -0.081909  0.415986  ...  0.419669  0.350892 -0.941822   \n",
       "4      0.360367 -0.081909  0.415986  ...  0.623031  0.373050 -0.321666   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "82723  0.379777 -0.349331  0.259023  ...  0.448116  0.394092 -0.273721   \n",
       "82724  0.123391 -0.405554  0.260061  ...  0.414758  0.189580 -0.471439   \n",
       "82725  0.509088 -0.487198  0.324044  ...  0.662839  0.347305 -0.633611   \n",
       "82726  0.197087 -0.033816  0.607952  ...  0.438913  0.329630 -0.676932   \n",
       "82727  0.707424 -0.418128  0.507497  ...  0.519454  0.385876 -0.537287   \n",
       "\n",
       "            94        95        96        97        98        99   100  \n",
       "0      0.190285  0.008524  0.009117 -0.155599  0.202474 -0.597380  0.0  \n",
       "1      0.135056  0.069828  0.127377 -0.028108  0.284480 -0.377469  0.0  \n",
       "2      0.053999  0.127199  0.019528 -0.133650  0.263689 -0.532280  0.0  \n",
       "3      0.227727 -0.656873 -0.281764 -0.346049  0.647751 -1.395413  0.0  \n",
       "4      0.190634 -0.144257  0.005621 -0.188413  0.209063 -0.761995  0.0  \n",
       "...         ...       ...       ...       ...       ...       ...  ...  \n",
       "82723  0.142124 -0.144411 -0.000833 -0.397974  0.332621 -0.672570  1.0  \n",
       "82724  0.007842  0.297609 -0.014151 -0.307918  0.186485 -0.439076  1.0  \n",
       "82725  0.138337  0.228748  0.017370 -0.438736  0.429414 -0.773768  1.0  \n",
       "82726  0.292915 -0.130853  0.281016 -0.318669  0.149844 -0.189404  1.0  \n",
       "82727  0.221076  0.076945  0.252530 -0.567862  0.479234 -0.894742  1.0  \n",
       "\n",
       "[82728 rows x 101 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='enhanced_VAE_final_new_par_50_LMF_space_3.csv'\n",
    "file_path = os.path.join(base_dir,'data','split',ltype, file_name)\n",
    "output_path = file_path\n",
    "enhanced_df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
