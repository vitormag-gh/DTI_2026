{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend as K\n",
    "\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def build_encoder(latent_dim=20):\n",
    "    encoder_inputs = layers.Input(shape=(100,)) #change here features*2\n",
    "    x = layers.Dense(256, activation='relu')(encoder_inputs)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    z_mean = layers.Dense(latent_dim)(x)\n",
    "    z_log_var = layers.Dense(latent_dim)(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    encoder = models.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "    return encoder\n",
    "\n",
    "def build_decoder(latent_dim=20):\n",
    "    latent_inputs = layers.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(64, activation='relu')(latent_inputs)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    decoder_outputs = layers.Dense(100, activation='linear')(x) #change here features*2\n",
    "    decoder = models.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "    return decoder\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        # Initialize trackers for monitoring losses\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # Return list of metrics to be updated during training\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(z)\n",
    "        # Compute KL divergence loss even during inference to track loss correctly\n",
    "        kl_loss = -0.5 * tf.reduce_mean(\n",
    "            1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\n",
    "        # Only add KL loss during training\n",
    "        if training:\n",
    "            self.add_loss(kl_loss)\n",
    "        return reconstructed\n",
    "\n",
    "    def train_step(self, data):\n",
    "    # Unpack the data\n",
    "        x = data[0] if isinstance(data, tuple) else data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(x, training=True)\n",
    "            reconstruction = self.decoder(z, training=True)\n",
    "\n",
    "            # If  data is flat (e.g., shape=(batch_size, features)), adjust axis accordingly\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(x, reconstruction), axis=-1\n",
    "            )\n",
    "            reconstruction_loss = tf.reduce_sum(reconstruction_loss)  # Sum over all dimensions\n",
    "\n",
    "            kl_loss = -0.5 * tf.reduce_mean(\n",
    "                1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1\n",
    "            )\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        return {'loss': total_loss, 'reconstruction_loss': reconstruction_loss, 'kl_loss': kl_loss}\n",
    "\n",
    "# Example usage:\n",
    "latent_dim = 16  \n",
    "encoder = build_encoder(latent_dim)\n",
    "decoder = build_decoder(latent_dim)\n",
    "vae = VAE(encoder, decoder)\n",
    "#vae.compile(optimizer='adam')\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relative paths. # Set directory paths for later use.\n",
    "# Get the directory of the script file\n",
    "base_dir = os.getcwd()\n",
    "base_dir\n",
    "ligants_type=['enzyme','GPCR','ion_channel','nuclear_receptor']\n",
    "ltype=ligants_type[3]\n",
    "file_name='final_new_par_NNMF_50.csv'\n",
    "file_path = os.path.join(base_dir,'data','split',ltype, file_name)\n",
    "output_path = file_path\n",
    "data_frame = pd.read_csv(file_path, header=None, skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include instances with label 1 (interactions)\n",
    "# Separate features and labels\n",
    "filtered_df = data_frame[data_frame.iloc[:, -1] == 1]  # All rows, all columns except the last one\n",
    "features_new = filtered_df.iloc[:, :-1]     # All rows, just the last column\n",
    "\n",
    "# Convert features DataFrame to a NumPy array if necessary\n",
    "x_train = features_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 101)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para\n",
    "epochs=4\n",
    "batch_size=45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 0.7594 - reconstruction_loss: 0.6376 - kl_loss: 0.0463\n",
      "Epoch 2/4\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6705 - reconstruction_loss: 0.6214 - kl_loss: 0.0342\n",
      "Epoch 3/4\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6184 - reconstruction_loss: 0.5853 - kl_loss: 0.0240\n",
      "Epoch 4/4\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5794 - reconstruction_loss: 0.5546 - kl_loss: 0.0194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x19f21af5c90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "vae.fit(x_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include instances with label 1 (interactions)\n",
    "filtered_df = data_frame[data_frame.iloc[:, -1] == 1]\n",
    "\n",
    "# Separate features\n",
    "features_new = filtered_df.iloc[:, :-1]  # Assuming the last column is the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = features_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "z_mean, z_log_var, z = vae.encoder.predict(x_new)\n",
    "# Now, z contains the latent representations of  filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "reconstructed_new = vae.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0              1    2    3    4         5    6         7    8   \\\n",
      "0   0.000000  9.784057e-199  0.0  0.0  0.0  0.000000  0.0  0.000000  0.0   \n",
      "1   3.398607   0.000000e+00  0.0  0.0  0.0  0.813774  0.0  0.151195  0.0   \n",
      "2   3.398607   0.000000e+00  0.0  0.0  0.0  0.813774  0.0  0.151195  0.0   \n",
      "3   3.398607   0.000000e+00  0.0  0.0  0.0  0.813774  0.0  0.151195  0.0   \n",
      "4   3.398607   0.000000e+00  0.0  0.0  0.0  0.813774  0.0  0.151195  0.0   \n",
      "..       ...            ...  ...  ...  ...       ...  ...       ...  ...   \n",
      "85  0.000000   0.000000e+00  0.0  0.0  0.0  0.000000  0.0  0.000000  0.0   \n",
      "86  0.000000   0.000000e+00  0.0  0.0  0.0  0.000000  0.0  0.000000  0.0   \n",
      "87  0.000000   0.000000e+00  0.0  0.0  0.0  0.000000  0.0  0.000000  0.0   \n",
      "88  0.000000   0.000000e+00  0.0  0.0  0.0  0.000000  0.0  0.000000  0.0   \n",
      "89  0.000000   0.000000e+00  0.0  0.0  0.0  0.000000  0.0  0.000000  0.0   \n",
      "\n",
      "          9   ...        90        91   92   93        94        95       96  \\\n",
      "0   0.000000  ...  0.000000  0.000000  0.0  0.0  1.242233  0.000000  0.00000   \n",
      "1   0.283983  ...  0.024123  1.101491  0.0  0.0  0.000000  0.000000  0.00000   \n",
      "2   0.283983  ...  0.026389  1.507284  0.0  0.0  0.000000  0.000000  0.00000   \n",
      "3   0.283983  ...  0.008970  0.010527  0.0  0.0  0.000000  0.000000  0.00000   \n",
      "4   0.283983  ...  0.039132  1.823961  0.0  0.0  0.000000  0.000000  0.00000   \n",
      "..       ...  ...       ...       ...  ...  ...       ...       ...      ...   \n",
      "85  0.000000  ...  0.000000  0.000000  0.0  0.0  0.000000  0.000000  0.00000   \n",
      "86  0.000000  ...  0.000000  0.000000  0.0  0.0  0.000000  0.000000  0.00000   \n",
      "87  0.000000  ...  0.000000  0.000000  0.0  0.0  0.000000  0.000000  0.00000   \n",
      "88  0.000000  ...  0.000000  0.000000  0.0  0.0  0.000000  0.841828  0.76477   \n",
      "89  0.000000  ...  0.000000  0.000000  0.0  0.0  0.000000  0.000000  0.00000   \n",
      "\n",
      "     97   98        99  \n",
      "0   0.0  0.0  0.000000  \n",
      "1   0.0  0.0  0.000000  \n",
      "2   0.0  0.0  0.000000  \n",
      "3   0.0  0.0  0.000000  \n",
      "4   0.0  0.0  0.000000  \n",
      "..  ...  ...       ...  \n",
      "85  0.0  0.0  0.891298  \n",
      "86  0.0  0.0  0.489487  \n",
      "87  0.0  0.0  0.318034  \n",
      "88  0.0  0.0  0.000000  \n",
      "89  0.0  0.0  0.000000  \n",
      "\n",
      "[90 rows x 100 columns]\n",
      "          0         1         2         3         4         5         6   \\\n",
      "0   0.728337  0.252341 -0.430401 -0.380237  0.064754  0.231725 -0.028846   \n",
      "1   0.863965  0.368665 -0.806697 -0.330807 -0.635908  0.486659 -0.092815   \n",
      "2   0.521806  0.147533 -0.132201 -0.377503 -0.094450 -0.053056 -0.299110   \n",
      "3   0.572990  0.196850 -0.048263 -0.365108 -0.066044  0.106884 -0.169686   \n",
      "4   0.226792  0.262180 -0.223541 -0.202549 -0.266578 -0.036398 -0.175415   \n",
      "..       ...       ...       ...       ...       ...       ...       ...   \n",
      "85  0.670104  0.386755 -0.199149 -0.340998 -0.481804 -0.038745 -0.367839   \n",
      "86  0.323628  0.068335 -0.120422  0.142601 -0.406547  0.036962 -0.146981   \n",
      "87  0.624861  0.336610 -0.121689 -0.138374 -0.182812 -0.127349 -0.333992   \n",
      "88  0.610731  0.477789 -0.431775 -0.185563 -0.139464  0.249424 -0.099545   \n",
      "89  0.464960  0.214128 -0.166141 -0.024450 -0.187457 -0.145949 -0.365257   \n",
      "\n",
      "          7         8         9   ...        90        91        92        93  \\\n",
      "0  -0.223664 -0.035591 -0.253857  ... -0.806790  0.475697 -0.108435 -0.152430   \n",
      "1  -0.029383 -0.048135  0.017781  ... -0.750447  0.478629 -0.602392 -0.909419   \n",
      "2  -0.021320 -0.360872 -0.188976  ... -0.459744  0.085065 -0.124812 -0.111010   \n",
      "3  -0.153908 -0.310950 -0.032121  ... -0.345234  0.181952 -0.070727 -0.432513   \n",
      "4   0.061892 -0.033599  0.156231  ... -0.345071  0.311008 -0.421860 -0.462680   \n",
      "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
      "85 -0.164039 -0.516298  0.449517  ... -0.223954  0.039344 -0.623105 -0.449362   \n",
      "86  0.095846  0.216232  0.214131  ... -0.047942  0.254894 -0.505077 -0.484406   \n",
      "87 -0.381304 -0.556930  0.101078  ... -0.174528  0.211804 -0.576759 -0.204850   \n",
      "88 -0.097958 -0.102262  0.175210  ... -0.453902  0.463165 -0.113178 -0.336635   \n",
      "89 -0.252614 -0.159906  0.055058  ... -0.396294  0.460503 -0.444854 -0.268499   \n",
      "\n",
      "          94        95        96        97        98        99  \n",
      "0   0.062531 -0.201325 -0.320260 -0.021544  0.139969 -0.244578  \n",
      "1   0.089618 -0.205372 -0.265990  0.326417 -0.237688 -0.016340  \n",
      "2   0.068472 -0.143251 -0.291601 -0.169445  0.139357 -0.303712  \n",
      "3  -0.197764  0.003385 -0.269592 -0.115050  0.135114 -0.009442  \n",
      "4  -0.137760 -0.098083 -0.260434  0.088727  0.156863  0.083794  \n",
      "..       ...       ...       ...       ...       ...       ...  \n",
      "85 -0.182707 -0.048155 -0.337716 -0.230353  0.237506 -0.216436  \n",
      "86 -0.085915 -0.025196 -0.296835  0.118099 -0.026873  0.097919  \n",
      "87 -0.261220 -0.032452 -0.342690 -0.397846  0.304216 -0.228570  \n",
      "88  0.054592 -0.227880 -0.279316  0.159016 -0.287141 -0.338010  \n",
      "89 -0.099162 -0.084739 -0.239952 -0.214223  0.317655 -0.198571  \n",
      "\n",
      "[90 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the reconstructed data to a DataFrame\n",
    "reconstructed_df = pd.DataFrame(reconstructed_new)\n",
    "\n",
    "# Display the first few rows of the reconstructed DataFrame\n",
    "print(pd.DataFrame(x_new))\n",
    "print(reconstructed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0  0.728337  0.252341 -0.430401 -0.380237  0.064754  0.231725 -0.028846   \n",
      "1  0.863965  0.368665 -0.806697 -0.330807 -0.635908  0.486659 -0.092815   \n",
      "2  0.521806  0.147533 -0.132201 -0.377503 -0.094450 -0.053056 -0.299110   \n",
      "3  0.572990  0.196850 -0.048263 -0.365108 -0.066044  0.106884 -0.169686   \n",
      "4  0.226792  0.262180 -0.223541 -0.202549 -0.266578 -0.036398 -0.175415   \n",
      "\n",
      "        7         8         9    ...       91        92        93        94   \\\n",
      "0 -0.223664 -0.035591 -0.253857  ...  0.475697 -0.108435 -0.152430  0.062531   \n",
      "1 -0.029383 -0.048135  0.017781  ...  0.478629 -0.602392 -0.909419  0.089618   \n",
      "2 -0.021320 -0.360872 -0.188976  ...  0.085065 -0.124812 -0.111010  0.068472   \n",
      "3 -0.153908 -0.310950 -0.032121  ...  0.181952 -0.070727 -0.432513 -0.197764   \n",
      "4  0.061892 -0.033599  0.156231  ...  0.311008 -0.421860 -0.462680 -0.137760   \n",
      "\n",
      "        95        96        97        98        99   100  \n",
      "0 -0.201325 -0.320260 -0.021544  0.139969 -0.244578    1  \n",
      "1 -0.205372 -0.265990  0.326417 -0.237688 -0.016340    1  \n",
      "2 -0.143251 -0.291601 -0.169445  0.139357 -0.303712    1  \n",
      "3  0.003385 -0.269592 -0.115050  0.135114 -0.009442    1  \n",
      "4 -0.098083 -0.260434  0.088727  0.156863  0.083794    1  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "# Add a new column 'Label' with all values set to 1\n",
    "reconstructed_df[100] = 1\n",
    "\n",
    "# Display the first few rows to verify the new column\n",
    "print(reconstructed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 743us/step\n"
     ]
    }
   ],
   "source": [
    "num_samples_to_generate = 1224  # The number of new rows want to generate\n",
    "\n",
    "# Generate random samples from the latent space\n",
    "latent_dim = 16  # Ensure this matches the latent dimension size of  VAE\n",
    "z_new_samples = np.random.normal(size=(num_samples_to_generate, latent_dim))\n",
    "\n",
    "# Use the decoder to generate new data\n",
    "new_data_generated = vae.decoder.predict(z_new_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28658432,  0.2997013 , -0.17601691, ..., -0.10716633,\n",
       "         0.11184111,  0.22770865],\n",
       "       [ 0.35273823,  0.29303792, -0.09646215, ..., -0.06499067,\n",
       "         0.11163116, -0.02385332],\n",
       "       [ 0.56578934, -0.06928885, -0.4651704 , ...,  0.31439084,\n",
       "        -0.1797366 , -0.2143017 ],\n",
       "       ...,\n",
       "       [ 0.38110012,  0.3035871 , -0.49261037, ..., -0.03274395,\n",
       "        -0.21214347,  0.1518813 ],\n",
       "       [ 0.41897762,  0.10663438, -0.17796825, ...,  0.23006982,\n",
       "         0.12182347,  0.16352013],\n",
       "       [ 0.60858274,  0.33629084, -0.37386525, ...,  0.08513309,\n",
       "         0.0609857 , -0.14942801]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the generated data to a DataFrame\n",
    "new_data_df = pd.DataFrame(new_data_generated)\n",
    "\n",
    "# Add a column 'Label' with all values set to 1\n",
    "new_data_df[100] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_df = pd.concat([data_frame, new_data_df], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.784057e-199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.841355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.784057e-199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.101491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.784057e-199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.507284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.784057e-199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.784057e-199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>0.405654</td>\n",
       "      <td>4.629274e-01</td>\n",
       "      <td>-0.366650</td>\n",
       "      <td>-0.508944</td>\n",
       "      <td>-0.194749</td>\n",
       "      <td>0.141172</td>\n",
       "      <td>-0.174666</td>\n",
       "      <td>-0.229475</td>\n",
       "      <td>-0.125181</td>\n",
       "      <td>0.148029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462409</td>\n",
       "      <td>0.007850</td>\n",
       "      <td>-0.214231</td>\n",
       "      <td>-0.196469</td>\n",
       "      <td>-0.050491</td>\n",
       "      <td>-0.159095</td>\n",
       "      <td>0.120817</td>\n",
       "      <td>-0.008852</td>\n",
       "      <td>-0.045440</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>0.369171</td>\n",
       "      <td>1.758905e-01</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>0.050550</td>\n",
       "      <td>-0.525651</td>\n",
       "      <td>-0.142062</td>\n",
       "      <td>-0.131028</td>\n",
       "      <td>-0.155611</td>\n",
       "      <td>-0.177161</td>\n",
       "      <td>0.230657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101704</td>\n",
       "      <td>-0.632435</td>\n",
       "      <td>-0.408802</td>\n",
       "      <td>-0.146775</td>\n",
       "      <td>-0.159656</td>\n",
       "      <td>-0.537760</td>\n",
       "      <td>-0.268562</td>\n",
       "      <td>0.232839</td>\n",
       "      <td>-0.015646</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>0.381100</td>\n",
       "      <td>3.035871e-01</td>\n",
       "      <td>-0.492610</td>\n",
       "      <td>-0.131423</td>\n",
       "      <td>-0.505997</td>\n",
       "      <td>0.062401</td>\n",
       "      <td>-0.153792</td>\n",
       "      <td>0.152791</td>\n",
       "      <td>0.304824</td>\n",
       "      <td>0.161658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402255</td>\n",
       "      <td>-0.501319</td>\n",
       "      <td>-0.097919</td>\n",
       "      <td>-0.228281</td>\n",
       "      <td>-0.300880</td>\n",
       "      <td>-0.264588</td>\n",
       "      <td>-0.032744</td>\n",
       "      <td>-0.212143</td>\n",
       "      <td>0.151881</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>0.418978</td>\n",
       "      <td>1.066344e-01</td>\n",
       "      <td>-0.177968</td>\n",
       "      <td>-0.139130</td>\n",
       "      <td>-0.334364</td>\n",
       "      <td>0.102424</td>\n",
       "      <td>-0.215029</td>\n",
       "      <td>0.211196</td>\n",
       "      <td>-0.015105</td>\n",
       "      <td>0.221532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313792</td>\n",
       "      <td>-0.478980</td>\n",
       "      <td>-0.595775</td>\n",
       "      <td>-0.112882</td>\n",
       "      <td>0.085187</td>\n",
       "      <td>-0.374138</td>\n",
       "      <td>0.230070</td>\n",
       "      <td>0.121823</td>\n",
       "      <td>0.163520</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>0.608583</td>\n",
       "      <td>3.362908e-01</td>\n",
       "      <td>-0.373865</td>\n",
       "      <td>-0.059057</td>\n",
       "      <td>-0.292144</td>\n",
       "      <td>0.338196</td>\n",
       "      <td>-0.117725</td>\n",
       "      <td>-0.423571</td>\n",
       "      <td>-0.161783</td>\n",
       "      <td>0.413017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491108</td>\n",
       "      <td>-0.420856</td>\n",
       "      <td>-0.466451</td>\n",
       "      <td>-0.411644</td>\n",
       "      <td>0.142985</td>\n",
       "      <td>-0.407325</td>\n",
       "      <td>0.085133</td>\n",
       "      <td>0.060986</td>\n",
       "      <td>-0.149428</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2628 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0              1         2         3         4         5    \\\n",
       "0     0.000000  9.784057e-199  0.000000  0.000000  0.000000  0.000000   \n",
       "1     0.000000  9.784057e-199  0.000000  0.000000  0.000000  0.000000   \n",
       "2     0.000000  9.784057e-199  0.000000  0.000000  0.000000  0.000000   \n",
       "3     0.000000  9.784057e-199  0.000000  0.000000  0.000000  0.000000   \n",
       "4     0.000000  9.784057e-199  0.000000  0.000000  0.000000  0.000000   \n",
       "...        ...            ...       ...       ...       ...       ...   \n",
       "2623  0.405654   4.629274e-01 -0.366650 -0.508944 -0.194749  0.141172   \n",
       "2624  0.369171   1.758905e-01  0.006864  0.050550 -0.525651 -0.142062   \n",
       "2625  0.381100   3.035871e-01 -0.492610 -0.131423 -0.505997  0.062401   \n",
       "2626  0.418978   1.066344e-01 -0.177968 -0.139130 -0.334364  0.102424   \n",
       "2627  0.608583   3.362908e-01 -0.373865 -0.059057 -0.292144  0.338196   \n",
       "\n",
       "           6         7         8         9    ...       91        92   \\\n",
       "0     0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "1     0.000000  0.000000  0.000000  0.000000  ...  1.101491  0.000000   \n",
       "2     0.000000  0.000000  0.000000  0.000000  ...  1.507284  0.000000   \n",
       "3     0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "4     0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "...        ...       ...       ...       ...  ...       ...       ...   \n",
       "2623 -0.174666 -0.229475 -0.125181  0.148029  ...  0.462409  0.007850   \n",
       "2624 -0.131028 -0.155611 -0.177161  0.230657  ...  0.101704 -0.632435   \n",
       "2625 -0.153792  0.152791  0.304824  0.161658  ...  0.402255 -0.501319   \n",
       "2626 -0.215029  0.211196 -0.015105  0.221532  ...  0.313792 -0.478980   \n",
       "2627 -0.117725 -0.423571 -0.161783  0.413017  ...  0.491108 -0.420856   \n",
       "\n",
       "           93        94        95        96        97        98        99   \\\n",
       "0     0.841355  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2623 -0.214231 -0.196469 -0.050491 -0.159095  0.120817 -0.008852 -0.045440   \n",
       "2624 -0.408802 -0.146775 -0.159656 -0.537760 -0.268562  0.232839 -0.015646   \n",
       "2625 -0.097919 -0.228281 -0.300880 -0.264588 -0.032744 -0.212143  0.151881   \n",
       "2626 -0.595775 -0.112882  0.085187 -0.374138  0.230070  0.121823  0.163520   \n",
       "2627 -0.466451 -0.411644  0.142985 -0.407325  0.085133  0.060986 -0.149428   \n",
       "\n",
       "      100  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "...   ...  \n",
       "2623  1.0  \n",
       "2624  1.0  \n",
       "2625  1.0  \n",
       "2626  1.0  \n",
       "2627  1.0  \n",
       "\n",
       "[2628 rows x 101 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='enhanced_VAE_final_new_par_50_NNMF_space_2.csv'\n",
    "file_path = os.path.join(base_dir,'data','split',ltype, file_name)\n",
    "output_path = file_path\n",
    "enhanced_df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
