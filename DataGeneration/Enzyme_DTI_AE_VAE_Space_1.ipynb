{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend as K\n",
    "\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def build_encoder(latent_dim=20):\n",
    "    encoder_inputs = layers.Input(shape=(100,)) #change here features*2\n",
    "    x = layers.Dense(256, activation='relu')(encoder_inputs)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    z_mean = layers.Dense(latent_dim)(x)\n",
    "    z_log_var = layers.Dense(latent_dim)(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    encoder = models.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "    return encoder\n",
    "\n",
    "def build_decoder(latent_dim=20):\n",
    "    latent_inputs = layers.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(64, activation='relu')(latent_inputs)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    decoder_outputs = layers.Dense(100, activation='linear')(x) #change here features*2\n",
    "    decoder = models.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "    return decoder\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        # Initialize trackers for monitoring losses\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # Return list of metrics to be updated during training\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(z)\n",
    "        # Compute KL divergence loss even during inference to track loss correctly\n",
    "        kl_loss = -0.5 * tf.reduce_mean(\n",
    "            1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\n",
    "        # Only add KL loss during training\n",
    "        if training:\n",
    "            self.add_loss(kl_loss)\n",
    "        return reconstructed\n",
    "\n",
    "    def train_step(self, data):\n",
    "    # Unpack the data\n",
    "        x = data[0] if isinstance(data, tuple) else data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(x, training=True)\n",
    "            reconstruction = self.decoder(z, training=True)\n",
    "\n",
    "            # If  data is flat (e.g., shape=(batch_size, features)), adjust axis accordingly\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(x, reconstruction), axis=-1\n",
    "            )\n",
    "            reconstruction_loss = tf.reduce_sum(reconstruction_loss)  # Sum over all dimensions\n",
    "\n",
    "            kl_loss = -0.5 * tf.reduce_mean(\n",
    "                1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1\n",
    "            )\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        return {'loss': total_loss, 'reconstruction_loss': reconstruction_loss, 'kl_loss': kl_loss}\n",
    "\n",
    "# Example usage:\n",
    "latent_dim = 16  \n",
    "encoder = build_encoder(latent_dim)\n",
    "decoder = build_decoder(latent_dim)\n",
    "vae = VAE(encoder, decoder)\n",
    "#vae.compile(optimizer='adam')\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relative paths. # Set directory paths for later use.\n",
    "# Get the directory of the script file\n",
    "base_dir = os.getcwd()\n",
    "base_dir\n",
    "ligants_type=['enzyme','GPCR','ion_channel','nuclear_receptor']\n",
    "ltype=ligants_type[0]\n",
    "file_name='final_new_par_50.csv'\n",
    "file_path = os.path.join(base_dir,'data','split',ltype, file_name)\n",
    "output_path = file_path\n",
    "data_frame = pd.read_csv(file_path, header=None, skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include instances with label 1 (interactions)\n",
    "# Separate features and labels\n",
    "filtered_df = data_frame[data_frame.iloc[:, -1] == 1]  # All rows, all columns except the last one\n",
    "features_new = filtered_df.iloc[:, :-1]     # All rows, just the last column\n",
    "\n",
    "# Convert features DataFrame to a NumPy array if necessary\n",
    "x_train = features_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para\n",
    "epochs=4\n",
    "batch_size=77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "38/38 [==============================] - 1s 1ms/step - loss: -0.4480 - reconstruction_loss: -0.5447 - kl_loss: 0.0057\n",
      "Epoch 2/4\n",
      "38/38 [==============================] - 0s 1ms/step - loss: -0.5374 - reconstruction_loss: -0.6820 - kl_loss: 0.0043\n",
      "Epoch 3/4\n",
      "38/38 [==============================] - 0s 1ms/step - loss: -0.5268 - reconstruction_loss: -0.4341 - kl_loss: 0.0086\n",
      "Epoch 4/4\n",
      "38/38 [==============================] - 0s 1ms/step - loss: -0.5196 - reconstruction_loss: -0.6218 - kl_loss: 0.0164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b59e139840>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "vae.fit(x_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include instances with label 1 (interactions)\n",
    "filtered_df = data_frame[data_frame.iloc[:, -1] == 1]\n",
    "\n",
    "# Separate features\n",
    "features_new = filtered_df.iloc[:, :-1]  # Assuming the last column is the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = features_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 690us/step\n"
     ]
    }
   ],
   "source": [
    "z_mean, z_log_var, z = vae.encoder.predict(x_new)\n",
    "# Now, z contains the latent representations of  filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 740us/step\n"
     ]
    }
   ],
   "source": [
    "reconstructed_new = vae.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6   \\\n",
      "0     0.080027  0.055418  0.017724  0.017277  0.056821  0.005954 -0.029917   \n",
      "1     0.080027  0.055418  0.017724  0.017277  0.056821  0.005954 -0.029917   \n",
      "2    -0.046547 -0.080549  0.052451  0.000061 -0.064179 -0.012908 -0.102061   \n",
      "3    -0.046547 -0.080549  0.052451  0.000061 -0.064179 -0.012908 -0.102061   \n",
      "4     0.038484  0.007434  0.102825  0.015764 -0.125684  0.015386  0.026150   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2921  0.003413  0.029073  0.025779 -0.019589 -0.060884 -0.042604  0.027152   \n",
      "2922  0.003413  0.029073  0.025779 -0.019589 -0.060884 -0.042604  0.027152   \n",
      "2923  0.068374 -0.106889  0.044540 -0.122091  0.018286 -0.004360 -0.022856   \n",
      "2924  0.075645 -0.062817  0.059782  0.100770  0.028446  0.059260  0.046615   \n",
      "2925 -0.039468 -0.070520  0.049080 -0.000448 -0.058769 -0.011082 -0.091713   \n",
      "\n",
      "            7         8         9   ...        90        91        92  \\\n",
      "0     0.008259  0.019316  0.066974  ... -0.082742 -0.403536 -0.191163   \n",
      "1     0.008259  0.019316  0.066974  ... -0.240424 -0.541881 -0.157027   \n",
      "2     0.055502  0.022353 -0.009300  ... -0.138903 -0.027521  0.706775   \n",
      "3     0.055502  0.022353 -0.009300  ... -0.002350 -0.007346  0.075844   \n",
      "4    -0.075134 -0.098530 -0.040639  ... -0.398685 -0.222352 -0.190930   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "2921  0.055969  0.044580  0.035242  ... -0.272913  0.083724 -0.088851   \n",
      "2922  0.055969  0.044580  0.035242  ... -0.254114  0.077957 -0.082731   \n",
      "2923  0.060628  0.086119 -0.117409  ... -0.356530 -0.083311 -0.277773   \n",
      "2924  0.083618 -0.034867  0.030905  ...  0.058316  0.568170  0.032549   \n",
      "2925  0.048254  0.019025 -0.007533  ... -0.138903 -0.027521  0.706775   \n",
      "\n",
      "            93        94        95        96        97        98        99  \n",
      "0    -0.382638 -0.072666 -0.235280  0.674016 -0.230834  0.576804  0.109754  \n",
      "1     0.260723 -0.318664  0.225260  0.085720 -0.126427 -0.033257 -0.360073  \n",
      "2    -0.092144  0.512230 -0.300680  0.110968  0.058411  0.445414 -0.153385  \n",
      "3    -0.004010  0.037738 -0.022507  0.011184 -0.006567  0.059387 -0.016497  \n",
      "4     0.167677  0.393765  0.120785 -0.344031  0.143958 -0.214465 -0.417340  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "2921 -0.237121  0.226598  0.143899  0.149934 -0.612863  0.414312  0.073460  \n",
      "2922 -0.220788  0.210990  0.133987  0.139607 -0.570649  0.385774  0.068400  \n",
      "2923  0.073635  0.150799  0.262812 -0.356142  0.040232 -0.036989 -0.069247  \n",
      "2924 -0.237664 -0.463677  0.182856  0.157182  0.178704  0.105138 -0.273955  \n",
      "2925 -0.092144  0.512230 -0.300680  0.110968  0.058411  0.445414 -0.153385  \n",
      "\n",
      "[2926 rows x 100 columns]\n",
      "            0         1         2         3         4         5         6   \\\n",
      "0    -0.861661 -0.585915 -0.591043 -0.842195 -0.745447  0.216452 -1.074485   \n",
      "1    -0.949222 -0.500993 -0.880098 -0.553721 -0.883937  0.266532 -0.630056   \n",
      "2    -0.413318 -0.222935 -0.334005 -0.224209 -0.315733  0.181605 -0.325502   \n",
      "3    -0.635586 -0.641435 -0.709967 -0.775536 -0.257161  0.036724 -0.398677   \n",
      "4    -0.772618 -0.453097 -0.257382 -0.739482 -0.630653  0.008736 -0.606879   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2921 -0.690284 -0.210814 -0.534554 -0.157743 -0.799618  0.178113 -0.518718   \n",
      "2922 -0.338139 -0.275630 -0.333683 -0.297046 -0.329686  0.053825 -0.225794   \n",
      "2923 -0.575187 -0.353117 -0.416436 -0.427413 -0.463848  0.069277 -0.545866   \n",
      "2924 -0.577597 -0.325521 -0.678258 -0.740509 -0.514636  0.022943 -0.229400   \n",
      "2925 -0.397993 -0.375442 -0.305215 -0.266346 -0.335772 -0.065752 -0.145036   \n",
      "\n",
      "            7         8         9   ...        90        91        92  \\\n",
      "0     0.154959 -0.548225 -0.604495  ... -0.632059 -0.806050 -0.734828   \n",
      "1    -0.394999 -0.661617 -0.385762  ... -0.715893 -0.442364 -0.664430   \n",
      "2    -0.126942 -0.518338 -0.373655  ... -0.663003 -0.551292 -0.726652   \n",
      "3    -0.233421 -0.926981 -0.387345  ... -0.912043 -0.648746 -0.915288   \n",
      "4     0.067446 -0.679020 -0.501460  ... -0.598040 -0.604135 -0.721946   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "2921  0.277687 -0.889715 -0.584637  ... -0.778299 -0.508237 -0.719592   \n",
      "2922 -0.001463 -0.316086 -0.247453  ... -0.424149 -0.253366 -0.380821   \n",
      "2923  0.221172 -0.401496 -0.229486  ... -0.588826 -0.427042 -0.692562   \n",
      "2924  0.020231 -0.587952 -0.560123  ... -0.861534 -0.818853 -0.558505   \n",
      "2925 -0.181053 -0.349485 -0.240781  ... -0.472907 -0.281217 -0.555540   \n",
      "\n",
      "            93        94        95        96        97        98        99  \n",
      "0    -0.444605 -0.901690 -0.773047  0.715118 -0.698463 -0.853807 -0.131986  \n",
      "1    -0.690633 -1.119779 -0.705094  0.702095 -0.539687 -0.685365 -0.136393  \n",
      "2    -0.494389 -0.682730 -0.145706  0.173168 -0.377877 -0.492044 -0.163639  \n",
      "3    -0.749956 -0.948687 -0.665511  0.702343 -0.693025 -0.570631 -0.649230  \n",
      "4    -0.522817 -0.616394 -0.718979  0.507590 -0.525080 -0.691504  0.063068  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "2921 -0.525224 -0.573067 -0.612911  0.650661 -1.035418 -0.668072 -0.255328  \n",
      "2922 -0.348682 -0.472802 -0.344948  0.206454 -0.349638 -0.420305 -0.149939  \n",
      "2923 -0.426538 -0.612872 -0.433257  0.092757 -0.281732 -0.499984 -0.084431  \n",
      "2924 -0.589791 -0.653682 -0.861971  0.303888 -0.281962 -0.703086 -0.108574  \n",
      "2925 -0.323157 -0.452676 -0.223550  0.090546 -0.417423 -0.342780 -0.041926  \n",
      "\n",
      "[2926 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the reconstructed data to a DataFrame\n",
    "reconstructed_df = pd.DataFrame(reconstructed_new)\n",
    "\n",
    "# Display the first few rows of the reconstructed DataFrame\n",
    "print(pd.DataFrame(x_new))\n",
    "print(reconstructed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0 -0.861661 -0.585915 -0.591043 -0.842195 -0.745447  0.216452 -1.074485   \n",
      "1 -0.949222 -0.500993 -0.880098 -0.553721 -0.883937  0.266532 -0.630056   \n",
      "2 -0.413318 -0.222935 -0.334005 -0.224209 -0.315733  0.181605 -0.325502   \n",
      "3 -0.635586 -0.641435 -0.709967 -0.775536 -0.257161  0.036724 -0.398677   \n",
      "4 -0.772618 -0.453097 -0.257382 -0.739482 -0.630653  0.008736 -0.606879   \n",
      "\n",
      "        7         8         9    ...       91        92        93        94   \\\n",
      "0  0.154959 -0.548225 -0.604495  ... -0.806050 -0.734828 -0.444605 -0.901690   \n",
      "1 -0.394999 -0.661617 -0.385762  ... -0.442364 -0.664430 -0.690633 -1.119779   \n",
      "2 -0.126942 -0.518338 -0.373655  ... -0.551292 -0.726652 -0.494389 -0.682730   \n",
      "3 -0.233421 -0.926981 -0.387345  ... -0.648746 -0.915288 -0.749956 -0.948687   \n",
      "4  0.067446 -0.679020 -0.501460  ... -0.604135 -0.721946 -0.522817 -0.616394   \n",
      "\n",
      "        95        96        97        98        99   100  \n",
      "0 -0.773047  0.715118 -0.698463 -0.853807 -0.131986    1  \n",
      "1 -0.705094  0.702095 -0.539687 -0.685365 -0.136393    1  \n",
      "2 -0.145706  0.173168 -0.377877 -0.492044 -0.163639    1  \n",
      "3 -0.665511  0.702343 -0.693025 -0.570631 -0.649230    1  \n",
      "4 -0.718979  0.507590 -0.525080 -0.691504  0.063068    1  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "# Add a new column 'Label' with all values set to 1\n",
    "reconstructed_df[100] = 1\n",
    "\n",
    "# Display the first few rows to verify the new column\n",
    "print(reconstructed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9051/9051 [==============================] - 5s 569us/step\n"
     ]
    }
   ],
   "source": [
    "num_samples_to_generate = 289628  # The number of new rows want to generate\n",
    "\n",
    "# Generate random samples from the latent space\n",
    "latent_dim = 16  # Ensure this matches the latent dimension size of  VAE\n",
    "z_new_samples = np.random.normal(size=(num_samples_to_generate, latent_dim))\n",
    "\n",
    "# Use the decoder to generate new data\n",
    "new_data_generated = vae.decoder.predict(z_new_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.63620895, -0.7194237 , -0.6346098 , ..., -0.57374126,\n",
       "        -0.5961747 , -0.2661002 ],\n",
       "       [-0.787896  , -0.63543403, -0.99782455, ..., -0.7914736 ,\n",
       "        -0.688481  , -0.33501157],\n",
       "       [-0.52725196, -0.48129678, -0.35705304, ..., -0.5709403 ,\n",
       "        -0.6445925 , -0.21847096],\n",
       "       ...,\n",
       "       [-0.39053866, -0.29287115, -0.42058325, ..., -0.47583935,\n",
       "        -0.33196518,  0.01297571],\n",
       "       [-0.51104516, -0.3512726 , -0.5907528 , ..., -0.6765822 ,\n",
       "        -0.6665807 , -0.4243497 ],\n",
       "       [-0.7252508 , -0.65709627, -0.66352063, ..., -0.53400946,\n",
       "        -0.9022702 , -0.34600395]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the generated data to a DataFrame\n",
    "new_data_df = pd.DataFrame(new_data_generated)\n",
    "\n",
    "# Add a column 'Label' with all values set to 1\n",
    "new_data_df[100] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_df = pd.concat([data_frame, new_data_df], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.080027</td>\n",
       "      <td>0.055418</td>\n",
       "      <td>0.017724</td>\n",
       "      <td>0.017277</td>\n",
       "      <td>0.056821</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>-0.029917</td>\n",
       "      <td>0.008259</td>\n",
       "      <td>0.019316</td>\n",
       "      <td>0.066974</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.035356e-01</td>\n",
       "      <td>-1.911631e-01</td>\n",
       "      <td>-3.826382e-01</td>\n",
       "      <td>-7.266647e-02</td>\n",
       "      <td>-2.352797e-01</td>\n",
       "      <td>6.740164e-01</td>\n",
       "      <td>-2.308341e-01</td>\n",
       "      <td>5.768036e-01</td>\n",
       "      <td>1.097545e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.080027</td>\n",
       "      <td>0.055418</td>\n",
       "      <td>0.017724</td>\n",
       "      <td>0.017277</td>\n",
       "      <td>0.056821</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>-0.029917</td>\n",
       "      <td>0.008259</td>\n",
       "      <td>0.019316</td>\n",
       "      <td>0.066974</td>\n",
       "      <td>...</td>\n",
       "      <td>3.967650e-01</td>\n",
       "      <td>-1.127281e-01</td>\n",
       "      <td>-1.678870e-01</td>\n",
       "      <td>-2.890346e-01</td>\n",
       "      <td>3.202525e-01</td>\n",
       "      <td>-8.532839e-02</td>\n",
       "      <td>4.050606e-01</td>\n",
       "      <td>-5.754756e-01</td>\n",
       "      <td>-1.279708e-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.080027</td>\n",
       "      <td>0.055418</td>\n",
       "      <td>0.017724</td>\n",
       "      <td>0.017277</td>\n",
       "      <td>0.056821</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>-0.029917</td>\n",
       "      <td>0.008259</td>\n",
       "      <td>0.019316</td>\n",
       "      <td>0.066974</td>\n",
       "      <td>...</td>\n",
       "      <td>7.442881e-02</td>\n",
       "      <td>-6.804657e-02</td>\n",
       "      <td>-3.267399e-02</td>\n",
       "      <td>-1.205570e-02</td>\n",
       "      <td>6.426763e-02</td>\n",
       "      <td>1.016071e-01</td>\n",
       "      <td>-8.468351e-02</td>\n",
       "      <td>4.665966e-02</td>\n",
       "      <td>-3.235123e-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.080027</td>\n",
       "      <td>0.055418</td>\n",
       "      <td>0.017724</td>\n",
       "      <td>0.017277</td>\n",
       "      <td>0.056821</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>-0.029917</td>\n",
       "      <td>0.008259</td>\n",
       "      <td>0.019316</td>\n",
       "      <td>0.066974</td>\n",
       "      <td>...</td>\n",
       "      <td>2.713670e-02</td>\n",
       "      <td>-5.593964e-03</td>\n",
       "      <td>-1.520310e-02</td>\n",
       "      <td>-4.307803e-02</td>\n",
       "      <td>2.164530e-02</td>\n",
       "      <td>-5.633650e-03</td>\n",
       "      <td>2.971487e-02</td>\n",
       "      <td>-3.464674e-02</td>\n",
       "      <td>-6.370794e-03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.080027</td>\n",
       "      <td>0.055418</td>\n",
       "      <td>0.017724</td>\n",
       "      <td>0.017277</td>\n",
       "      <td>0.056821</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>-0.029917</td>\n",
       "      <td>0.008259</td>\n",
       "      <td>0.019316</td>\n",
       "      <td>0.066974</td>\n",
       "      <td>...</td>\n",
       "      <td>5.513798e-92</td>\n",
       "      <td>2.232982e-92</td>\n",
       "      <td>-3.225556e-92</td>\n",
       "      <td>-6.545422e-92</td>\n",
       "      <td>-4.187428e-93</td>\n",
       "      <td>5.274171e-92</td>\n",
       "      <td>-2.057419e-92</td>\n",
       "      <td>3.269600e-92</td>\n",
       "      <td>6.465156e-92</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585103</th>\n",
       "      <td>-0.719688</td>\n",
       "      <td>-0.680150</td>\n",
       "      <td>-0.353983</td>\n",
       "      <td>-0.179601</td>\n",
       "      <td>-0.446141</td>\n",
       "      <td>0.480896</td>\n",
       "      <td>-0.623835</td>\n",
       "      <td>-0.014250</td>\n",
       "      <td>-0.568623</td>\n",
       "      <td>-0.413539</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.082448e-01</td>\n",
       "      <td>-4.042336e-01</td>\n",
       "      <td>-4.044191e-01</td>\n",
       "      <td>-5.423626e-01</td>\n",
       "      <td>-5.827414e-01</td>\n",
       "      <td>6.793197e-01</td>\n",
       "      <td>-6.844943e-01</td>\n",
       "      <td>-6.408510e-01</td>\n",
       "      <td>-2.931975e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585104</th>\n",
       "      <td>-0.666006</td>\n",
       "      <td>-0.660190</td>\n",
       "      <td>-0.294481</td>\n",
       "      <td>-0.242714</td>\n",
       "      <td>-0.525151</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>-0.788085</td>\n",
       "      <td>-0.022284</td>\n",
       "      <td>-0.518921</td>\n",
       "      <td>-0.470952</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.003229e-01</td>\n",
       "      <td>-4.233132e-01</td>\n",
       "      <td>-1.515131e-01</td>\n",
       "      <td>-3.987822e-01</td>\n",
       "      <td>-3.624037e-01</td>\n",
       "      <td>4.606413e-01</td>\n",
       "      <td>-7.625961e-01</td>\n",
       "      <td>-4.748498e-01</td>\n",
       "      <td>-1.639115e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585105</th>\n",
       "      <td>-0.390539</td>\n",
       "      <td>-0.292871</td>\n",
       "      <td>-0.420583</td>\n",
       "      <td>-0.412239</td>\n",
       "      <td>-0.264540</td>\n",
       "      <td>-0.175043</td>\n",
       "      <td>-0.367739</td>\n",
       "      <td>-0.039407</td>\n",
       "      <td>-0.468592</td>\n",
       "      <td>-0.208790</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.240860e-01</td>\n",
       "      <td>-9.338436e-01</td>\n",
       "      <td>-3.865623e-01</td>\n",
       "      <td>-5.520256e-01</td>\n",
       "      <td>-2.412660e-01</td>\n",
       "      <td>1.375760e-01</td>\n",
       "      <td>-4.758393e-01</td>\n",
       "      <td>-3.319652e-01</td>\n",
       "      <td>1.297571e-02</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585106</th>\n",
       "      <td>-0.511045</td>\n",
       "      <td>-0.351273</td>\n",
       "      <td>-0.590753</td>\n",
       "      <td>-0.173930</td>\n",
       "      <td>-0.420678</td>\n",
       "      <td>0.511116</td>\n",
       "      <td>-0.498013</td>\n",
       "      <td>-0.296720</td>\n",
       "      <td>-0.558568</td>\n",
       "      <td>-0.506717</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.115302e-01</td>\n",
       "      <td>-8.027560e-01</td>\n",
       "      <td>-5.947903e-01</td>\n",
       "      <td>-9.388174e-01</td>\n",
       "      <td>-3.517639e-01</td>\n",
       "      <td>3.777383e-01</td>\n",
       "      <td>-6.765822e-01</td>\n",
       "      <td>-6.665807e-01</td>\n",
       "      <td>-4.243497e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585107</th>\n",
       "      <td>-0.725251</td>\n",
       "      <td>-0.657096</td>\n",
       "      <td>-0.663521</td>\n",
       "      <td>-0.245382</td>\n",
       "      <td>-0.726984</td>\n",
       "      <td>0.188715</td>\n",
       "      <td>-0.570688</td>\n",
       "      <td>-0.334337</td>\n",
       "      <td>-0.693770</td>\n",
       "      <td>-0.303505</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.736910e-01</td>\n",
       "      <td>-5.270962e-01</td>\n",
       "      <td>-3.345095e-01</td>\n",
       "      <td>-9.481250e-01</td>\n",
       "      <td>-3.738827e-01</td>\n",
       "      <td>3.142248e-01</td>\n",
       "      <td>-5.340095e-01</td>\n",
       "      <td>-9.022702e-01</td>\n",
       "      <td>-3.460039e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>585108 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6    \\\n",
       "0       0.080027  0.055418  0.017724  0.017277  0.056821  0.005954 -0.029917   \n",
       "1       0.080027  0.055418  0.017724  0.017277  0.056821  0.005954 -0.029917   \n",
       "2       0.080027  0.055418  0.017724  0.017277  0.056821  0.005954 -0.029917   \n",
       "3       0.080027  0.055418  0.017724  0.017277  0.056821  0.005954 -0.029917   \n",
       "4       0.080027  0.055418  0.017724  0.017277  0.056821  0.005954 -0.029917   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "585103 -0.719688 -0.680150 -0.353983 -0.179601 -0.446141  0.480896 -0.623835   \n",
       "585104 -0.666006 -0.660190 -0.294481 -0.242714 -0.525151  0.003201 -0.788085   \n",
       "585105 -0.390539 -0.292871 -0.420583 -0.412239 -0.264540 -0.175043 -0.367739   \n",
       "585106 -0.511045 -0.351273 -0.590753 -0.173930 -0.420678  0.511116 -0.498013   \n",
       "585107 -0.725251 -0.657096 -0.663521 -0.245382 -0.726984  0.188715 -0.570688   \n",
       "\n",
       "             7         8         9    ...           91            92   \\\n",
       "0       0.008259  0.019316  0.066974  ... -4.035356e-01 -1.911631e-01   \n",
       "1       0.008259  0.019316  0.066974  ...  3.967650e-01 -1.127281e-01   \n",
       "2       0.008259  0.019316  0.066974  ...  7.442881e-02 -6.804657e-02   \n",
       "3       0.008259  0.019316  0.066974  ...  2.713670e-02 -5.593964e-03   \n",
       "4       0.008259  0.019316  0.066974  ...  5.513798e-92  2.232982e-92   \n",
       "...          ...       ...       ...  ...           ...           ...   \n",
       "585103 -0.014250 -0.568623 -0.413539  ... -4.082448e-01 -4.042336e-01   \n",
       "585104 -0.022284 -0.518921 -0.470952  ... -4.003229e-01 -4.233132e-01   \n",
       "585105 -0.039407 -0.468592 -0.208790  ... -4.240860e-01 -9.338436e-01   \n",
       "585106 -0.296720 -0.558568 -0.506717  ... -5.115302e-01 -8.027560e-01   \n",
       "585107 -0.334337 -0.693770 -0.303505  ... -3.736910e-01 -5.270962e-01   \n",
       "\n",
       "                 93            94            95            96            97   \\\n",
       "0      -3.826382e-01 -7.266647e-02 -2.352797e-01  6.740164e-01 -2.308341e-01   \n",
       "1      -1.678870e-01 -2.890346e-01  3.202525e-01 -8.532839e-02  4.050606e-01   \n",
       "2      -3.267399e-02 -1.205570e-02  6.426763e-02  1.016071e-01 -8.468351e-02   \n",
       "3      -1.520310e-02 -4.307803e-02  2.164530e-02 -5.633650e-03  2.971487e-02   \n",
       "4      -3.225556e-92 -6.545422e-92 -4.187428e-93  5.274171e-92 -2.057419e-92   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "585103 -4.044191e-01 -5.423626e-01 -5.827414e-01  6.793197e-01 -6.844943e-01   \n",
       "585104 -1.515131e-01 -3.987822e-01 -3.624037e-01  4.606413e-01 -7.625961e-01   \n",
       "585105 -3.865623e-01 -5.520256e-01 -2.412660e-01  1.375760e-01 -4.758393e-01   \n",
       "585106 -5.947903e-01 -9.388174e-01 -3.517639e-01  3.777383e-01 -6.765822e-01   \n",
       "585107 -3.345095e-01 -9.481250e-01 -3.738827e-01  3.142248e-01 -5.340095e-01   \n",
       "\n",
       "                 98            99   100  \n",
       "0       5.768036e-01  1.097545e-01  1.0  \n",
       "1      -5.754756e-01 -1.279708e-01  0.0  \n",
       "2       4.665966e-02 -3.235123e-02  0.0  \n",
       "3      -3.464674e-02 -6.370794e-03  0.0  \n",
       "4       3.269600e-92  6.465156e-92  0.0  \n",
       "...              ...           ...  ...  \n",
       "585103 -6.408510e-01 -2.931975e-01  1.0  \n",
       "585104 -4.748498e-01 -1.639115e-01  1.0  \n",
       "585105 -3.319652e-01  1.297571e-02  1.0  \n",
       "585106 -6.665807e-01 -4.243497e-01  1.0  \n",
       "585107 -9.022702e-01 -3.460039e-01  1.0  \n",
       "\n",
       "[585108 rows x 101 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='enhanced_final_new_par_50_space_1.csv'\n",
    "file_path = os.path.join(base_dir,'data','split',ltype, file_name)\n",
    "output_path = file_path\n",
    "enhanced_df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
