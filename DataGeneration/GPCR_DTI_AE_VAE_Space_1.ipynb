{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend as K\n",
    "\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def build_encoder(latent_dim=20):\n",
    "    encoder_inputs = layers.Input(shape=(100,)) #change here features*2\n",
    "    x = layers.Dense(256, activation='relu')(encoder_inputs)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    z_mean = layers.Dense(latent_dim)(x)\n",
    "    z_log_var = layers.Dense(latent_dim)(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    encoder = models.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "    return encoder\n",
    "\n",
    "def build_decoder(latent_dim=20):\n",
    "    latent_inputs = layers.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(64, activation='relu')(latent_inputs)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    decoder_outputs = layers.Dense(100, activation='linear')(x) #change here features*2\n",
    "    decoder = models.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "    return decoder\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        # Initialize trackers for monitoring losses\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # Return list of metrics to be updated during training\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(z)\n",
    "        # Compute KL divergence loss even during inference to track loss correctly\n",
    "        kl_loss = -0.5 * tf.reduce_mean(\n",
    "            1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\n",
    "        # Only add KL loss during training\n",
    "        if training:\n",
    "            self.add_loss(kl_loss)\n",
    "        return reconstructed\n",
    "\n",
    "    def train_step(self, data):\n",
    "    # Unpack the data\n",
    "        x = data[0] if isinstance(data, tuple) else data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(x, training=True)\n",
    "            reconstruction = self.decoder(z, training=True)\n",
    "\n",
    "            # If  data is flat (e.g., shape=(batch_size, features)), adjust axis accordingly\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(x, reconstruction), axis=-1\n",
    "            )\n",
    "            reconstruction_loss = tf.reduce_sum(reconstruction_loss)  # Sum over all dimensions\n",
    "\n",
    "            kl_loss = -0.5 * tf.reduce_mean(\n",
    "                1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1\n",
    "            )\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        return {'loss': total_loss, 'reconstruction_loss': reconstruction_loss, 'kl_loss': kl_loss}\n",
    "\n",
    "# Example usage:\n",
    "latent_dim = 16  \n",
    "encoder = build_encoder(latent_dim)\n",
    "decoder = build_decoder(latent_dim)\n",
    "vae = VAE(encoder, decoder)\n",
    "#vae.compile(optimizer='adam')\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relative paths. # Set directory paths for later use.\n",
    "# Get the directory of the script file\n",
    "base_dir = os.getcwd()\n",
    "base_dir\n",
    "ligants_type=['enzyme','GPCR','ion_channel','nuclear_receptor']\n",
    "ltype=ligants_type[1]\n",
    "file_name='final_new_par_50.csv'\n",
    "file_path = os.path.join(base_dir,'data','split',ltype, file_name)\n",
    "output_path = file_path\n",
    "data_frame = pd.read_csv(file_path, header=None, skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include instances with label 1 (interactions)\n",
    "# Separate features and labels\n",
    "filtered_df = data_frame[data_frame.iloc[:, -1] == 1]  # All rows, all columns except the last one\n",
    "features_new = filtered_df.iloc[:, :-1]     # All rows, just the last column\n",
    "\n",
    "# Convert features DataFrame to a NumPy array if necessary\n",
    "x_train = features_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(635, 101)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para\n",
    "epochs=20\n",
    "batch_size=127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5/5 [==============================] - 1s 3ms/step - loss: -0.3555 - reconstruction_loss: -0.4627 - kl_loss: 0.0091\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 2ms/step - loss: -0.4828 - reconstruction_loss: -0.5145 - kl_loss: 0.0091\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 2ms/step - loss: -0.5649 - reconstruction_loss: -0.6173 - kl_loss: 0.0095\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 2ms/step - loss: -0.6008 - reconstruction_loss: -0.6029 - kl_loss: 0.0092\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 2ms/step - loss: -0.6251 - reconstruction_loss: -0.6212 - kl_loss: 0.0080\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 2ms/step - loss: -0.6414 - reconstruction_loss: -0.6527 - kl_loss: 0.0076\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 2ms/step - loss: -0.6429 - reconstruction_loss: -0.6316 - kl_loss: 0.0074\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 2ms/step - loss: -0.6391 - reconstruction_loss: -0.6122 - kl_loss: 0.0070\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 2ms/step - loss: -0.6484 - reconstruction_loss: -0.6414 - kl_loss: 0.0067\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 2ms/step - loss: -0.6482 - reconstruction_loss: -0.6344 - kl_loss: 0.0067\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 2ms/step - loss: -0.6496 - reconstruction_loss: -0.6446 - kl_loss: 0.0072\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 2ms/step - loss: -0.6507 - reconstruction_loss: -0.6688 - kl_loss: 0.0066\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 2ms/step - loss: -0.6532 - reconstruction_loss: -0.6584 - kl_loss: 0.0060\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 2ms/step - loss: -0.6554 - reconstruction_loss: -0.6799 - kl_loss: 0.0057\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 2ms/step - loss: -0.6543 - reconstruction_loss: -0.6482 - kl_loss: 0.0059\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 2ms/step - loss: -0.6546 - reconstruction_loss: -0.6416 - kl_loss: 0.0058\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 2ms/step - loss: -0.6571 - reconstruction_loss: -0.6663 - kl_loss: 0.0057\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 2ms/step - loss: -0.6591 - reconstruction_loss: -0.6664 - kl_loss: 0.0054\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 2ms/step - loss: -0.6555 - reconstruction_loss: -0.6325 - kl_loss: 0.0057\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 2ms/step - loss: -0.6522 - reconstruction_loss: -0.6103 - kl_loss: 0.0051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17c9ed82020>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "vae.fit(x_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include instances with label 1 (interactions)\n",
    "filtered_df = data_frame[data_frame.iloc[:, -1] == 1]\n",
    "\n",
    "# Separate features\n",
    "features_new = filtered_df.iloc[:, :-1]  # Assuming the last column is the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = features_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 764us/step\n"
     ]
    }
   ],
   "source": [
    "z_mean, z_log_var, z = vae.encoder.predict(x_new)\n",
    "# Now, z contains the latent representations of  filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 692us/step\n"
     ]
    }
   ],
   "source": [
    "reconstructed_new = vae.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0             1             2             3             4   \\\n",
      "0   -3.394378e-02 -2.774489e-02  7.436590e-02 -2.090742e-03  5.429764e-02   \n",
      "1    2.061547e-01 -3.876480e-02  9.635618e-02 -3.174892e-02  1.931787e-01   \n",
      "2    2.061547e-01 -3.876480e-02  9.635618e-02 -3.174892e-02  1.931787e-01   \n",
      "3    2.061547e-01 -3.876480e-02  9.635618e-02 -3.174892e-02  1.931787e-01   \n",
      "4    8.515725e-02  6.800587e-03 -7.951888e-02 -1.056655e-01  3.806502e-02   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "630 -8.027622e-02  1.060513e-01  1.119848e-01 -5.767181e-02 -5.158156e-02   \n",
      "631 -8.027622e-02  1.060513e-01  1.119848e-01 -5.767181e-02 -5.158156e-02   \n",
      "632 -5.106899e-07  9.601754e-07 -5.953880e-07 -8.921481e-07  8.955838e-07   \n",
      "633 -1.766981e-07  3.091753e-07 -1.796200e-07 -2.279041e-07  3.049497e-07   \n",
      "634 -3.394378e-02 -2.774489e-02  7.436590e-02 -2.090742e-03  5.429764e-02   \n",
      "\n",
      "               5             6             7             8             9   \\\n",
      "0    6.331745e-02  2.202923e-03 -4.671405e-02 -1.289144e-02 -7.775326e-02   \n",
      "1   -5.171219e-02 -2.916311e-02  1.510089e-01 -4.695306e-02 -1.179926e-01   \n",
      "2   -5.171219e-02 -2.916311e-02  1.510089e-01 -4.695306e-02 -1.179926e-01   \n",
      "3   -5.171219e-02 -2.916311e-02  1.510089e-01 -4.695306e-02 -1.179926e-01   \n",
      "4   -1.078900e-01  1.744520e-01  2.807515e-02  1.183638e-01 -7.637991e-02   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "630 -1.216857e-02  3.399506e-02 -3.712097e-02 -4.581004e-02 -8.790220e-02   \n",
      "631 -1.216857e-02  3.399506e-02 -3.712097e-02 -4.581004e-02 -8.790220e-02   \n",
      "632  9.519933e-07  1.932143e-06  2.131218e-06 -4.099574e-07 -2.836771e-06   \n",
      "633  3.136248e-07  7.021606e-07  7.031657e-07 -1.450937e-07 -9.239236e-07   \n",
      "634  6.331745e-02  2.202923e-03 -4.671405e-02 -1.289144e-02 -7.775326e-02   \n",
      "\n",
      "     ...            90            91            92            93  \\\n",
      "0    ...  3.727172e-01  6.145643e-01  1.022076e-01 -8.743386e-02   \n",
      "1    ...  1.549818e-02  3.723683e-01  2.356849e-01  2.768909e-02   \n",
      "2    ... -6.886406e-02  8.749928e-02 -1.252540e-02 -9.068005e-02   \n",
      "3    ... -2.403902e-01  1.144372e-01 -1.575744e-02 -2.027453e-01   \n",
      "4    ... -8.989160e-02  6.115322e-02  1.074650e-01  2.830752e-01   \n",
      "..   ...           ...           ...           ...           ...   \n",
      "630  ...  9.926677e-02 -2.323308e-01 -2.479449e-01  6.943759e-02   \n",
      "631  ...  9.926677e-02 -2.323308e-01 -2.479449e-01  6.943759e-02   \n",
      "632  ... -1.710462e-06 -8.452601e-07 -2.362153e-06 -2.292205e-06   \n",
      "633  ... -6.180583e-07 -3.339024e-07 -7.878403e-07 -8.026924e-07   \n",
      "634  ...  3.727172e-01  6.145643e-01  1.022076e-01 -8.743386e-02   \n",
      "\n",
      "               94            95            96            97            98  \\\n",
      "0   -7.124609e-01 -7.491338e-01  1.617664e-02 -1.017524e-01  4.498711e-01   \n",
      "1    3.672321e-01 -6.237235e-02 -2.575412e-01  2.346456e-01 -1.020131e-01   \n",
      "2    1.107035e-01 -4.619621e-02 -7.831721e-02  4.729598e-02  1.222292e-02   \n",
      "3    2.137073e-01 -3.390138e-02 -1.167211e-01  1.291375e-01  1.150235e-01   \n",
      "4   -1.304299e-01  2.099094e-02  1.280811e-01  1.648923e-01  2.694979e-01   \n",
      "..            ...           ...           ...           ...           ...   \n",
      "630  2.856043e-01 -1.396266e-01 -2.416597e-01  9.323817e-02 -1.251078e-03   \n",
      "631  2.856043e-01 -1.396266e-01 -2.416597e-01  9.323817e-02 -1.251078e-03   \n",
      "632 -5.640821e-07 -6.983902e-07  1.942949e-07 -7.831622e-07  1.231410e-06   \n",
      "633 -1.956675e-07 -2.264675e-07  9.285129e-08 -2.824850e-07  4.062207e-07   \n",
      "634 -7.124609e-01 -7.491338e-01  1.617664e-02 -1.017524e-01  4.498711e-01   \n",
      "\n",
      "               99  \n",
      "0    3.249295e-02  \n",
      "1   -1.200243e-01  \n",
      "2   -7.049375e-02  \n",
      "3   -1.208980e-01  \n",
      "4   -1.702494e-01  \n",
      "..            ...  \n",
      "630  3.985335e-02  \n",
      "631  3.985335e-02  \n",
      "632 -7.150177e-07  \n",
      "633 -2.287157e-07  \n",
      "634  3.249295e-02  \n",
      "\n",
      "[635 rows x 100 columns]\n",
      "           0         1         2         3         4         5         6   \\\n",
      "0   -0.492125 -0.336018 -0.559723 -0.117003 -0.528587 -0.422723 -0.238075   \n",
      "1   -0.477891 -0.235203 -0.371923 -0.592861 -0.590469 -0.613857 -0.219182   \n",
      "2   -0.435469 -0.260772 -0.145093 -0.541271 -0.148564 -0.380243 -0.062029   \n",
      "3   -0.650563 -0.246841 -0.859602 -0.594107 -0.581299 -0.222427  0.174027   \n",
      "4   -0.787603 -0.127268 -0.829895 -0.702727 -0.654649 -0.169831 -0.160371   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "630 -0.850224 -0.359337 -0.726721 -0.563846 -0.599186 -0.571017 -0.203377   \n",
      "631 -0.039684 -0.424622  0.056557 -0.263461 -0.157499 -0.182002 -0.044987   \n",
      "632 -0.637595 -0.697375 -0.572557 -0.441528 -0.206049 -0.752587  0.109893   \n",
      "633 -0.323306 -0.442054 -0.250637 -0.458230 -0.423969 -0.387110  0.235032   \n",
      "634 -0.417197 -0.217432 -0.641810 -0.464355 -0.387283 -0.492615  0.052410   \n",
      "\n",
      "           7         8         9   ...        90        91        92  \\\n",
      "0   -0.303260 -0.457011 -0.079655  ... -0.881980 -0.505221 -0.772251   \n",
      "1   -0.321777 -0.351439 -0.264356  ... -0.582843 -0.746410 -0.501690   \n",
      "2   -0.205360 -0.470583 -0.060717  ... -0.465020 -0.341087 -0.440586   \n",
      "3    0.155203 -0.487916 -0.597907  ... -0.170579 -0.368406 -0.309678   \n",
      "4   -0.171508 -0.537167 -0.415171  ... -0.501363 -0.350304 -0.649189   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "630 -0.020634 -0.644624 -0.371461  ... -0.641777 -0.519275 -0.629045   \n",
      "631  0.226686 -0.475269 -0.226829  ... -0.727957 -0.236997 -0.561108   \n",
      "632 -0.149776 -0.554114 -0.399625  ... -0.754490 -0.579951 -1.023975   \n",
      "633 -0.166043 -0.461057 -0.157454  ... -0.482963 -0.249518 -0.387550   \n",
      "634  0.046255 -0.377155 -0.187755  ... -0.275802 -0.315289 -0.297133   \n",
      "\n",
      "           93        94        95        96        97        98        99  \n",
      "0    0.058573 -0.576534 -0.440619 -0.091196 -0.363915 -0.228306 -0.612995  \n",
      "1    0.136681 -0.725792 -0.863653 -0.243930 -0.434670 -0.085307 -0.538941  \n",
      "2    0.007748 -0.466442 -0.456711 -0.241428 -0.177486 -0.385864 -0.301036  \n",
      "3   -0.367306 -0.592962 -0.576819  0.301793 -0.512762 -0.391579 -0.319483  \n",
      "4   -0.176557 -0.523346 -0.782027 -0.237194 -0.467468 -0.351924 -0.724318  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "630  0.047112 -0.609682 -0.480451 -0.165262 -0.499361 -0.469660 -0.766601  \n",
      "631 -0.068093 -0.528363 -0.263481  0.065486 -0.293120 -0.094290 -0.263243  \n",
      "632 -0.212726 -0.727958 -0.355690  0.105364 -0.582024 -0.416362 -0.375622  \n",
      "633  0.125964 -0.357339 -0.367140  0.127392 -0.313137 -0.457499 -0.500418  \n",
      "634 -0.245023 -0.540345 -0.561077  0.298135 -0.464394  0.095502 -0.418654  \n",
      "\n",
      "[635 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the reconstructed data to a DataFrame\n",
    "reconstructed_df = pd.DataFrame(reconstructed_new)\n",
    "\n",
    "# Display the first few rows of the reconstructed DataFrame\n",
    "print(pd.DataFrame(x_new))\n",
    "print(reconstructed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0 -0.492125 -0.336018 -0.559723 -0.117003 -0.528587 -0.422723 -0.238075   \n",
      "1 -0.477891 -0.235203 -0.371923 -0.592861 -0.590469 -0.613857 -0.219182   \n",
      "2 -0.435469 -0.260772 -0.145093 -0.541271 -0.148564 -0.380243 -0.062029   \n",
      "3 -0.650563 -0.246841 -0.859602 -0.594107 -0.581299 -0.222427  0.174027   \n",
      "4 -0.787603 -0.127268 -0.829895 -0.702727 -0.654649 -0.169831 -0.160371   \n",
      "\n",
      "        7         8         9    ...       91        92        93        94   \\\n",
      "0 -0.303260 -0.457011 -0.079655  ... -0.505221 -0.772251  0.058573 -0.576534   \n",
      "1 -0.321777 -0.351439 -0.264356  ... -0.746410 -0.501690  0.136681 -0.725792   \n",
      "2 -0.205360 -0.470583 -0.060717  ... -0.341087 -0.440586  0.007748 -0.466442   \n",
      "3  0.155203 -0.487916 -0.597907  ... -0.368406 -0.309678 -0.367306 -0.592962   \n",
      "4 -0.171508 -0.537167 -0.415171  ... -0.350304 -0.649189 -0.176557 -0.523346   \n",
      "\n",
      "        95        96        97        98        99   100  \n",
      "0 -0.440619 -0.091196 -0.363915 -0.228306 -0.612995    1  \n",
      "1 -0.863653 -0.243930 -0.434670 -0.085307 -0.538941    1  \n",
      "2 -0.456711 -0.241428 -0.177486 -0.385864 -0.301036    1  \n",
      "3 -0.576819  0.301793 -0.512762 -0.391579 -0.319483    1  \n",
      "4 -0.782027 -0.237194 -0.467468 -0.351924 -0.724318    1  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "# Add a new column 'Label' with all values set to 1\n",
    "reconstructed_df[100] = 1\n",
    "\n",
    "# Display the first few rows to verify the new column\n",
    "print(reconstructed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623/623 [==============================] - 0s 558us/step\n"
     ]
    }
   ],
   "source": [
    "num_samples_to_generate = 19915  # The number of new rows want to generate\n",
    "\n",
    "# Generate random samples from the latent space\n",
    "latent_dim = 16  # Ensure this matches the latent dimension size of  VAE\n",
    "z_new_samples = np.random.normal(size=(num_samples_to_generate, latent_dim))\n",
    "\n",
    "# Use the decoder to generate new data\n",
    "new_data_generated = vae.decoder.predict(z_new_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.0777221 , -1.0918008 , -0.7030367 , ..., -0.7296246 ,\n",
       "        -0.5811352 , -0.8859711 ],\n",
       "       [-0.3001925 , -0.4287057 , -0.2137387 , ..., -0.5918791 ,\n",
       "        -0.5554475 , -0.8658088 ],\n",
       "       [-0.6815854 , -0.6867297 , -0.5907994 , ..., -0.8811034 ,\n",
       "        -0.44196633, -0.5763391 ],\n",
       "       ...,\n",
       "       [-0.7349929 , -0.82603246, -0.15990685, ..., -0.58413976,\n",
       "        -0.21431829, -0.69971174],\n",
       "       [-0.5471129 , -0.3064836 , -0.53453535, ..., -0.52871704,\n",
       "        -0.28403103, -0.36786234],\n",
       "       [-0.15381911, -0.6186482 , -0.4932994 , ..., -0.60181916,\n",
       "        -0.21477833, -0.7888159 ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the generated data to a DataFrame\n",
    "new_data_df = pd.DataFrame(new_data_generated)\n",
    "\n",
    "# Add a column 'Label' with all values set to 1\n",
    "new_data_df[100] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_df = pd.concat([data_frame, new_data_df], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.033944</td>\n",
       "      <td>-0.027745</td>\n",
       "      <td>0.074366</td>\n",
       "      <td>-0.002091</td>\n",
       "      <td>0.054298</td>\n",
       "      <td>0.063317</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>-0.046714</td>\n",
       "      <td>-0.012891</td>\n",
       "      <td>-0.077753</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.010880e-06</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-6.166932e-07</td>\n",
       "      <td>-7.527073e-07</td>\n",
       "      <td>2.791215e-07</td>\n",
       "      <td>-8.883754e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-7.427837e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.033944</td>\n",
       "      <td>-0.027745</td>\n",
       "      <td>0.074366</td>\n",
       "      <td>-0.002091</td>\n",
       "      <td>0.054298</td>\n",
       "      <td>0.063317</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>-0.046714</td>\n",
       "      <td>-0.012891</td>\n",
       "      <td>-0.077753</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.413894e-02</td>\n",
       "      <td>-0.082139</td>\n",
       "      <td>0.211017</td>\n",
       "      <td>6.760421e-03</td>\n",
       "      <td>-5.197733e-02</td>\n",
       "      <td>4.568656e-02</td>\n",
       "      <td>-1.280104e-01</td>\n",
       "      <td>-0.130348</td>\n",
       "      <td>-7.988450e-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.033944</td>\n",
       "      <td>-0.027745</td>\n",
       "      <td>0.074366</td>\n",
       "      <td>-0.002091</td>\n",
       "      <td>0.054298</td>\n",
       "      <td>0.063317</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>-0.046714</td>\n",
       "      <td>-0.012891</td>\n",
       "      <td>-0.077753</td>\n",
       "      <td>...</td>\n",
       "      <td>2.240346e-03</td>\n",
       "      <td>0.004919</td>\n",
       "      <td>-0.008754</td>\n",
       "      <td>-2.784838e-02</td>\n",
       "      <td>2.779317e-03</td>\n",
       "      <td>-1.460430e-01</td>\n",
       "      <td>1.236033e-01</td>\n",
       "      <td>0.071233</td>\n",
       "      <td>2.409235e-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.033944</td>\n",
       "      <td>-0.027745</td>\n",
       "      <td>0.074366</td>\n",
       "      <td>-0.002091</td>\n",
       "      <td>0.054298</td>\n",
       "      <td>0.063317</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>-0.046714</td>\n",
       "      <td>-0.012891</td>\n",
       "      <td>-0.077753</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.452601e-07</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-5.640821e-07</td>\n",
       "      <td>-6.983902e-07</td>\n",
       "      <td>1.942949e-07</td>\n",
       "      <td>-7.831622e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-7.150177e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.033944</td>\n",
       "      <td>-0.027745</td>\n",
       "      <td>0.074366</td>\n",
       "      <td>-0.002091</td>\n",
       "      <td>0.054298</td>\n",
       "      <td>0.063317</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>-0.046714</td>\n",
       "      <td>-0.012891</td>\n",
       "      <td>-0.077753</td>\n",
       "      <td>...</td>\n",
       "      <td>8.912425e-02</td>\n",
       "      <td>-0.075009</td>\n",
       "      <td>0.164325</td>\n",
       "      <td>-1.113106e-01</td>\n",
       "      <td>-8.748227e-02</td>\n",
       "      <td>-1.467504e-01</td>\n",
       "      <td>-4.673217e-02</td>\n",
       "      <td>-0.011832</td>\n",
       "      <td>3.213240e-02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41095</th>\n",
       "      <td>-0.519155</td>\n",
       "      <td>-0.135045</td>\n",
       "      <td>-0.574430</td>\n",
       "      <td>-0.346728</td>\n",
       "      <td>-0.530469</td>\n",
       "      <td>-0.391611</td>\n",
       "      <td>0.086913</td>\n",
       "      <td>0.038543</td>\n",
       "      <td>-0.538496</td>\n",
       "      <td>-0.446105</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.857168e-01</td>\n",
       "      <td>-0.476790</td>\n",
       "      <td>-0.055436</td>\n",
       "      <td>-3.985401e-01</td>\n",
       "      <td>-6.020269e-01</td>\n",
       "      <td>9.638464e-02</td>\n",
       "      <td>-2.804751e-01</td>\n",
       "      <td>-0.368702</td>\n",
       "      <td>-4.198478e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41096</th>\n",
       "      <td>-0.108699</td>\n",
       "      <td>-0.204299</td>\n",
       "      <td>-0.024243</td>\n",
       "      <td>-0.164217</td>\n",
       "      <td>-0.125962</td>\n",
       "      <td>-0.151479</td>\n",
       "      <td>-0.065604</td>\n",
       "      <td>0.021812</td>\n",
       "      <td>-0.202745</td>\n",
       "      <td>-0.123396</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.359127e-01</td>\n",
       "      <td>-0.095078</td>\n",
       "      <td>-0.015124</td>\n",
       "      <td>-2.674699e-01</td>\n",
       "      <td>-1.799986e-01</td>\n",
       "      <td>1.614631e-03</td>\n",
       "      <td>-1.841585e-01</td>\n",
       "      <td>-0.068155</td>\n",
       "      <td>-1.348069e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41097</th>\n",
       "      <td>-0.734993</td>\n",
       "      <td>-0.826032</td>\n",
       "      <td>-0.159907</td>\n",
       "      <td>-0.886572</td>\n",
       "      <td>-0.457482</td>\n",
       "      <td>-0.812474</td>\n",
       "      <td>0.086447</td>\n",
       "      <td>-0.177162</td>\n",
       "      <td>-0.592399</td>\n",
       "      <td>-0.697786</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.914510e-01</td>\n",
       "      <td>-0.488457</td>\n",
       "      <td>-0.223353</td>\n",
       "      <td>-1.252389e+00</td>\n",
       "      <td>-8.397382e-01</td>\n",
       "      <td>-3.781731e-01</td>\n",
       "      <td>-5.841398e-01</td>\n",
       "      <td>-0.214318</td>\n",
       "      <td>-6.997117e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41098</th>\n",
       "      <td>-0.547113</td>\n",
       "      <td>-0.306484</td>\n",
       "      <td>-0.534535</td>\n",
       "      <td>-0.447887</td>\n",
       "      <td>-0.536975</td>\n",
       "      <td>-0.420732</td>\n",
       "      <td>-0.312824</td>\n",
       "      <td>-0.084043</td>\n",
       "      <td>-0.633664</td>\n",
       "      <td>-0.250730</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.812471e-01</td>\n",
       "      <td>-0.635850</td>\n",
       "      <td>-0.164249</td>\n",
       "      <td>-5.179812e-01</td>\n",
       "      <td>-4.505555e-01</td>\n",
       "      <td>1.035014e-01</td>\n",
       "      <td>-5.287170e-01</td>\n",
       "      <td>-0.284031</td>\n",
       "      <td>-3.678623e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41099</th>\n",
       "      <td>-0.153819</td>\n",
       "      <td>-0.618648</td>\n",
       "      <td>-0.493299</td>\n",
       "      <td>-0.701798</td>\n",
       "      <td>-0.459339</td>\n",
       "      <td>-0.870299</td>\n",
       "      <td>0.024529</td>\n",
       "      <td>-0.348082</td>\n",
       "      <td>-0.657130</td>\n",
       "      <td>-0.734354</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.980737e-01</td>\n",
       "      <td>-0.258009</td>\n",
       "      <td>-0.104662</td>\n",
       "      <td>-1.185357e+00</td>\n",
       "      <td>-7.482116e-01</td>\n",
       "      <td>-2.342473e-01</td>\n",
       "      <td>-6.018192e-01</td>\n",
       "      <td>-0.214778</td>\n",
       "      <td>-7.888159e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41100 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "0     -0.033944 -0.027745  0.074366 -0.002091  0.054298  0.063317  0.002203   \n",
       "1     -0.033944 -0.027745  0.074366 -0.002091  0.054298  0.063317  0.002203   \n",
       "2     -0.033944 -0.027745  0.074366 -0.002091  0.054298  0.063317  0.002203   \n",
       "3     -0.033944 -0.027745  0.074366 -0.002091  0.054298  0.063317  0.002203   \n",
       "4     -0.033944 -0.027745  0.074366 -0.002091  0.054298  0.063317  0.002203   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "41095 -0.519155 -0.135045 -0.574430 -0.346728 -0.530469 -0.391611  0.086913   \n",
       "41096 -0.108699 -0.204299 -0.024243 -0.164217 -0.125962 -0.151479 -0.065604   \n",
       "41097 -0.734993 -0.826032 -0.159907 -0.886572 -0.457482 -0.812474  0.086447   \n",
       "41098 -0.547113 -0.306484 -0.534535 -0.447887 -0.536975 -0.420732 -0.312824   \n",
       "41099 -0.153819 -0.618648 -0.493299 -0.701798 -0.459339 -0.870299  0.024529   \n",
       "\n",
       "            7         8         9    ...           91        92        93   \\\n",
       "0     -0.046714 -0.012891 -0.077753  ... -1.010880e-06 -0.000002 -0.000003   \n",
       "1     -0.046714 -0.012891 -0.077753  ... -8.413894e-02 -0.082139  0.211017   \n",
       "2     -0.046714 -0.012891 -0.077753  ...  2.240346e-03  0.004919 -0.008754   \n",
       "3     -0.046714 -0.012891 -0.077753  ... -8.452601e-07 -0.000002 -0.000002   \n",
       "4     -0.046714 -0.012891 -0.077753  ...  8.912425e-02 -0.075009  0.164325   \n",
       "...         ...       ...       ...  ...           ...       ...       ...   \n",
       "41095  0.038543 -0.538496 -0.446105  ... -2.857168e-01 -0.476790 -0.055436   \n",
       "41096  0.021812 -0.202745 -0.123396  ... -1.359127e-01 -0.095078 -0.015124   \n",
       "41097 -0.177162 -0.592399 -0.697786  ... -6.914510e-01 -0.488457 -0.223353   \n",
       "41098 -0.084043 -0.633664 -0.250730  ... -3.812471e-01 -0.635850 -0.164249   \n",
       "41099 -0.348082 -0.657130 -0.734354  ... -6.980737e-01 -0.258009 -0.104662   \n",
       "\n",
       "                94            95            96            97        98   \\\n",
       "0     -6.166932e-07 -7.527073e-07  2.791215e-07 -8.883754e-07  0.000001   \n",
       "1      6.760421e-03 -5.197733e-02  4.568656e-02 -1.280104e-01 -0.130348   \n",
       "2     -2.784838e-02  2.779317e-03 -1.460430e-01  1.236033e-01  0.071233   \n",
       "3     -5.640821e-07 -6.983902e-07  1.942949e-07 -7.831622e-07  0.000001   \n",
       "4     -1.113106e-01 -8.748227e-02 -1.467504e-01 -4.673217e-02 -0.011832   \n",
       "...             ...           ...           ...           ...       ...   \n",
       "41095 -3.985401e-01 -6.020269e-01  9.638464e-02 -2.804751e-01 -0.368702   \n",
       "41096 -2.674699e-01 -1.799986e-01  1.614631e-03 -1.841585e-01 -0.068155   \n",
       "41097 -1.252389e+00 -8.397382e-01 -3.781731e-01 -5.841398e-01 -0.214318   \n",
       "41098 -5.179812e-01 -4.505555e-01  1.035014e-01 -5.287170e-01 -0.284031   \n",
       "41099 -1.185357e+00 -7.482116e-01 -2.342473e-01 -6.018192e-01 -0.214778   \n",
       "\n",
       "                99   100  \n",
       "0     -7.427837e-07  0.0  \n",
       "1     -7.988450e-02  0.0  \n",
       "2      2.409235e-02  0.0  \n",
       "3     -7.150177e-07  0.0  \n",
       "4      3.213240e-02  0.0  \n",
       "...             ...  ...  \n",
       "41095 -4.198478e-01  1.0  \n",
       "41096 -1.348069e-01  1.0  \n",
       "41097 -6.997117e-01  1.0  \n",
       "41098 -3.678623e-01  1.0  \n",
       "41099 -7.888159e-01  1.0  \n",
       "\n",
       "[41100 rows x 101 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='enhanced_final_new_par_50_space_1.csv'\n",
    "file_path = os.path.join(base_dir,'data','split',ltype, file_name)\n",
    "output_path = file_path\n",
    "enhanced_df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
