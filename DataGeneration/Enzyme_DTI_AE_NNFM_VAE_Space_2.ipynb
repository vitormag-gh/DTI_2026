{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend as K\n",
    "\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def build_encoder(latent_dim=20):\n",
    "    encoder_inputs = layers.Input(shape=(100,)) #change here features*2\n",
    "    x = layers.Dense(256, activation='relu')(encoder_inputs)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    z_mean = layers.Dense(latent_dim)(x)\n",
    "    z_log_var = layers.Dense(latent_dim)(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    encoder = models.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "    return encoder\n",
    "\n",
    "def build_decoder(latent_dim=20):\n",
    "    latent_inputs = layers.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(64, activation='relu')(latent_inputs)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    decoder_outputs = layers.Dense(100, activation='linear')(x) #change here features*2\n",
    "    decoder = models.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "    return decoder\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        # Initialize trackers for monitoring losses\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # Return list of metrics to be updated during training\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(z)\n",
    "        # Compute KL divergence loss even during inference to track loss correctly\n",
    "        kl_loss = -0.5 * tf.reduce_mean(\n",
    "            1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\n",
    "        # Only add KL loss during training\n",
    "        if training:\n",
    "            self.add_loss(kl_loss)\n",
    "        return reconstructed\n",
    "\n",
    "    def train_step(self, data):\n",
    "    # Unpack the data\n",
    "        x = data[0] if isinstance(data, tuple) else data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(x, training=True)\n",
    "            reconstruction = self.decoder(z, training=True)\n",
    "\n",
    "            # If  data is flat (e.g., shape=(batch_size, features)), adjust axis accordingly\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(x, reconstruction), axis=-1\n",
    "            )\n",
    "            reconstruction_loss = tf.reduce_sum(reconstruction_loss)  # Sum over all dimensions\n",
    "\n",
    "            kl_loss = -0.5 * tf.reduce_mean(\n",
    "                1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1\n",
    "            )\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        return {'loss': total_loss, 'reconstruction_loss': reconstruction_loss, 'kl_loss': kl_loss}\n",
    "\n",
    "# Example usage:\n",
    "latent_dim = 16  \n",
    "encoder = build_encoder(latent_dim)\n",
    "decoder = build_decoder(latent_dim)\n",
    "vae = VAE(encoder, decoder)\n",
    "#vae.compile(optimizer='adam')\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relative paths. # Set directory paths for later use.\n",
    "# Get the directory of the script file\n",
    "base_dir = os.getcwd()\n",
    "base_dir\n",
    "ligants_type=['enzyme','GPCR','ion_channel','nuclear_receptor']\n",
    "ltype=ligants_type[0]\n",
    "file_name='final_new_par_NNMF_50.csv'\n",
    "file_path = os.path.join(base_dir,'data','split',ltype, file_name)\n",
    "output_path = file_path\n",
    "data_frame = pd.read_csv(file_path, header=None, skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include instances with label 1 (interactions)\n",
    "# Separate features and labels\n",
    "filtered_df = data_frame[data_frame.iloc[:, -1] == 1]  # All rows, all columns except the last one\n",
    "features_new = filtered_df.iloc[:, :-1]     # All rows, just the last column\n",
    "\n",
    "# Convert features DataFrame to a NumPy array if necessary\n",
    "x_train = features_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para\n",
    "epochs=4\n",
    "batch_size=77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "38/38 [==============================] - 1s 1ms/step - loss: 0.3117 - reconstruction_loss: 0.1826 - kl_loss: 0.0178\n",
      "Epoch 2/4\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2249 - reconstruction_loss: 0.2614 - kl_loss: 0.0252\n",
      "Epoch 3/4\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.2138 - reconstruction_loss: 0.1997 - kl_loss: 0.0265\n",
      "Epoch 4/4\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.1924 - reconstruction_loss: 0.1228 - kl_loss: 0.0496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c01f7edf60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "vae.fit(x_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include instances with label 1 (interactions)\n",
    "filtered_df = data_frame[data_frame.iloc[:, -1] == 1]\n",
    "\n",
    "# Separate features\n",
    "features_new = filtered_df.iloc[:, :-1]  # Assuming the last column is the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = features_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 665us/step\n"
     ]
    }
   ],
   "source": [
    "z_mean, z_log_var, z = vae.encoder.predict(x_new)\n",
    "# Now, z contains the latent representations of  filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 707us/step\n"
     ]
    }
   ],
   "source": [
    "reconstructed_new = vae.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2    3    4    5    6    7    8         9   ...        90  \\\n",
      "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.000000   \n",
      "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  5.110435   \n",
      "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.000000   \n",
      "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.000000   \n",
      "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.014562  ...  0.000000   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...       ...  ...       ...   \n",
      "2921  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.000000   \n",
      "2922  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.000000   \n",
      "2923  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.000000   \n",
      "2924  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.120670  ...  0.000000   \n",
      "2925  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.000000   \n",
      "\n",
      "       91   92        93        94        95   96   97   98   99  \n",
      "0     0.0  0.0  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  \n",
      "1     0.0  0.0  0.849574  0.000000  0.000000  0.0  0.0  0.0  0.0  \n",
      "2     0.0  0.0  0.000000  6.779612  0.000000  0.0  0.0  0.0  0.0  \n",
      "3     0.0  0.0  0.000000  0.672785  0.000000  0.0  0.0  0.0  0.0  \n",
      "4     0.0  0.0  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  \n",
      "...   ...  ...       ...       ...       ...  ...  ...  ...  ...  \n",
      "2921  0.0  0.0  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  \n",
      "2922  0.0  0.0  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  \n",
      "2923  0.0  0.0  0.000000  0.000000  1.762979  0.0  0.0  0.0  0.0  \n",
      "2924  0.0  0.0  0.000000  0.000000  0.000000  0.0  0.0  0.0  0.0  \n",
      "2925  0.0  0.0  0.000000  6.779612  0.000000  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[2926 rows x 100 columns]\n",
      "            0         1         2         3         4         5         6   \\\n",
      "0     0.695677  0.143632  0.117471 -0.020689  0.185663 -0.385531  0.213294   \n",
      "1     0.988414  0.090808  0.054008  0.002988  0.229224 -0.401676  0.287895   \n",
      "2     0.337309 -0.027988  0.121742 -0.104274  0.147242 -0.251802  0.198055   \n",
      "3     0.471478 -0.304712  0.288216 -0.268586  0.236000 -0.488064  0.332048   \n",
      "4     0.437947 -0.045382 -0.028887 -0.082802  0.237653 -0.336536  0.162202   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2921  0.257533 -0.192996  0.244204 -0.283125  0.204233 -0.487042  0.372369   \n",
      "2922  1.048447 -0.279164 -0.045439 -0.116498  0.418280 -0.602342  0.369415   \n",
      "2923  1.225567 -0.543773  0.140784 -0.119641  0.271342 -0.656345  0.398260   \n",
      "2924  1.761069 -0.055964  0.107031 -0.075057  0.297054 -0.867410  0.371170   \n",
      "2925  1.047842  0.036709 -0.040327  0.069947  0.075124 -0.454183  0.053697   \n",
      "\n",
      "            7         8         9   ...        90        91        92  \\\n",
      "0    -0.448035 -0.022585 -0.429457  ... -0.355101 -0.343178 -0.423867   \n",
      "1    -0.399467  0.009779 -0.375494  ... -0.330830 -0.434709 -0.358744   \n",
      "2    -0.302448 -0.023633 -0.365933  ... -0.285548 -0.216432 -0.279205   \n",
      "3    -0.364924  0.026968 -0.442159  ... -0.356535 -0.476634 -0.081738   \n",
      "4    -0.423634  0.146821 -0.298812  ... -0.302045 -0.377484 -0.390980   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "2921 -0.381444 -0.056490 -0.665068  ... -0.460004 -0.474092 -0.330882   \n",
      "2922 -0.746287  0.374125 -0.568914  ... -0.347569 -0.970402 -0.836535   \n",
      "2923 -0.457801  0.182555 -0.887283  ... -0.552374 -0.819456 -0.423158   \n",
      "2924 -0.658941  0.380544 -0.645705  ... -0.447907 -0.411144 -0.777539   \n",
      "2925 -0.329540  0.096694 -0.285948  ... -0.267270 -0.493558 -0.336857   \n",
      "\n",
      "            93        94        95        96        97        98        99  \n",
      "0    -0.250233 -0.036870 -0.400625 -0.270881 -0.072996 -0.643338 -0.572974  \n",
      "1    -0.236484 -0.084229 -0.393228 -0.236083  0.285189 -0.592090 -0.853428  \n",
      "2    -0.169452 -0.192790 -0.229125 -0.236600 -0.007782 -0.430663 -0.401046  \n",
      "3    -0.026328 -0.290690 -0.495179 -0.365658 -0.034142 -0.289519 -0.567626  \n",
      "4    -0.154023  0.029324 -0.329013 -0.412313  0.065380 -0.329488 -0.609693  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "2921 -0.215079 -0.588198 -0.433650 -0.676315 -0.050370 -0.466696 -0.497991  \n",
      "2922 -0.003755  0.037171 -0.565976 -0.658265  0.153767 -0.646241 -0.929906  \n",
      "2923 -0.266597 -0.403270 -0.699598 -0.301759  0.369520 -1.069612 -1.186870  \n",
      "2924 -0.177532 -0.436217 -1.097869 -0.702629  0.022421 -0.999275 -0.827581  \n",
      "2925 -0.124073 -0.222058 -0.470821 -0.216910  0.098113 -0.567524 -0.694300  \n",
      "\n",
      "[2926 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the reconstructed data to a DataFrame\n",
    "reconstructed_df = pd.DataFrame(reconstructed_new)\n",
    "\n",
    "# Display the first few rows of the reconstructed DataFrame\n",
    "print(pd.DataFrame(x_new))\n",
    "print(reconstructed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0  0.695677  0.143632  0.117471 -0.020689  0.185663 -0.385531  0.213294   \n",
      "1  0.988414  0.090808  0.054008  0.002988  0.229224 -0.401676  0.287895   \n",
      "2  0.337309 -0.027988  0.121742 -0.104274  0.147242 -0.251802  0.198055   \n",
      "3  0.471478 -0.304712  0.288216 -0.268586  0.236000 -0.488064  0.332048   \n",
      "4  0.437947 -0.045382 -0.028887 -0.082802  0.237653 -0.336536  0.162202   \n",
      "\n",
      "        7         8         9    ...       91        92        93        94   \\\n",
      "0 -0.448035 -0.022585 -0.429457  ... -0.343178 -0.423867 -0.250233 -0.036870   \n",
      "1 -0.399467  0.009779 -0.375494  ... -0.434709 -0.358744 -0.236484 -0.084229   \n",
      "2 -0.302448 -0.023633 -0.365933  ... -0.216432 -0.279205 -0.169452 -0.192790   \n",
      "3 -0.364924  0.026968 -0.442159  ... -0.476634 -0.081738 -0.026328 -0.290690   \n",
      "4 -0.423634  0.146821 -0.298812  ... -0.377484 -0.390980 -0.154023  0.029324   \n",
      "\n",
      "        95        96        97        98        99   100  \n",
      "0 -0.400625 -0.270881 -0.072996 -0.643338 -0.572974    1  \n",
      "1 -0.393228 -0.236083  0.285189 -0.592090 -0.853428    1  \n",
      "2 -0.229125 -0.236600 -0.007782 -0.430663 -0.401046    1  \n",
      "3 -0.495179 -0.365658 -0.034142 -0.289519 -0.567626    1  \n",
      "4 -0.329013 -0.412313  0.065380 -0.329488 -0.609693    1  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "# Add a new column 'Label' with all values set to 1\n",
    "reconstructed_df[100] = 1\n",
    "\n",
    "# Display the first few rows to verify the new column\n",
    "print(reconstructed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9051/9051 [==============================] - 5s 550us/step\n"
     ]
    }
   ],
   "source": [
    "num_samples_to_generate = 289628  \n",
    "\n",
    "# Generate random samples from the latent space\n",
    "latent_dim = 16  # Ensure this matches the latent dimension size of  VAE\n",
    "z_new_samples = np.random.normal(size=(num_samples_to_generate, latent_dim))\n",
    "\n",
    "# Use the decoder to generate new data\n",
    "new_data_generated = vae.decoder.predict(z_new_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9531993 ,  0.61610764,  0.00503654, ...,  0.1134003 ,\n",
       "        -0.60187966, -1.0281173 ],\n",
       "       [ 0.5137695 , -0.15900362,  0.14083761, ..., -0.17476079,\n",
       "        -0.6424307 , -0.8401363 ],\n",
       "       [ 0.60779315, -0.0601043 ,  0.08108652, ..., -0.0283568 ,\n",
       "        -0.22836436, -0.4427022 ],\n",
       "       ...,\n",
       "       [ 0.78120357, -0.12632771,  0.16767126, ..., -0.07107446,\n",
       "        -0.5062637 , -0.73861045],\n",
       "       [ 0.82661325, -0.0308955 ,  0.05064399, ...,  0.12419126,\n",
       "        -0.46481034, -0.61822397],\n",
       "       [ 0.9942495 ,  0.4230418 , -0.0245189 , ...,  0.07805028,\n",
       "        -0.748095  , -0.6321356 ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the generated data to a DataFrame\n",
    "new_data_df = pd.DataFrame(new_data_generated)\n",
    "\n",
    "# Add a column 'Label' with all values set to 1\n",
    "new_data_df[100] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_df = pd.concat([data_frame, new_data_df], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.947743</td>\n",
       "      <td>7.487351e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.729715e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146746</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.080936e-215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585103</th>\n",
       "      <td>0.706367</td>\n",
       "      <td>0.162674</td>\n",
       "      <td>-0.028344</td>\n",
       "      <td>-0.201966</td>\n",
       "      <td>0.289283</td>\n",
       "      <td>-0.404519</td>\n",
       "      <td>0.290795</td>\n",
       "      <td>-0.419304</td>\n",
       "      <td>0.144264</td>\n",
       "      <td>-0.432503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.471380</td>\n",
       "      <td>-3.131129e-01</td>\n",
       "      <td>-0.068906</td>\n",
       "      <td>-0.048637</td>\n",
       "      <td>-0.361918</td>\n",
       "      <td>-0.510515</td>\n",
       "      <td>-0.136898</td>\n",
       "      <td>-0.567991</td>\n",
       "      <td>-0.638304</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585104</th>\n",
       "      <td>0.407153</td>\n",
       "      <td>0.130907</td>\n",
       "      <td>0.150620</td>\n",
       "      <td>-0.121162</td>\n",
       "      <td>0.186471</td>\n",
       "      <td>-0.317278</td>\n",
       "      <td>0.270852</td>\n",
       "      <td>-0.235071</td>\n",
       "      <td>0.012905</td>\n",
       "      <td>-0.402576</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.161271</td>\n",
       "      <td>-2.821451e-01</td>\n",
       "      <td>-0.352899</td>\n",
       "      <td>-0.239710</td>\n",
       "      <td>-0.344966</td>\n",
       "      <td>-0.229304</td>\n",
       "      <td>0.084699</td>\n",
       "      <td>-0.364441</td>\n",
       "      <td>-0.625612</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585105</th>\n",
       "      <td>0.781204</td>\n",
       "      <td>-0.126328</td>\n",
       "      <td>0.167671</td>\n",
       "      <td>-0.221109</td>\n",
       "      <td>0.339594</td>\n",
       "      <td>-0.211090</td>\n",
       "      <td>0.253513</td>\n",
       "      <td>-0.476060</td>\n",
       "      <td>-0.017334</td>\n",
       "      <td>-0.536464</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.438001</td>\n",
       "      <td>-5.053270e-01</td>\n",
       "      <td>-0.061797</td>\n",
       "      <td>-0.620700</td>\n",
       "      <td>-0.496545</td>\n",
       "      <td>-0.689555</td>\n",
       "      <td>-0.071074</td>\n",
       "      <td>-0.506264</td>\n",
       "      <td>-0.738610</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585106</th>\n",
       "      <td>0.826613</td>\n",
       "      <td>-0.030895</td>\n",
       "      <td>0.050644</td>\n",
       "      <td>-0.342844</td>\n",
       "      <td>0.250680</td>\n",
       "      <td>-0.398355</td>\n",
       "      <td>0.357057</td>\n",
       "      <td>-0.213522</td>\n",
       "      <td>0.134193</td>\n",
       "      <td>-0.406385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.443432</td>\n",
       "      <td>-3.193145e-01</td>\n",
       "      <td>-0.201415</td>\n",
       "      <td>-0.416608</td>\n",
       "      <td>-0.600299</td>\n",
       "      <td>-0.513583</td>\n",
       "      <td>0.124191</td>\n",
       "      <td>-0.464810</td>\n",
       "      <td>-0.618224</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585107</th>\n",
       "      <td>0.994250</td>\n",
       "      <td>0.423042</td>\n",
       "      <td>-0.024519</td>\n",
       "      <td>-0.121068</td>\n",
       "      <td>0.291400</td>\n",
       "      <td>-0.715510</td>\n",
       "      <td>0.283183</td>\n",
       "      <td>-0.497423</td>\n",
       "      <td>0.220790</td>\n",
       "      <td>-0.594443</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.374175</td>\n",
       "      <td>-4.170076e-01</td>\n",
       "      <td>-0.111092</td>\n",
       "      <td>-0.438345</td>\n",
       "      <td>-0.588395</td>\n",
       "      <td>-0.845956</td>\n",
       "      <td>0.078050</td>\n",
       "      <td>-0.748095</td>\n",
       "      <td>-0.632136</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>585108 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6    \\\n",
       "0       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "585103  0.706367  0.162674 -0.028344 -0.201966  0.289283 -0.404519  0.290795   \n",
       "585104  0.407153  0.130907  0.150620 -0.121162  0.186471 -0.317278  0.270852   \n",
       "585105  0.781204 -0.126328  0.167671 -0.221109  0.339594 -0.211090  0.253513   \n",
       "585106  0.826613 -0.030895  0.050644 -0.342844  0.250680 -0.398355  0.357057   \n",
       "585107  0.994250  0.423042 -0.024519 -0.121068  0.291400 -0.715510  0.283183   \n",
       "\n",
       "             7         8         9    ...       91             92        93   \\\n",
       "0       0.000000  0.000000  0.000000  ...  0.000000   0.000000e+00  0.000000   \n",
       "1       0.000000  0.000000  0.000000  ...  1.947743   7.487351e-03  0.000000   \n",
       "2       0.000000  0.000000  0.000000  ...  0.000000   3.729715e-02  0.000000   \n",
       "3       0.000000  0.000000  0.000000  ...  0.146746   0.000000e+00  0.000000   \n",
       "4       0.000000  0.000000  0.000000  ...  0.000000  1.080936e-215  0.000000   \n",
       "...          ...       ...       ...  ...       ...            ...       ...   \n",
       "585103 -0.419304  0.144264 -0.432503  ... -0.471380  -3.131129e-01 -0.068906   \n",
       "585104 -0.235071  0.012905 -0.402576  ... -0.161271  -2.821451e-01 -0.352899   \n",
       "585105 -0.476060 -0.017334 -0.536464  ... -0.438001  -5.053270e-01 -0.061797   \n",
       "585106 -0.213522  0.134193 -0.406385  ... -0.443432  -3.193145e-01 -0.201415   \n",
       "585107 -0.497423  0.220790 -0.594443  ... -0.374175  -4.170076e-01 -0.111092   \n",
       "\n",
       "             94        95        96        97        98        99   100  \n",
       "0       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  1.0  \n",
       "1       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  \n",
       "2       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  \n",
       "3       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  \n",
       "4       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  \n",
       "...          ...       ...       ...       ...       ...       ...  ...  \n",
       "585103 -0.048637 -0.361918 -0.510515 -0.136898 -0.567991 -0.638304  1.0  \n",
       "585104 -0.239710 -0.344966 -0.229304  0.084699 -0.364441 -0.625612  1.0  \n",
       "585105 -0.620700 -0.496545 -0.689555 -0.071074 -0.506264 -0.738610  1.0  \n",
       "585106 -0.416608 -0.600299 -0.513583  0.124191 -0.464810 -0.618224  1.0  \n",
       "585107 -0.438345 -0.588395 -0.845956  0.078050 -0.748095 -0.632136  1.0  \n",
       "\n",
       "[585108 rows x 101 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='enhanced_VAE_final_new_par_50_NNFM_space_2.csv'\n",
    "file_path = os.path.join(base_dir,'data','split',ltype, file_name)\n",
    "output_path = file_path\n",
    "enhanced_df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
