{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend as K\n",
    "\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def build_encoder(latent_dim=20):\n",
    "    encoder_inputs = layers.Input(shape=(100,)) #change here features*2\n",
    "    x = layers.Dense(256, activation='relu')(encoder_inputs)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    z_mean = layers.Dense(latent_dim)(x)\n",
    "    z_log_var = layers.Dense(latent_dim)(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    encoder = models.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "    return encoder\n",
    "\n",
    "def build_decoder(latent_dim=20):\n",
    "    latent_inputs = layers.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(64, activation='relu')(latent_inputs)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    decoder_outputs = layers.Dense(100, activation='linear')(x) #change here features*2\n",
    "    decoder = models.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "    return decoder\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        # Initialize trackers for monitoring losses\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # Return list of metrics to be updated during training\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(z)\n",
    "        # Compute KL divergence loss even during inference to track loss correctly\n",
    "        kl_loss = -0.5 * tf.reduce_mean(\n",
    "            1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\n",
    "        # Only add KL loss during training\n",
    "        if training:\n",
    "            self.add_loss(kl_loss)\n",
    "        return reconstructed\n",
    "\n",
    "    def train_step(self, data):\n",
    "    # Unpack the data\n",
    "        x = data[0] if isinstance(data, tuple) else data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(x, training=True)\n",
    "            reconstruction = self.decoder(z, training=True)\n",
    "\n",
    "            # If data is flat (e.g., shape=(batch_size, features)), adjust axis accordingly\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(x, reconstruction), axis=-1\n",
    "            )\n",
    "            reconstruction_loss = tf.reduce_sum(reconstruction_loss)  # Sum over all dimensions\n",
    "\n",
    "            kl_loss = -0.5 * tf.reduce_mean(\n",
    "                1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1\n",
    "            )\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        return {'loss': total_loss, 'reconstruction_loss': reconstruction_loss, 'kl_loss': kl_loss}\n",
    "\n",
    "# Example usage:\n",
    "latent_dim = 16  \n",
    "encoder = build_encoder(latent_dim)\n",
    "decoder = build_decoder(latent_dim)\n",
    "vae = VAE(encoder, decoder)\n",
    "#vae.compile(optimizer='adam')\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relative paths. # Set directory paths for later use.\n",
    "# Get the directory of the script file\n",
    "base_dir = os.getcwd()\n",
    "base_dir\n",
    "ligants_type=['enzyme','GPCR','ion_channel','nuclear_receptor']\n",
    "ltype=ligants_type[0]\n",
    "file_name='final_new_par_LMF_50.csv'\n",
    "file_path = os.path.join(base_dir,'data','split',ltype, file_name)\n",
    "output_path = file_path\n",
    "data_frame = pd.read_csv(file_path, header=None, skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include instances with label 1 (interactions)\n",
    "# Separate features and labels\n",
    "filtered_df = data_frame[data_frame.iloc[:, -1] == 1]  # All rows, all columns except the last one\n",
    "features_new = filtered_df.iloc[:, :-1]     # All rows, just the last column\n",
    "\n",
    "# Convert features DataFrame to a NumPy array if necessary\n",
    "x_train = features_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para\n",
    "epochs=4\n",
    "batch_size=77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "38/38 [==============================] - 1s 2ms/step - loss: -2.2365 - reconstruction_loss: -2.7872 - kl_loss: 0.1030\n",
      "Epoch 2/4\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -2.9018 - reconstruction_loss: -2.6394 - kl_loss: 0.0451\n",
      "Epoch 3/4\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -2.9901 - reconstruction_loss: -3.0472 - kl_loss: 0.0569\n",
      "Epoch 4/4\n",
      "38/38 [==============================] - 0s 2ms/step - loss: -2.9756 - reconstruction_loss: -2.8316 - kl_loss: 0.0294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2139e13e0e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "vae.fit(x_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include instances with label 1 (interactions)\n",
    "filtered_df = data_frame[data_frame.iloc[:, -1] == 1]\n",
    "\n",
    "# Separate features\n",
    "features_new = filtered_df.iloc[:, :-1]  # Assuming the last column is the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = features_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 681us/step\n"
     ]
    }
   ],
   "source": [
    "z_mean, z_log_var, z = vae.encoder.predict(x_new)\n",
    "# Now, z contains the latent representations of  filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 793us/step\n"
     ]
    }
   ],
   "source": [
    "reconstructed_new = vae.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6   \\\n",
      "0     0.378580  0.279222  0.529452  0.224391  0.269244  0.288321  0.116587   \n",
      "1     0.378580  0.279222  0.529452  0.224391  0.269244  0.288321  0.116587   \n",
      "2     0.191642  0.174801  0.150674  0.324245  0.216482  0.277361  0.236950   \n",
      "3     0.191642  0.174801  0.150674  0.324245  0.216482  0.277361  0.236950   \n",
      "4     0.234871  0.244009  0.164632  0.376041  0.268878  0.334274  0.310694   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2921  0.457356  0.257199  0.352959  0.327653  0.473576  0.241599  0.613059   \n",
      "2922  0.457356  0.257199  0.352959  0.327653  0.473576  0.241599  0.613059   \n",
      "2923  0.256248  0.247317  0.186627  0.386409  0.290559  0.357915  0.350838   \n",
      "2924  0.250683  0.227646  0.241334  0.399093  0.316098  0.338614  0.326268   \n",
      "2925  0.233042  0.225892  0.219956  0.389313  0.257460  0.331327  0.301114   \n",
      "\n",
      "            7         8         9   ...        90        91        92  \\\n",
      "0     0.395598  0.339238  0.202399  ... -1.031617 -0.640229  0.179676   \n",
      "1     0.395598  0.339238  0.202399  ...  0.112434 -0.431153 -0.561669   \n",
      "2     0.320837  0.291000  0.322254  ... -0.151033 -0.406258 -0.092095   \n",
      "3     0.320837  0.291000  0.322254  ... -0.349944 -0.402142 -0.407144   \n",
      "4     0.376568  0.340823  0.361991  ... -0.205098 -0.299336 -0.223911   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "2921  0.145035  0.489153  0.557131  ...  0.182035 -0.376902  1.224116   \n",
      "2922  0.145035  0.489153  0.557131  ...  0.172680 -0.430923  1.096196   \n",
      "2923  0.413941  0.348874  0.402187  ... -0.100347 -0.249872 -0.075303   \n",
      "2924  0.399644  0.374313  0.390525  ... -0.151165 -0.207984 -0.046090   \n",
      "2925  0.395430  0.363506  0.410178  ... -0.151033 -0.406258 -0.092095   \n",
      "\n",
      "            93        94        95        96        97        98        99  \n",
      "0    -0.025780  0.637873 -0.032854 -0.968462  0.351491 -0.433654  0.828018  \n",
      "1    -0.033590 -0.637070 -0.149181 -0.100162 -0.603995 -0.504309 -0.215885  \n",
      "2    -0.351306 -0.345280 -0.215277 -0.363889 -0.439094 -0.241523 -0.277523  \n",
      "3    -0.386393 -0.527521 -0.435643 -0.481570 -0.537215 -0.463025 -0.496404  \n",
      "4    -0.280423 -0.322314 -0.173082 -0.283569 -0.390914 -0.266025 -0.347591  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "2921  0.045993  0.437521  1.577083  0.219283 -2.002779  0.007501  0.239382  \n",
      "2922  0.033826  0.281679  1.390661  0.119657 -1.977922 -0.059671  0.166430  \n",
      "2923 -0.279952 -0.188202 -0.079253 -0.196540 -0.403111 -0.189214 -0.226959  \n",
      "2924 -0.200557 -0.109273 -0.119865 -0.248225 -0.367662 -0.187840 -0.368512  \n",
      "2925 -0.351306 -0.345280 -0.215277 -0.363889 -0.439094 -0.241523 -0.277523  \n",
      "\n",
      "[2926 rows x 100 columns]\n",
      "            0         1         2         3         4         5         6   \\\n",
      "0     0.233711  0.824533 -0.361689  0.213427  0.176328  0.361833  0.237922   \n",
      "1     0.157646  0.453922 -0.714357  0.419542  0.153146  0.225082  0.183694   \n",
      "2     0.203672  0.346812 -0.238632  0.300500  0.167312  0.252384  0.288623   \n",
      "3     0.413539  0.252494 -0.331688  0.291488  0.244147  0.382248  0.385660   \n",
      "4    -0.183347  0.544884 -0.565753  0.478404  0.154922  0.333349  0.255030   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2921  0.143053  0.370152 -0.108078  0.447632  0.291347  0.335902  0.237821   \n",
      "2922  0.260215  0.690719 -0.507149  0.536305  0.392717  0.458167  0.267335   \n",
      "2923  0.051809  0.219580 -0.415300  0.291638  0.307391  0.444492  0.267589   \n",
      "2924  0.199063  0.336721 -0.542108  0.249703  0.214065  0.252834  0.367116   \n",
      "2925  0.229608  0.266714 -0.310704  0.225384  0.359841  0.242556  0.190864   \n",
      "\n",
      "            7         8         9   ...        90        91        92  \\\n",
      "0     0.275631  0.469756  0.133133  ... -0.628109 -0.616203 -0.646469   \n",
      "1     0.335473  0.343401  0.396220  ... -0.543594 -0.590101 -0.692909   \n",
      "2     0.340246  0.256751  0.368965  ... -0.322527 -0.391984 -0.357546   \n",
      "3     0.657324  0.326355  0.214861  ... -0.386212 -0.302604 -0.796272   \n",
      "4     0.552091  0.475044  0.406952  ... -0.407168 -0.880203 -0.819833   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "2921  0.352774  0.355795  0.219577  ... -0.233424 -0.508413 -0.638326   \n",
      "2922  0.385274  0.479937  0.416940  ... -0.789077 -0.253522 -0.321376   \n",
      "2923  0.471216  0.290066  0.255014  ... -0.316226 -0.471147 -0.689415   \n",
      "2924  0.523380  0.221961  0.182721  ... -0.429537 -0.462694 -0.620925   \n",
      "2925  0.420697  0.171635  0.230975  ... -0.165006 -0.371507 -0.411834   \n",
      "\n",
      "            93        94        95        96        97        98        99  \n",
      "0    -0.442575 -0.580871 -0.325056 -0.352904 -0.017499 -0.423901 -0.293411  \n",
      "1    -0.577921 -0.501927 -0.485553 -0.368178 -0.127511 -0.314112 -0.657222  \n",
      "2    -0.317578 -0.278554 -0.317327 -0.454755 -0.342924 -0.130255 -0.305346  \n",
      "3    -0.494969 -0.351633 -0.483819 -0.577523 -0.426259 -0.498191 -0.345922  \n",
      "4    -0.505979 -0.240180 -0.933755 -0.670747 -0.517725 -0.703706 -0.630669  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "2921 -0.442773 -0.463739 -0.560406 -0.342646 -0.506065 -0.604247 -0.412892  \n",
      "2922 -0.630667 -0.182650 -0.367744 -0.452997 -0.325607 -0.728279 -0.746963  \n",
      "2923 -0.502270 -0.246268 -0.674538 -0.489273 -0.551127 -0.397295 -0.311155  \n",
      "2924 -0.630475 -0.556670 -0.317340 -0.484982 -0.320582 -0.405618 -0.404864  \n",
      "2925 -0.188864 -0.264407 -0.278321 -0.449501 -0.339741 -0.287752 -0.267721  \n",
      "\n",
      "[2926 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the reconstructed data to a DataFrame\n",
    "reconstructed_df = pd.DataFrame(reconstructed_new)\n",
    "\n",
    "# Display the first few rows of the reconstructed DataFrame\n",
    "print(pd.DataFrame(x_new))\n",
    "print(reconstructed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0  0.233711  0.824533 -0.361689  0.213427  0.176328  0.361833  0.237922   \n",
      "1  0.157646  0.453922 -0.714357  0.419542  0.153146  0.225082  0.183694   \n",
      "2  0.203672  0.346812 -0.238632  0.300500  0.167312  0.252384  0.288623   \n",
      "3  0.413539  0.252494 -0.331688  0.291488  0.244147  0.382248  0.385660   \n",
      "4 -0.183347  0.544884 -0.565753  0.478404  0.154922  0.333349  0.255030   \n",
      "\n",
      "        7         8         9    ...       91        92        93        94   \\\n",
      "0  0.275631  0.469756  0.133133  ... -0.616203 -0.646469 -0.442575 -0.580871   \n",
      "1  0.335473  0.343401  0.396220  ... -0.590101 -0.692909 -0.577921 -0.501927   \n",
      "2  0.340246  0.256751  0.368965  ... -0.391984 -0.357546 -0.317578 -0.278554   \n",
      "3  0.657324  0.326355  0.214861  ... -0.302604 -0.796272 -0.494969 -0.351633   \n",
      "4  0.552091  0.475044  0.406952  ... -0.880203 -0.819833 -0.505979 -0.240180   \n",
      "\n",
      "        95        96        97        98        99   100  \n",
      "0 -0.325056 -0.352904 -0.017499 -0.423901 -0.293411    1  \n",
      "1 -0.485553 -0.368178 -0.127511 -0.314112 -0.657222    1  \n",
      "2 -0.317327 -0.454755 -0.342924 -0.130255 -0.305346    1  \n",
      "3 -0.483819 -0.577523 -0.426259 -0.498191 -0.345922    1  \n",
      "4 -0.933755 -0.670747 -0.517725 -0.703706 -0.630669    1  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "# Add a new column 'Label' with all values set to 1\n",
    "reconstructed_df[100] = 1\n",
    "\n",
    "# Display the first few rows to verify the new column\n",
    "print(reconstructed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9051/9051 [==============================] - 5s 587us/step\n"
     ]
    }
   ],
   "source": [
    "num_samples_to_generate = 289628  # The number of new rows want to generate\n",
    "\n",
    "# Generate random samples from the latent space\n",
    "latent_dim = 16  # Ensure this matches the latent dimension size of  VAE\n",
    "z_new_samples = np.random.normal(size=(num_samples_to_generate, latent_dim))\n",
    "\n",
    "# Use the decoder to generate new data\n",
    "new_data_generated = vae.decoder.predict(z_new_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09607969,  0.47993645, -0.23520415, ..., -0.37171686,\n",
       "        -0.48678243, -0.42768505],\n",
       "       [ 0.18671435,  0.42267683, -0.5109693 , ..., -0.2641505 ,\n",
       "        -0.36249384, -0.18440033],\n",
       "       [ 0.47839245,  0.2465533 , -0.58737195, ..., -0.4443998 ,\n",
       "        -0.49874362, -0.48620078],\n",
       "       ...,\n",
       "       [ 0.16239291,  0.42153484, -0.80414003, ..., -0.20427476,\n",
       "        -0.45685947, -0.5756828 ],\n",
       "       [ 0.16119185,  0.5059398 , -0.43641225, ..., -0.2997183 ,\n",
       "        -0.15366216, -0.39828062],\n",
       "       [ 0.6129894 ,  0.28827775, -0.5283671 , ..., -0.48132578,\n",
       "        -0.30079854, -0.4160057 ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the generated data to a DataFrame\n",
    "new_data_df = pd.DataFrame(new_data_generated)\n",
    "\n",
    "# Add a column 'Label' with all values set to 1\n",
    "new_data_df[100] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_df = pd.concat([data_frame, new_data_df], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.378580</td>\n",
       "      <td>0.279222</td>\n",
       "      <td>0.529452</td>\n",
       "      <td>0.224391</td>\n",
       "      <td>0.269244</td>\n",
       "      <td>0.288321</td>\n",
       "      <td>0.116587</td>\n",
       "      <td>0.395598</td>\n",
       "      <td>0.339238</td>\n",
       "      <td>0.202399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.640229</td>\n",
       "      <td>0.179676</td>\n",
       "      <td>-0.025780</td>\n",
       "      <td>0.637873</td>\n",
       "      <td>-0.032854</td>\n",
       "      <td>-0.968462</td>\n",
       "      <td>0.351491</td>\n",
       "      <td>-0.433654</td>\n",
       "      <td>0.828018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.378580</td>\n",
       "      <td>0.279222</td>\n",
       "      <td>0.529452</td>\n",
       "      <td>0.224391</td>\n",
       "      <td>0.269244</td>\n",
       "      <td>0.288321</td>\n",
       "      <td>0.116587</td>\n",
       "      <td>0.395598</td>\n",
       "      <td>0.339238</td>\n",
       "      <td>0.202399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038291</td>\n",
       "      <td>0.038372</td>\n",
       "      <td>-0.141714</td>\n",
       "      <td>-0.202433</td>\n",
       "      <td>-0.500281</td>\n",
       "      <td>-0.184908</td>\n",
       "      <td>-0.386320</td>\n",
       "      <td>-0.435208</td>\n",
       "      <td>-0.225072</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.378580</td>\n",
       "      <td>0.279222</td>\n",
       "      <td>0.529452</td>\n",
       "      <td>0.224391</td>\n",
       "      <td>0.269244</td>\n",
       "      <td>0.288321</td>\n",
       "      <td>0.116587</td>\n",
       "      <td>0.395598</td>\n",
       "      <td>0.339238</td>\n",
       "      <td>0.202399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.356340</td>\n",
       "      <td>-0.321038</td>\n",
       "      <td>-0.323238</td>\n",
       "      <td>-0.444865</td>\n",
       "      <td>-0.348860</td>\n",
       "      <td>-0.419126</td>\n",
       "      <td>-0.456461</td>\n",
       "      <td>-0.397482</td>\n",
       "      <td>-0.391028</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.378580</td>\n",
       "      <td>0.279222</td>\n",
       "      <td>0.529452</td>\n",
       "      <td>0.224391</td>\n",
       "      <td>0.269244</td>\n",
       "      <td>0.288321</td>\n",
       "      <td>0.116587</td>\n",
       "      <td>0.395598</td>\n",
       "      <td>0.339238</td>\n",
       "      <td>0.202399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.339246</td>\n",
       "      <td>-0.312920</td>\n",
       "      <td>-0.305780</td>\n",
       "      <td>-0.427002</td>\n",
       "      <td>-0.366420</td>\n",
       "      <td>-0.416211</td>\n",
       "      <td>-0.452622</td>\n",
       "      <td>-0.389398</td>\n",
       "      <td>-0.394058</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.378580</td>\n",
       "      <td>0.279222</td>\n",
       "      <td>0.529452</td>\n",
       "      <td>0.224391</td>\n",
       "      <td>0.269244</td>\n",
       "      <td>0.288321</td>\n",
       "      <td>0.116587</td>\n",
       "      <td>0.395598</td>\n",
       "      <td>0.339238</td>\n",
       "      <td>0.202399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.332402</td>\n",
       "      <td>-0.331912</td>\n",
       "      <td>-0.333846</td>\n",
       "      <td>-0.432593</td>\n",
       "      <td>-0.318621</td>\n",
       "      <td>-0.380771</td>\n",
       "      <td>-0.445847</td>\n",
       "      <td>-0.366790</td>\n",
       "      <td>-0.433988</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585103</th>\n",
       "      <td>0.147669</td>\n",
       "      <td>0.541537</td>\n",
       "      <td>-0.181800</td>\n",
       "      <td>0.492964</td>\n",
       "      <td>0.120922</td>\n",
       "      <td>0.391678</td>\n",
       "      <td>0.144622</td>\n",
       "      <td>0.197834</td>\n",
       "      <td>0.325198</td>\n",
       "      <td>0.299830</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.355880</td>\n",
       "      <td>-0.404848</td>\n",
       "      <td>-0.239798</td>\n",
       "      <td>-0.269187</td>\n",
       "      <td>-0.457925</td>\n",
       "      <td>-0.365233</td>\n",
       "      <td>-0.249292</td>\n",
       "      <td>-0.273733</td>\n",
       "      <td>-0.454504</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585104</th>\n",
       "      <td>0.121502</td>\n",
       "      <td>0.260829</td>\n",
       "      <td>-0.248446</td>\n",
       "      <td>0.422976</td>\n",
       "      <td>0.205730</td>\n",
       "      <td>0.233995</td>\n",
       "      <td>0.310397</td>\n",
       "      <td>0.360269</td>\n",
       "      <td>0.322920</td>\n",
       "      <td>0.463311</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.434099</td>\n",
       "      <td>-0.495137</td>\n",
       "      <td>-0.549230</td>\n",
       "      <td>-0.453075</td>\n",
       "      <td>-0.327035</td>\n",
       "      <td>-0.357408</td>\n",
       "      <td>-0.080530</td>\n",
       "      <td>-0.381289</td>\n",
       "      <td>-0.427422</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585105</th>\n",
       "      <td>0.162393</td>\n",
       "      <td>0.421535</td>\n",
       "      <td>-0.804140</td>\n",
       "      <td>0.450230</td>\n",
       "      <td>0.187825</td>\n",
       "      <td>0.219477</td>\n",
       "      <td>0.307229</td>\n",
       "      <td>0.300398</td>\n",
       "      <td>0.403289</td>\n",
       "      <td>0.081054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.365379</td>\n",
       "      <td>-0.496839</td>\n",
       "      <td>-0.281589</td>\n",
       "      <td>-0.454220</td>\n",
       "      <td>-0.478565</td>\n",
       "      <td>-0.613799</td>\n",
       "      <td>-0.204275</td>\n",
       "      <td>-0.456859</td>\n",
       "      <td>-0.575683</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585106</th>\n",
       "      <td>0.161192</td>\n",
       "      <td>0.505940</td>\n",
       "      <td>-0.436412</td>\n",
       "      <td>0.375269</td>\n",
       "      <td>0.228820</td>\n",
       "      <td>0.334090</td>\n",
       "      <td>0.204048</td>\n",
       "      <td>0.381848</td>\n",
       "      <td>0.404161</td>\n",
       "      <td>0.291552</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.696127</td>\n",
       "      <td>-0.388773</td>\n",
       "      <td>-0.351264</td>\n",
       "      <td>-0.331284</td>\n",
       "      <td>-0.493648</td>\n",
       "      <td>-0.445110</td>\n",
       "      <td>-0.299718</td>\n",
       "      <td>-0.153662</td>\n",
       "      <td>-0.398281</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585107</th>\n",
       "      <td>0.612989</td>\n",
       "      <td>0.288278</td>\n",
       "      <td>-0.528367</td>\n",
       "      <td>0.532792</td>\n",
       "      <td>0.277565</td>\n",
       "      <td>0.362440</td>\n",
       "      <td>0.248776</td>\n",
       "      <td>0.677524</td>\n",
       "      <td>0.440180</td>\n",
       "      <td>0.288924</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.700419</td>\n",
       "      <td>-0.760815</td>\n",
       "      <td>-0.361309</td>\n",
       "      <td>-0.681235</td>\n",
       "      <td>-0.728249</td>\n",
       "      <td>-0.699328</td>\n",
       "      <td>-0.481326</td>\n",
       "      <td>-0.300799</td>\n",
       "      <td>-0.416006</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>585108 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6    \\\n",
       "0       0.378580  0.279222  0.529452  0.224391  0.269244  0.288321  0.116587   \n",
       "1       0.378580  0.279222  0.529452  0.224391  0.269244  0.288321  0.116587   \n",
       "2       0.378580  0.279222  0.529452  0.224391  0.269244  0.288321  0.116587   \n",
       "3       0.378580  0.279222  0.529452  0.224391  0.269244  0.288321  0.116587   \n",
       "4       0.378580  0.279222  0.529452  0.224391  0.269244  0.288321  0.116587   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "585103  0.147669  0.541537 -0.181800  0.492964  0.120922  0.391678  0.144622   \n",
       "585104  0.121502  0.260829 -0.248446  0.422976  0.205730  0.233995  0.310397   \n",
       "585105  0.162393  0.421535 -0.804140  0.450230  0.187825  0.219477  0.307229   \n",
       "585106  0.161192  0.505940 -0.436412  0.375269  0.228820  0.334090  0.204048   \n",
       "585107  0.612989  0.288278 -0.528367  0.532792  0.277565  0.362440  0.248776   \n",
       "\n",
       "             7         8         9    ...       91        92        93   \\\n",
       "0       0.395598  0.339238  0.202399  ... -0.640229  0.179676 -0.025780   \n",
       "1       0.395598  0.339238  0.202399  ... -0.038291  0.038372 -0.141714   \n",
       "2       0.395598  0.339238  0.202399  ... -0.356340 -0.321038 -0.323238   \n",
       "3       0.395598  0.339238  0.202399  ... -0.339246 -0.312920 -0.305780   \n",
       "4       0.395598  0.339238  0.202399  ... -0.332402 -0.331912 -0.333846   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "585103  0.197834  0.325198  0.299830  ... -0.355880 -0.404848 -0.239798   \n",
       "585104  0.360269  0.322920  0.463311  ... -0.434099 -0.495137 -0.549230   \n",
       "585105  0.300398  0.403289  0.081054  ... -0.365379 -0.496839 -0.281589   \n",
       "585106  0.381848  0.404161  0.291552  ... -0.696127 -0.388773 -0.351264   \n",
       "585107  0.677524  0.440180  0.288924  ... -0.700419 -0.760815 -0.361309   \n",
       "\n",
       "             94        95        96        97        98        99   100  \n",
       "0       0.637873 -0.032854 -0.968462  0.351491 -0.433654  0.828018  1.0  \n",
       "1      -0.202433 -0.500281 -0.184908 -0.386320 -0.435208 -0.225072  0.0  \n",
       "2      -0.444865 -0.348860 -0.419126 -0.456461 -0.397482 -0.391028  0.0  \n",
       "3      -0.427002 -0.366420 -0.416211 -0.452622 -0.389398 -0.394058  0.0  \n",
       "4      -0.432593 -0.318621 -0.380771 -0.445847 -0.366790 -0.433988  0.0  \n",
       "...          ...       ...       ...       ...       ...       ...  ...  \n",
       "585103 -0.269187 -0.457925 -0.365233 -0.249292 -0.273733 -0.454504  1.0  \n",
       "585104 -0.453075 -0.327035 -0.357408 -0.080530 -0.381289 -0.427422  1.0  \n",
       "585105 -0.454220 -0.478565 -0.613799 -0.204275 -0.456859 -0.575683  1.0  \n",
       "585106 -0.331284 -0.493648 -0.445110 -0.299718 -0.153662 -0.398281  1.0  \n",
       "585107 -0.681235 -0.728249 -0.699328 -0.481326 -0.300799 -0.416006  1.0  \n",
       "\n",
       "[585108 rows x 101 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='enhanced_VAE_final_new_par_50_LFM_space_3.csv'\n",
    "file_path = os.path.join(base_dir,'data','split',ltype, file_name)\n",
    "output_path = file_path\n",
    "enhanced_df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
