{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend as K\n",
    "\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def build_encoder(latent_dim=20):\n",
    "    encoder_inputs = layers.Input(shape=(100,)) #change here features*2\n",
    "    x = layers.Dense(256, activation='relu')(encoder_inputs)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    z_mean = layers.Dense(latent_dim)(x)\n",
    "    z_log_var = layers.Dense(latent_dim)(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    encoder = models.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "    return encoder\n",
    "\n",
    "def build_decoder(latent_dim=20):\n",
    "    latent_inputs = layers.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(64, activation='relu')(latent_inputs)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    decoder_outputs = layers.Dense(100, activation='linear')(x) #change here features*2\n",
    "    decoder = models.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "    return decoder\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        # Initialize trackers for monitoring losses\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # Return list of metrics to be updated during training\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(z)\n",
    "        # Compute KL divergence loss even during inference to track loss correctly\n",
    "        kl_loss = -0.5 * tf.reduce_mean(\n",
    "            1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\n",
    "        # Only add KL loss during training\n",
    "        if training:\n",
    "            self.add_loss(kl_loss)\n",
    "        return reconstructed\n",
    "\n",
    "    def train_step(self, data):\n",
    "    # Unpack the data\n",
    "        x = data[0] if isinstance(data, tuple) else data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(x, training=True)\n",
    "            reconstruction = self.decoder(z, training=True)\n",
    "\n",
    "            # If  data is flat (e.g., shape=(batch_size, features)), adjust axis accordingly\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(x, reconstruction), axis=-1\n",
    "            )\n",
    "            reconstruction_loss = tf.reduce_sum(reconstruction_loss)  # Sum over all dimensions\n",
    "\n",
    "            kl_loss = -0.5 * tf.reduce_mean(\n",
    "                1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1\n",
    "            )\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        return {'loss': total_loss, 'reconstruction_loss': reconstruction_loss, 'kl_loss': kl_loss}\n",
    "\n",
    "# Example usage:\n",
    "latent_dim = 16  \n",
    "encoder = build_encoder(latent_dim)\n",
    "decoder = build_decoder(latent_dim)\n",
    "vae = VAE(encoder, decoder)\n",
    "#vae.compile(optimizer='adam')\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relative paths. # Set directory paths for later use.\n",
    "# Get the directory of the script file\n",
    "base_dir = os.getcwd()\n",
    "base_dir\n",
    "ligants_type=['enzyme','GPCR','ion_channel','nuclear_receptor']\n",
    "ltype=ligants_type[3]\n",
    "file_name='final_new_par_LMF_50.csv'\n",
    "file_path = os.path.join(base_dir,'data','split',ltype, file_name)\n",
    "output_path = file_path\n",
    "data_frame = pd.read_csv(file_path, header=None, skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include instances with label 1 (interactions)\n",
    "# Separate features and labels\n",
    "filtered_df = data_frame[data_frame.iloc[:, -1] == 1]  # All rows, all columns except the last one\n",
    "features_new = filtered_df.iloc[:, :-1]     # All rows, just the last column\n",
    "\n",
    "# Convert features DataFrame to a NumPy array if necessary\n",
    "x_train = features_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 101)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para\n",
    "epochs=4\n",
    "batch_size=45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "2/2 [==============================] - 1s 5ms/step - loss: -0.1906 - reconstruction_loss: -0.2597 - kl_loss: 0.0174\n",
      "Epoch 2/4\n",
      "2/2 [==============================] - 0s 3ms/step - loss: -0.5115 - reconstruction_loss: -0.5793 - kl_loss: 0.0202\n",
      "Epoch 3/4\n",
      "2/2 [==============================] - 0s 3ms/step - loss: -0.7064 - reconstruction_loss: -0.7083 - kl_loss: 0.0177\n",
      "Epoch 4/4\n",
      "2/2 [==============================] - 0s 2ms/step - loss: -1.0152 - reconstruction_loss: -1.1782 - kl_loss: 0.0158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1bc9e149870>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "vae.fit(x_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include instances with label 1 (interactions)\n",
    "filtered_df = data_frame[data_frame.iloc[:, -1] == 1]\n",
    "\n",
    "# Separate features\n",
    "features_new = filtered_df.iloc[:, :-1]  # Assuming the last column is the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = features_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "z_mean, z_log_var, z = vae.encoder.predict(x_new)\n",
    "# Now, z contains the latent representations of  filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "reconstructed_new = vae.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6   \\\n",
      "0  -0.565347 -0.426805 -0.278643 -0.341101 -0.444826 -0.245312 -0.517644   \n",
      "1  -0.138126 -0.144002 -0.076164 -0.028113 -0.119450 -0.135161 -0.008757   \n",
      "2  -0.138126 -0.144002 -0.076164 -0.028113 -0.119450 -0.135161 -0.008757   \n",
      "3  -0.138126 -0.144002 -0.076164 -0.028113 -0.119450 -0.135161 -0.008757   \n",
      "4  -0.138126 -0.144002 -0.076164 -0.028113 -0.119450 -0.135161 -0.008757   \n",
      "..       ...       ...       ...       ...       ...       ...       ...   \n",
      "85 -0.324121 -0.261553 -0.193835 -0.238345 -0.279753 -0.168059 -0.311657   \n",
      "86 -0.324121 -0.261553 -0.193835 -0.238345 -0.279753 -0.168059 -0.311657   \n",
      "87 -0.324121 -0.261553 -0.193835 -0.238345 -0.279753 -0.168059 -0.311657   \n",
      "88 -0.476878 -0.382709 -0.265242 -0.321077 -0.393143 -0.221384 -0.442175   \n",
      "89 -0.458062 -0.391875 -0.250347 -0.337288 -0.403554 -0.219870 -0.441276   \n",
      "\n",
      "          7         8         9   ...        90        91        92        93  \\\n",
      "0  -0.259974 -0.276345 -0.516024  ...  0.097761  0.085043  0.066079  0.115560   \n",
      "1   0.022529 -0.099207 -0.189062  ...  0.127131  0.267232 -0.005838  0.239797   \n",
      "2   0.022529 -0.099207 -0.189062  ...  0.189196  0.324669  0.001468  0.305311   \n",
      "3   0.022529 -0.099207 -0.189062  ...  0.153128  0.252015 -0.007667  0.201381   \n",
      "4   0.022529 -0.099207 -0.189062  ...  0.192116  0.318476  0.006821  0.301378   \n",
      "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
      "85 -0.156825 -0.164421 -0.255857  ...  0.195258  0.260207  0.017850  0.269732   \n",
      "86 -0.156825 -0.164421 -0.255857  ...  0.193102  0.257491  0.019748  0.271137   \n",
      "87 -0.156825 -0.164421 -0.255857  ...  0.193848  0.260099  0.020986  0.273913   \n",
      "88 -0.229904 -0.226671 -0.420564  ...  0.166274  0.240945  0.009398  0.250567   \n",
      "89 -0.223649 -0.229315 -0.416910  ...  0.172294  0.228911  0.009225  0.250641   \n",
      "\n",
      "          94        95        96        97        98        99  \n",
      "0   0.047737  0.006548  0.000498  0.102363 -0.023309  0.057503  \n",
      "1   0.170993  0.350185  0.209856  0.197427  0.259254  0.131175  \n",
      "2   0.217168  0.407196  0.257649  0.242267  0.282082  0.162188  \n",
      "3   0.170073  0.308038  0.181724  0.181515  0.250613  0.099931  \n",
      "4   0.218554  0.404232  0.260016  0.238620  0.283617  0.154760  \n",
      "..       ...       ...       ...       ...       ...       ...  \n",
      "85  0.173348  0.338203  0.215147  0.199882  0.188407  0.163064  \n",
      "86  0.180345  0.329111  0.218741  0.207740  0.194935  0.156420  \n",
      "87  0.170815  0.333055  0.220346  0.201296  0.191163  0.162270  \n",
      "88  0.161030  0.298324  0.206753  0.179011  0.173113  0.141783  \n",
      "89  0.154096  0.299893  0.194310  0.177886  0.167805  0.142719  \n",
      "\n",
      "[90 rows x 100 columns]\n",
      "          0         1         2         3         4         5         6   \\\n",
      "0  -0.064523 -0.134328  0.080037 -0.245222 -0.459697 -0.651397 -0.347039   \n",
      "1   0.037169  0.015262 -0.042780 -0.370491 -0.212642 -0.359512 -0.283710   \n",
      "2  -0.108611  0.055054 -0.159019 -0.220739 -0.044753 -0.554277 -0.267824   \n",
      "3  -0.078665  0.016328 -0.127069 -0.263205 -0.208562 -0.059981 -0.079525   \n",
      "4  -0.130004  0.042647  0.045475  0.086974 -0.212211  0.124418 -0.105467   \n",
      "..       ...       ...       ...       ...       ...       ...       ...   \n",
      "85 -0.195566  0.238230 -0.161608 -0.287058 -0.445437 -0.633864 -0.091357   \n",
      "86 -0.117440  0.154424 -0.261522 -0.404422 -0.277050 -1.027826 -0.252270   \n",
      "87  0.073552 -0.013364 -0.198169 -0.402683 -0.441281 -0.902368 -0.475202   \n",
      "88  0.058320 -0.170551 -0.090105 -0.286448 -0.326006 -0.584834 -0.398857   \n",
      "89 -0.205154 -0.075702  0.036636 -0.349501 -0.259022 -0.655473 -0.249392   \n",
      "\n",
      "          7         8         9   ...        90        91        92        93  \\\n",
      "0  -0.406750 -0.430594 -0.277396  ...  0.515734  0.101460 -0.143896  0.244717   \n",
      "1  -0.193819  0.022242 -0.040625  ... -0.003442  0.141334  0.042713  0.301073   \n",
      "2  -0.264545 -0.263012 -0.139345  ...  0.035651  0.126966 -0.230981  0.195033   \n",
      "3  -0.177945  0.077954  0.000507  ... -0.116485  0.060492  0.030883  0.168405   \n",
      "4  -0.155988 -0.299326 -0.002633  ...  0.087705  0.427540 -0.073234  0.146324   \n",
      "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
      "85 -0.500905 -0.144073  0.149402  ... -0.134497  0.095384 -0.074756  0.293121   \n",
      "86 -0.407424 -0.189082 -0.599424  ...  0.193228  0.313622 -0.290759  0.464356   \n",
      "87 -0.122222 -0.388596 -0.318462  ...  0.585482  0.295713 -0.140652  0.313776   \n",
      "88 -0.261047 -0.215112 -0.148649  ... -0.052134  0.166216 -0.183698  0.311786   \n",
      "89 -0.548391 -0.157104 -0.350186  ...  0.023979  0.364722 -0.011074  0.301385   \n",
      "\n",
      "          94        95        96        97        98        99  \n",
      "0   0.292520  0.119860  0.551756  0.242470 -0.051992 -0.394702  \n",
      "1   0.215140  0.166862  0.226546  0.373874  0.069599 -0.377393  \n",
      "2   0.317356  0.168483  0.117021  0.132371 -0.163156 -0.289074  \n",
      "3   0.130464  0.218212  0.209066  0.241018  0.214004 -0.181142  \n",
      "4   0.052302  0.062075  0.345697  0.341311  0.110872 -0.025347  \n",
      "..       ...       ...       ...       ...       ...       ...  \n",
      "85  0.396741  0.256724 -0.055067  0.302515  0.120835 -0.392278  \n",
      "86  0.824885  0.625673  0.396204  0.404887  0.406167 -0.814293  \n",
      "87  0.619005  0.050611  0.480075  0.319258 -0.050130 -0.562173  \n",
      "88  0.391449  0.289331  0.426621  0.359270  0.251518 -0.327827  \n",
      "89  0.363954  0.436090  0.426015  0.392417  0.006484 -0.521633  \n",
      "\n",
      "[90 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the reconstructed data to a DataFrame\n",
    "reconstructed_df = pd.DataFrame(reconstructed_new)\n",
    "\n",
    "# Display the first few rows of the reconstructed DataFrame\n",
    "print(pd.DataFrame(x_new))\n",
    "print(reconstructed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0 -0.064523 -0.134328  0.080037 -0.245222 -0.459697 -0.651397 -0.347039   \n",
      "1  0.037169  0.015262 -0.042780 -0.370491 -0.212642 -0.359512 -0.283710   \n",
      "2 -0.108611  0.055054 -0.159019 -0.220739 -0.044753 -0.554277 -0.267824   \n",
      "3 -0.078665  0.016328 -0.127069 -0.263205 -0.208562 -0.059981 -0.079525   \n",
      "4 -0.130004  0.042647  0.045475  0.086974 -0.212211  0.124418 -0.105467   \n",
      "\n",
      "        7         8         9    ...       91        92        93        94   \\\n",
      "0 -0.406750 -0.430594 -0.277396  ...  0.101460 -0.143896  0.244717  0.292520   \n",
      "1 -0.193819  0.022242 -0.040625  ...  0.141334  0.042713  0.301073  0.215140   \n",
      "2 -0.264545 -0.263012 -0.139345  ...  0.126966 -0.230981  0.195033  0.317356   \n",
      "3 -0.177945  0.077954  0.000507  ...  0.060492  0.030883  0.168405  0.130464   \n",
      "4 -0.155988 -0.299326 -0.002633  ...  0.427540 -0.073234  0.146324  0.052302   \n",
      "\n",
      "        95        96        97        98        99   100  \n",
      "0  0.119860  0.551756  0.242470 -0.051992 -0.394702    1  \n",
      "1  0.166862  0.226546  0.373874  0.069599 -0.377393    1  \n",
      "2  0.168483  0.117021  0.132371 -0.163156 -0.289074    1  \n",
      "3  0.218212  0.209066  0.241018  0.214004 -0.181142    1  \n",
      "4  0.062075  0.345697  0.341311  0.110872 -0.025347    1  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "# Add a new column 'Label' with all values set to 1\n",
    "reconstructed_df[100] = 1\n",
    "\n",
    "# Display the first few rows to verify the new column\n",
    "print(reconstructed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 818us/step\n"
     ]
    }
   ],
   "source": [
    "num_samples_to_generate = 1224  # The number of new rows want to generate\n",
    "\n",
    "# Generate random samples from the latent space\n",
    "latent_dim = 16  # Ensure this matches the latent dimension size of  VAE\n",
    "z_new_samples = np.random.normal(size=(num_samples_to_generate, latent_dim))\n",
    "\n",
    "# Use the decoder to generate new data\n",
    "new_data_generated = vae.decoder.predict(z_new_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.86626863e-01,  2.46674232e-02, -1.14546113e-01, ...,\n",
       "         9.68806386e-01,  2.79888690e-01, -6.48455203e-01],\n",
       "       [-1.92022786e-01, -2.71976352e-01, -1.47042230e-01, ...,\n",
       "         2.55978763e-01,  2.49570280e-01, -4.56500947e-01],\n",
       "       [-4.49671417e-01,  1.29464447e-01, -2.66862482e-01, ...,\n",
       "         3.59625816e-01,  3.57754618e-01, -4.47723448e-01],\n",
       "       ...,\n",
       "       [-5.75167477e-01, -1.06650010e-01, -1.20694518e-01, ...,\n",
       "         2.30109289e-01,  2.72606969e-01, -3.56229037e-01],\n",
       "       [ 9.45773441e-04,  2.68804491e-01,  7.34529868e-02, ...,\n",
       "         6.94784224e-01, -3.34284492e-02, -2.85421431e-01],\n",
       "       [-9.20171440e-02, -1.12558134e-01,  9.25085470e-02, ...,\n",
       "         7.56215215e-01,  1.21875912e-01, -4.83328044e-01]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the generated data to a DataFrame\n",
    "new_data_df = pd.DataFrame(new_data_generated)\n",
    "\n",
    "# Add a column 'Label' with all values set to 1\n",
    "new_data_df[100] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_df = pd.concat([data_frame, new_data_df], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.565347</td>\n",
       "      <td>-0.426805</td>\n",
       "      <td>-0.278643</td>\n",
       "      <td>-0.341101</td>\n",
       "      <td>-0.444826</td>\n",
       "      <td>-0.245312</td>\n",
       "      <td>-0.517644</td>\n",
       "      <td>-0.259974</td>\n",
       "      <td>-0.276345</td>\n",
       "      <td>-0.516024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243418</td>\n",
       "      <td>0.006033</td>\n",
       "      <td>0.263965</td>\n",
       "      <td>0.164053</td>\n",
       "      <td>0.323660</td>\n",
       "      <td>0.205177</td>\n",
       "      <td>0.183918</td>\n",
       "      <td>0.174048</td>\n",
       "      <td>0.147949</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.565347</td>\n",
       "      <td>-0.426805</td>\n",
       "      <td>-0.278643</td>\n",
       "      <td>-0.341101</td>\n",
       "      <td>-0.444826</td>\n",
       "      <td>-0.245312</td>\n",
       "      <td>-0.517644</td>\n",
       "      <td>-0.259974</td>\n",
       "      <td>-0.276345</td>\n",
       "      <td>-0.516024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267232</td>\n",
       "      <td>-0.005838</td>\n",
       "      <td>0.239797</td>\n",
       "      <td>0.170993</td>\n",
       "      <td>0.350185</td>\n",
       "      <td>0.209856</td>\n",
       "      <td>0.197427</td>\n",
       "      <td>0.259254</td>\n",
       "      <td>0.131175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.565347</td>\n",
       "      <td>-0.426805</td>\n",
       "      <td>-0.278643</td>\n",
       "      <td>-0.341101</td>\n",
       "      <td>-0.444826</td>\n",
       "      <td>-0.245312</td>\n",
       "      <td>-0.517644</td>\n",
       "      <td>-0.259974</td>\n",
       "      <td>-0.276345</td>\n",
       "      <td>-0.516024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324669</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.305311</td>\n",
       "      <td>0.217168</td>\n",
       "      <td>0.407196</td>\n",
       "      <td>0.257649</td>\n",
       "      <td>0.242267</td>\n",
       "      <td>0.282082</td>\n",
       "      <td>0.162188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.565347</td>\n",
       "      <td>-0.426805</td>\n",
       "      <td>-0.278643</td>\n",
       "      <td>-0.341101</td>\n",
       "      <td>-0.444826</td>\n",
       "      <td>-0.245312</td>\n",
       "      <td>-0.517644</td>\n",
       "      <td>-0.259974</td>\n",
       "      <td>-0.276345</td>\n",
       "      <td>-0.516024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286988</td>\n",
       "      <td>0.032042</td>\n",
       "      <td>0.299079</td>\n",
       "      <td>0.199626</td>\n",
       "      <td>0.369988</td>\n",
       "      <td>0.260502</td>\n",
       "      <td>0.221786</td>\n",
       "      <td>0.214709</td>\n",
       "      <td>0.187751</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.565347</td>\n",
       "      <td>-0.426805</td>\n",
       "      <td>-0.278643</td>\n",
       "      <td>-0.341101</td>\n",
       "      <td>-0.444826</td>\n",
       "      <td>-0.245312</td>\n",
       "      <td>-0.517644</td>\n",
       "      <td>-0.259974</td>\n",
       "      <td>-0.276345</td>\n",
       "      <td>-0.516024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262091</td>\n",
       "      <td>0.029252</td>\n",
       "      <td>0.277777</td>\n",
       "      <td>0.183678</td>\n",
       "      <td>0.360393</td>\n",
       "      <td>0.226148</td>\n",
       "      <td>0.206291</td>\n",
       "      <td>0.197065</td>\n",
       "      <td>0.162283</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>-0.243129</td>\n",
       "      <td>-0.122140</td>\n",
       "      <td>-0.053377</td>\n",
       "      <td>-0.231776</td>\n",
       "      <td>-0.374284</td>\n",
       "      <td>-0.378557</td>\n",
       "      <td>0.077639</td>\n",
       "      <td>-0.592342</td>\n",
       "      <td>-0.456843</td>\n",
       "      <td>-0.242238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556469</td>\n",
       "      <td>-0.178810</td>\n",
       "      <td>0.290289</td>\n",
       "      <td>0.407412</td>\n",
       "      <td>0.339677</td>\n",
       "      <td>0.191231</td>\n",
       "      <td>0.469876</td>\n",
       "      <td>0.341804</td>\n",
       "      <td>-0.536705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>-0.002513</td>\n",
       "      <td>0.156427</td>\n",
       "      <td>-0.053416</td>\n",
       "      <td>-0.243952</td>\n",
       "      <td>-0.528682</td>\n",
       "      <td>-0.177617</td>\n",
       "      <td>-0.454571</td>\n",
       "      <td>-0.386666</td>\n",
       "      <td>-0.018120</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.446218</td>\n",
       "      <td>0.106677</td>\n",
       "      <td>0.457910</td>\n",
       "      <td>-0.003070</td>\n",
       "      <td>0.426516</td>\n",
       "      <td>0.250798</td>\n",
       "      <td>0.433788</td>\n",
       "      <td>-0.024218</td>\n",
       "      <td>-0.281797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>-0.575167</td>\n",
       "      <td>-0.106650</td>\n",
       "      <td>-0.120695</td>\n",
       "      <td>-0.454638</td>\n",
       "      <td>-0.120757</td>\n",
       "      <td>-1.037028</td>\n",
       "      <td>-0.209787</td>\n",
       "      <td>-0.478722</td>\n",
       "      <td>-0.273956</td>\n",
       "      <td>0.151954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224131</td>\n",
       "      <td>0.094253</td>\n",
       "      <td>0.424761</td>\n",
       "      <td>0.391546</td>\n",
       "      <td>0.420641</td>\n",
       "      <td>0.136863</td>\n",
       "      <td>0.230109</td>\n",
       "      <td>0.272607</td>\n",
       "      <td>-0.356229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.268804</td>\n",
       "      <td>0.073453</td>\n",
       "      <td>-0.121740</td>\n",
       "      <td>-0.490353</td>\n",
       "      <td>-0.250157</td>\n",
       "      <td>-0.165540</td>\n",
       "      <td>0.066354</td>\n",
       "      <td>-0.518123</td>\n",
       "      <td>-0.103939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461725</td>\n",
       "      <td>-0.312239</td>\n",
       "      <td>0.418163</td>\n",
       "      <td>0.314173</td>\n",
       "      <td>0.035887</td>\n",
       "      <td>0.520013</td>\n",
       "      <td>0.694784</td>\n",
       "      <td>-0.033428</td>\n",
       "      <td>-0.285421</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>-0.092017</td>\n",
       "      <td>-0.112558</td>\n",
       "      <td>0.092509</td>\n",
       "      <td>-0.373975</td>\n",
       "      <td>-0.334540</td>\n",
       "      <td>-0.350445</td>\n",
       "      <td>-0.696104</td>\n",
       "      <td>-0.468576</td>\n",
       "      <td>-0.209287</td>\n",
       "      <td>-0.105816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307268</td>\n",
       "      <td>-0.083210</td>\n",
       "      <td>0.892792</td>\n",
       "      <td>0.026027</td>\n",
       "      <td>0.373396</td>\n",
       "      <td>0.324229</td>\n",
       "      <td>0.756215</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>-0.483328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2628 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0    -0.565347 -0.426805 -0.278643 -0.341101 -0.444826 -0.245312 -0.517644   \n",
       "1    -0.565347 -0.426805 -0.278643 -0.341101 -0.444826 -0.245312 -0.517644   \n",
       "2    -0.565347 -0.426805 -0.278643 -0.341101 -0.444826 -0.245312 -0.517644   \n",
       "3    -0.565347 -0.426805 -0.278643 -0.341101 -0.444826 -0.245312 -0.517644   \n",
       "4    -0.565347 -0.426805 -0.278643 -0.341101 -0.444826 -0.245312 -0.517644   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2623 -0.243129 -0.122140 -0.053377 -0.231776 -0.374284 -0.378557  0.077639   \n",
       "2624 -0.002513  0.156427 -0.053416 -0.243952 -0.528682 -0.177617 -0.454571   \n",
       "2625 -0.575167 -0.106650 -0.120695 -0.454638 -0.120757 -1.037028 -0.209787   \n",
       "2626  0.000946  0.268804  0.073453 -0.121740 -0.490353 -0.250157 -0.165540   \n",
       "2627 -0.092017 -0.112558  0.092509 -0.373975 -0.334540 -0.350445 -0.696104   \n",
       "\n",
       "           7         8         9    ...       91        92        93   \\\n",
       "0    -0.259974 -0.276345 -0.516024  ...  0.243418  0.006033  0.263965   \n",
       "1    -0.259974 -0.276345 -0.516024  ...  0.267232 -0.005838  0.239797   \n",
       "2    -0.259974 -0.276345 -0.516024  ...  0.324669  0.001468  0.305311   \n",
       "3    -0.259974 -0.276345 -0.516024  ...  0.286988  0.032042  0.299079   \n",
       "4    -0.259974 -0.276345 -0.516024  ...  0.262091  0.029252  0.277777   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2623 -0.592342 -0.456843 -0.242238  ...  0.556469 -0.178810  0.290289   \n",
       "2624 -0.386666 -0.018120  0.011200  ...  0.446218  0.106677  0.457910   \n",
       "2625 -0.478722 -0.273956  0.151954  ...  0.224131  0.094253  0.424761   \n",
       "2626  0.066354 -0.518123 -0.103939  ...  0.461725 -0.312239  0.418163   \n",
       "2627 -0.468576 -0.209287 -0.105816  ...  0.307268 -0.083210  0.892792   \n",
       "\n",
       "           94        95        96        97        98        99   100  \n",
       "0     0.164053  0.323660  0.205177  0.183918  0.174048  0.147949    0  \n",
       "1     0.170993  0.350185  0.209856  0.197427  0.259254  0.131175    0  \n",
       "2     0.217168  0.407196  0.257649  0.242267  0.282082  0.162188    0  \n",
       "3     0.199626  0.369988  0.260502  0.221786  0.214709  0.187751    0  \n",
       "4     0.183678  0.360393  0.226148  0.206291  0.197065  0.162283    0  \n",
       "...        ...       ...       ...       ...       ...       ...  ...  \n",
       "2623  0.407412  0.339677  0.191231  0.469876  0.341804 -0.536705    1  \n",
       "2624 -0.003070  0.426516  0.250798  0.433788 -0.024218 -0.281797    1  \n",
       "2625  0.391546  0.420641  0.136863  0.230109  0.272607 -0.356229    1  \n",
       "2626  0.314173  0.035887  0.520013  0.694784 -0.033428 -0.285421    1  \n",
       "2627  0.026027  0.373396  0.324229  0.756215  0.121876 -0.483328    1  \n",
       "\n",
       "[2628 rows x 101 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='enhanced_VAE_final_new_par_50_LMF_space_3.csv'\n",
    "file_path = os.path.join(base_dir,'data','split',ltype, file_name)\n",
    "output_path = file_path\n",
    "enhanced_df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
