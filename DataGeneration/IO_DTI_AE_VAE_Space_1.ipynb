{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend as K\n",
    "\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def build_encoder(latent_dim=20):\n",
    "    encoder_inputs = layers.Input(shape=(100,)) #change here features*2\n",
    "    x = layers.Dense(256, activation='relu')(encoder_inputs)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    z_mean = layers.Dense(latent_dim)(x)\n",
    "    z_log_var = layers.Dense(latent_dim)(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    encoder = models.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "    return encoder\n",
    "\n",
    "def build_decoder(latent_dim=20):\n",
    "    latent_inputs = layers.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(64, activation='relu')(latent_inputs)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    decoder_outputs = layers.Dense(100, activation='linear')(x) #change here features*2\n",
    "    decoder = models.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "    return decoder\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        # Initialize trackers for monitoring losses\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # Return list of metrics to be updated during training\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(z)\n",
    "        # Compute KL divergence loss even during inference to track loss correctly\n",
    "        kl_loss = -0.5 * tf.reduce_mean(\n",
    "            1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\n",
    "        # Only add KL loss during training\n",
    "        if training:\n",
    "            self.add_loss(kl_loss)\n",
    "        return reconstructed\n",
    "\n",
    "    def train_step(self, data):\n",
    "    # Unpack the data\n",
    "        x = data[0] if isinstance(data, tuple) else data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(x, training=True)\n",
    "            reconstruction = self.decoder(z, training=True)\n",
    "\n",
    "            # If  data is flat (e.g., shape=(batch_size, features)), adjust axis accordingly\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(x, reconstruction), axis=-1\n",
    "            )\n",
    "            reconstruction_loss = tf.reduce_sum(reconstruction_loss)  # Sum over all dimensions\n",
    "\n",
    "            kl_loss = -0.5 * tf.reduce_mean(\n",
    "                1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1\n",
    "            )\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        return {'loss': total_loss, 'reconstruction_loss': reconstruction_loss, 'kl_loss': kl_loss}\n",
    "\n",
    "# Example usage:\n",
    "latent_dim = 16  \n",
    "encoder = build_encoder(latent_dim)\n",
    "decoder = build_decoder(latent_dim)\n",
    "vae = VAE(encoder, decoder)\n",
    "#vae.compile(optimizer='adam')\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relative paths. # Set directory paths for later use.\n",
    "# Get the directory of the script file\n",
    "base_dir = os.getcwd()\n",
    "base_dir\n",
    "ligants_type=['enzyme','GPCR','ion_channel','nuclear_receptor']\n",
    "ltype=ligants_type[2]\n",
    "file_name='final_new_par_50.csv'\n",
    "file_path = os.path.join(base_dir,'data','split',ltype, file_name)\n",
    "output_path = file_path\n",
    "data_frame = pd.read_csv(file_path, header=None, skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include instances with label 1 (interactions)\n",
    "# Separate features and labels\n",
    "filtered_df = data_frame[data_frame.iloc[:, -1] == 1]  # All rows, all columns except the last one\n",
    "features_new = filtered_df.iloc[:, :-1]     # All rows, just the last column\n",
    "\n",
    "# Convert features DataFrame to a NumPy array if necessary\n",
    "x_train = features_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1476, 101)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para\n",
    "epochs=4\n",
    "batch_size=82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "18/18 [==============================] - 1s 2ms/step - loss: -0.7575 - reconstruction_loss: -0.9745 - kl_loss: 0.0068\n",
      "Epoch 2/4\n",
      "18/18 [==============================] - 0s 2ms/step - loss: -0.9095 - reconstruction_loss: -0.9538 - kl_loss: 0.0062\n",
      "Epoch 3/4\n",
      "18/18 [==============================] - 0s 2ms/step - loss: -0.9256 - reconstruction_loss: -0.9513 - kl_loss: 0.0043\n",
      "Epoch 4/4\n",
      "18/18 [==============================] - 0s 2ms/step - loss: -0.9427 - reconstruction_loss: -1.0260 - kl_loss: 0.0025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x24a1e1421a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "vae.fit(x_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include instances with label 1 (interactions)\n",
    "filtered_df = data_frame[data_frame.iloc[:, -1] == 1]\n",
    "\n",
    "# Separate features\n",
    "features_new = filtered_df.iloc[:, :-1]  # Assuming the last column is the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = features_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 717us/step\n"
     ]
    }
   ],
   "source": [
    "z_mean, z_log_var, z = vae.encoder.predict(x_new)\n",
    "# z contains the latent representations of  filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 725us/step\n"
     ]
    }
   ],
   "source": [
    "reconstructed_new = vae.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6   \\\n",
      "0    -0.046412 -0.058844  0.030492 -0.045302 -0.047853 -0.017467  0.049574   \n",
      "1    -0.046412 -0.058844  0.030492 -0.045302 -0.047853 -0.017467  0.049574   \n",
      "2    -0.092292  0.050318  0.007350 -0.025365 -0.007617  0.043665  0.030111   \n",
      "3     0.001631 -0.043295 -0.090071 -0.045389 -0.108350 -0.136271  0.069069   \n",
      "4     0.001631 -0.043295 -0.090071 -0.045389 -0.108350 -0.136271  0.069069   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1471 -0.040237 -0.150078  0.016174 -0.207401  0.026399 -0.030389 -0.210890   \n",
      "1472 -0.040237 -0.150078  0.016174 -0.207401  0.026399 -0.030389 -0.210890   \n",
      "1473 -0.040237 -0.150078  0.016174 -0.207401  0.026399 -0.030389 -0.210890   \n",
      "1474 -0.046412 -0.058844  0.030492 -0.045302 -0.047853 -0.017467  0.049574   \n",
      "1475 -0.046412 -0.058844  0.030492 -0.045302 -0.047853 -0.017467  0.049574   \n",
      "\n",
      "            7         8         9   ...        90        91        92  \\\n",
      "0    -0.033913 -0.039866 -0.073236  ... -0.477456 -0.563680 -0.269111   \n",
      "1    -0.033913 -0.039866 -0.073236  ... -0.472150 -0.602052 -0.787511   \n",
      "2    -0.055201 -0.025035 -0.025908  ... -0.472150 -0.602052 -0.787511   \n",
      "3     0.073759 -0.029556 -0.110557  ...  0.004113 -0.335019 -0.198016   \n",
      "4     0.073759 -0.029556 -0.110557  ...  0.252745 -0.495947 -0.046093   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1471 -0.022524  0.034482 -0.155930  ... -0.186205 -0.047240  0.349221   \n",
      "1472 -0.022524  0.034482 -0.155930  ...  0.208200  0.247458  0.003390   \n",
      "1473 -0.022524  0.034482 -0.155930  ... -0.472150 -0.602052 -0.787511   \n",
      "1474 -0.033913 -0.039866 -0.073236  ... -0.477456 -0.563680 -0.269111   \n",
      "1475 -0.033913 -0.039866 -0.073236  ... -0.472150 -0.602052 -0.787511   \n",
      "\n",
      "            93        94        95        96        97        98        99  \n",
      "0     0.470786  0.233778  0.005202 -0.532169  0.495181  0.442895  0.391756  \n",
      "1    -0.049248 -0.373984 -0.095637 -0.281007 -0.274386  0.498808  0.129197  \n",
      "2    -0.049248 -0.373984 -0.095637 -0.281007 -0.274386  0.498808  0.129197  \n",
      "3    -0.336936 -0.551998 -0.191809  0.061965 -0.526433  0.223521 -0.109956  \n",
      "4    -0.311332 -0.316327  0.038032  0.067388 -0.202162 -0.186519 -0.273333  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "1471 -0.168011 -0.371869 -0.305116 -0.378202 -0.112920  0.153880  0.261339  \n",
      "1472 -0.286956  0.232851 -0.005182 -0.281391 -0.208426 -0.092566  0.173618  \n",
      "1473 -0.049248 -0.373984 -0.095637 -0.281007 -0.274386  0.498808  0.129197  \n",
      "1474  0.470786  0.233778  0.005202 -0.532169  0.495181  0.442895  0.391756  \n",
      "1475 -0.049248 -0.373984 -0.095637 -0.281007 -0.274386  0.498808  0.129197  \n",
      "\n",
      "[1476 rows x 100 columns]\n",
      "            0         1         2         3         4         5         6   \\\n",
      "0    -0.498210 -0.511602 -0.517240 -0.592945 -0.387479 -0.457874 -0.698511   \n",
      "1    -0.324382 -0.486380 -0.613683 -0.643124 -0.569715 -0.234215 -0.482178   \n",
      "2    -0.458869 -0.613392 -0.392305 -0.301704 -0.636402 -0.494370 -0.724505   \n",
      "3    -0.268335 -0.777448 -0.311483 -0.349589 -0.322678 -0.632217 -0.496246   \n",
      "4    -0.503912 -0.486360 -0.548580 -0.051595 -0.381177 -0.451978 -0.514669   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1471 -0.417939 -0.429044 -0.373932 -0.165376 -0.367093 -0.378765 -0.249799   \n",
      "1472 -0.250548 -0.204962 -0.557958 -0.360107 -0.339238 -0.451204 -0.620592   \n",
      "1473 -0.608299 -0.618220 -0.425558 -0.429873 -0.703764 -0.661727 -0.586630   \n",
      "1474 -0.304208 -0.522075 -0.633427 -0.307655 -0.370983 -0.336818 -0.700111   \n",
      "1475 -0.605692 -0.312953 -0.423557 -0.463558 -0.314234 -0.443173 -0.384851   \n",
      "\n",
      "            7         8         9   ...        90        91        92  \\\n",
      "0    -0.643023 -0.392554 -0.884905  ... -0.773296 -0.379539 -1.200930   \n",
      "1    -0.222053 -0.234737 -0.882680  ... -0.269337 -0.545987 -0.172602   \n",
      "2    -0.395026 -0.377087 -0.682469  ... -0.646773 -0.587894 -0.409835   \n",
      "3    -0.328431 -0.314897 -0.831167  ... -0.471512 -0.534184 -0.852437   \n",
      "4    -0.673165 -0.339315 -0.555230  ... -0.594182 -0.472965 -0.373595   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1471 -0.189267 -0.281423 -0.227711  ... -0.432430 -0.470947 -0.555908   \n",
      "1472 -0.409771 -0.474858 -0.602726  ... -0.728578 -0.436930 -0.569104   \n",
      "1473 -0.855515 -0.190484 -1.009313  ... -0.612676 -0.503393 -0.246616   \n",
      "1474 -0.408272 -0.388108 -0.939230  ... -0.769990 -0.448878 -0.523890   \n",
      "1475 -0.589807 -0.480515 -0.649234  ... -0.407765 -0.215540 -0.364510   \n",
      "\n",
      "            93        94        95        96        97        98        99  \n",
      "0    -0.740842 -0.791174 -0.720541 -0.571446 -0.646337 -0.389948 -0.457720  \n",
      "1    -0.825639 -0.479157 -0.599028 -0.676013 -0.480160 -0.613610 -0.370215  \n",
      "2    -0.576252 -0.385306 -0.343216 -0.303520 -0.562161 -0.437906 -0.320803  \n",
      "3    -0.657167 -0.558626 -0.568110 -0.305216 -0.639422 -0.488318 -0.214943  \n",
      "4    -0.384282 -0.517885 -0.407225 -0.622817 -0.739634 -0.546709 -0.350312  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "1471 -0.254298 -0.507873 -0.157125 -0.413626 -0.672100 -0.213065 -0.243283  \n",
      "1472 -0.611313 -0.576644 -0.563479 -0.340969 -0.306373 -0.511161 -0.307469  \n",
      "1473 -0.667755 -0.597194 -0.301398 -0.624242 -0.952530 -0.602727 -0.238529  \n",
      "1474 -0.546992 -0.620339 -0.705317 -0.573273 -0.616532 -0.667822 -0.248379  \n",
      "1475 -0.532719 -0.390836 -0.318926 -0.566332 -0.333400 -0.379957 -0.431469  \n",
      "\n",
      "[1476 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the reconstructed data to a DataFrame\n",
    "reconstructed_df = pd.DataFrame(reconstructed_new)\n",
    "\n",
    "# Display the first few rows of the reconstructed DataFrame\n",
    "print(pd.DataFrame(x_new))\n",
    "print(reconstructed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0 -0.498210 -0.511602 -0.517240 -0.592945 -0.387479 -0.457874 -0.698511   \n",
      "1 -0.324382 -0.486380 -0.613683 -0.643124 -0.569715 -0.234215 -0.482178   \n",
      "2 -0.458869 -0.613392 -0.392305 -0.301704 -0.636402 -0.494370 -0.724505   \n",
      "3 -0.268335 -0.777448 -0.311483 -0.349589 -0.322678 -0.632217 -0.496246   \n",
      "4 -0.503912 -0.486360 -0.548580 -0.051595 -0.381177 -0.451978 -0.514669   \n",
      "\n",
      "        7         8         9    ...       91        92        93        94   \\\n",
      "0 -0.643023 -0.392554 -0.884905  ... -0.379539 -1.200930 -0.740842 -0.791174   \n",
      "1 -0.222053 -0.234737 -0.882680  ... -0.545987 -0.172602 -0.825639 -0.479157   \n",
      "2 -0.395026 -0.377087 -0.682469  ... -0.587894 -0.409835 -0.576252 -0.385306   \n",
      "3 -0.328431 -0.314897 -0.831167  ... -0.534184 -0.852437 -0.657167 -0.558626   \n",
      "4 -0.673165 -0.339315 -0.555230  ... -0.472965 -0.373595 -0.384282 -0.517885   \n",
      "\n",
      "        95        96        97        98        99   100  \n",
      "0 -0.720541 -0.571446 -0.646337 -0.389948 -0.457720    1  \n",
      "1 -0.599028 -0.676013 -0.480160 -0.613610 -0.370215    1  \n",
      "2 -0.343216 -0.303520 -0.562161 -0.437906 -0.320803    1  \n",
      "3 -0.568110 -0.305216 -0.639422 -0.488318 -0.214943    1  \n",
      "4 -0.407225 -0.622817 -0.739634 -0.546709 -0.350312    1  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "# Add a new column 'Label' with all values set to 1\n",
    "reconstructed_df[100] = 1\n",
    "\n",
    "# Display the first few rows to verify the new column\n",
    "print(reconstructed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1247/1247 [==============================] - 1s 581us/step\n"
     ]
    }
   ],
   "source": [
    "num_samples_to_generate = 39888  # The number of new rows want to generate\n",
    "\n",
    "# Generate random samples from the latent space\n",
    "latent_dim = 16  # Ensure this matches the latent dimension size of  VAE\n",
    "z_new_samples = np.random.normal(size=(num_samples_to_generate, latent_dim))\n",
    "\n",
    "# Use the decoder to generate new data\n",
    "new_data_generated = vae.decoder.predict(z_new_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4450297 , -0.22294852, -0.3034466 , ..., -0.35437968,\n",
       "        -0.47133923, -0.2836992 ],\n",
       "       [-0.72759336, -0.6453137 , -0.45204452, ..., -0.3087919 ,\n",
       "        -0.46016502,  0.06936888],\n",
       "       [-0.40785375, -0.32768172, -0.33342355, ..., -0.5748681 ,\n",
       "        -0.2446973 , -0.27959502],\n",
       "       ...,\n",
       "       [-0.49384815, -0.77441335, -0.50638896, ..., -0.53581977,\n",
       "        -1.0080055 , -0.37307867],\n",
       "       [-0.410911  , -0.4628031 , -0.5406908 , ..., -0.5029852 ,\n",
       "        -0.60248905, -0.03458967],\n",
       "       [-0.30690894, -0.5111382 , -0.4811407 , ..., -0.7031956 ,\n",
       "        -0.5389546 , -0.45367998]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the generated data to a DataFrame\n",
    "new_data_df = pd.DataFrame(new_data_generated)\n",
    "\n",
    "# Add a column 'Label' with all values set to 1\n",
    "new_data_df[100] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_df = pd.concat([data_frame, new_data_df], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.046412</td>\n",
       "      <td>-0.058844</td>\n",
       "      <td>0.030492</td>\n",
       "      <td>-0.045302</td>\n",
       "      <td>-0.047853</td>\n",
       "      <td>-0.017467</td>\n",
       "      <td>0.049574</td>\n",
       "      <td>-0.033913</td>\n",
       "      <td>-0.039866</td>\n",
       "      <td>-0.073236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117293</td>\n",
       "      <td>0.031330</td>\n",
       "      <td>-0.265421</td>\n",
       "      <td>-0.020640</td>\n",
       "      <td>-0.166901</td>\n",
       "      <td>0.272434</td>\n",
       "      <td>0.110138</td>\n",
       "      <td>0.171606</td>\n",
       "      <td>0.299765</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.046412</td>\n",
       "      <td>-0.058844</td>\n",
       "      <td>0.030492</td>\n",
       "      <td>-0.045302</td>\n",
       "      <td>-0.047853</td>\n",
       "      <td>-0.017467</td>\n",
       "      <td>0.049574</td>\n",
       "      <td>-0.033913</td>\n",
       "      <td>-0.039866</td>\n",
       "      <td>-0.073236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>-0.358520</td>\n",
       "      <td>0.476823</td>\n",
       "      <td>-0.439907</td>\n",
       "      <td>0.063418</td>\n",
       "      <td>0.117955</td>\n",
       "      <td>0.029408</td>\n",
       "      <td>-0.054011</td>\n",
       "      <td>-0.026943</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.046412</td>\n",
       "      <td>-0.058844</td>\n",
       "      <td>0.030492</td>\n",
       "      <td>-0.045302</td>\n",
       "      <td>-0.047853</td>\n",
       "      <td>-0.017467</td>\n",
       "      <td>0.049574</td>\n",
       "      <td>-0.033913</td>\n",
       "      <td>-0.039866</td>\n",
       "      <td>-0.073236</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.236721</td>\n",
       "      <td>-0.386960</td>\n",
       "      <td>0.214320</td>\n",
       "      <td>0.207976</td>\n",
       "      <td>0.147840</td>\n",
       "      <td>0.355381</td>\n",
       "      <td>-0.277013</td>\n",
       "      <td>0.094609</td>\n",
       "      <td>0.033371</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.046412</td>\n",
       "      <td>-0.058844</td>\n",
       "      <td>0.030492</td>\n",
       "      <td>-0.045302</td>\n",
       "      <td>-0.047853</td>\n",
       "      <td>-0.017467</td>\n",
       "      <td>0.049574</td>\n",
       "      <td>-0.033913</td>\n",
       "      <td>-0.039866</td>\n",
       "      <td>-0.073236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284572</td>\n",
       "      <td>0.157956</td>\n",
       "      <td>-0.099907</td>\n",
       "      <td>0.066470</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.125655</td>\n",
       "      <td>-0.291628</td>\n",
       "      <td>-0.342115</td>\n",
       "      <td>-0.107380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.046412</td>\n",
       "      <td>-0.058844</td>\n",
       "      <td>0.030492</td>\n",
       "      <td>-0.045302</td>\n",
       "      <td>-0.047853</td>\n",
       "      <td>-0.017467</td>\n",
       "      <td>0.049574</td>\n",
       "      <td>-0.033913</td>\n",
       "      <td>-0.039866</td>\n",
       "      <td>-0.073236</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.172661</td>\n",
       "      <td>0.090018</td>\n",
       "      <td>0.142202</td>\n",
       "      <td>0.089949</td>\n",
       "      <td>0.180742</td>\n",
       "      <td>-0.046197</td>\n",
       "      <td>0.052328</td>\n",
       "      <td>-0.031697</td>\n",
       "      <td>-0.077126</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82723</th>\n",
       "      <td>-0.681225</td>\n",
       "      <td>-0.631664</td>\n",
       "      <td>-0.586629</td>\n",
       "      <td>-0.279244</td>\n",
       "      <td>-0.570045</td>\n",
       "      <td>-0.778755</td>\n",
       "      <td>-0.579645</td>\n",
       "      <td>-0.531065</td>\n",
       "      <td>-0.553003</td>\n",
       "      <td>-0.606099</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263636</td>\n",
       "      <td>-0.434946</td>\n",
       "      <td>-0.607003</td>\n",
       "      <td>-0.691970</td>\n",
       "      <td>-0.211970</td>\n",
       "      <td>-0.240839</td>\n",
       "      <td>-0.734272</td>\n",
       "      <td>-0.311152</td>\n",
       "      <td>-0.195251</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82724</th>\n",
       "      <td>-0.752199</td>\n",
       "      <td>-0.457726</td>\n",
       "      <td>-0.231432</td>\n",
       "      <td>-0.328189</td>\n",
       "      <td>-0.429773</td>\n",
       "      <td>-0.638683</td>\n",
       "      <td>-0.743695</td>\n",
       "      <td>-0.711249</td>\n",
       "      <td>-0.358762</td>\n",
       "      <td>-0.610126</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.475021</td>\n",
       "      <td>-0.280397</td>\n",
       "      <td>-0.720837</td>\n",
       "      <td>-0.410277</td>\n",
       "      <td>-0.291110</td>\n",
       "      <td>-0.442867</td>\n",
       "      <td>-0.514432</td>\n",
       "      <td>-0.602070</td>\n",
       "      <td>-0.171334</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82725</th>\n",
       "      <td>-0.493848</td>\n",
       "      <td>-0.774413</td>\n",
       "      <td>-0.506389</td>\n",
       "      <td>-0.262213</td>\n",
       "      <td>-0.488300</td>\n",
       "      <td>-0.342439</td>\n",
       "      <td>-0.640493</td>\n",
       "      <td>-0.601936</td>\n",
       "      <td>-0.553273</td>\n",
       "      <td>-1.082474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.492404</td>\n",
       "      <td>-0.310275</td>\n",
       "      <td>-0.677233</td>\n",
       "      <td>-0.554982</td>\n",
       "      <td>-0.310899</td>\n",
       "      <td>-0.708503</td>\n",
       "      <td>-0.535820</td>\n",
       "      <td>-1.008005</td>\n",
       "      <td>-0.373079</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82726</th>\n",
       "      <td>-0.410911</td>\n",
       "      <td>-0.462803</td>\n",
       "      <td>-0.540691</td>\n",
       "      <td>-0.747069</td>\n",
       "      <td>-0.337355</td>\n",
       "      <td>-0.321866</td>\n",
       "      <td>-0.348446</td>\n",
       "      <td>-0.647528</td>\n",
       "      <td>-0.268311</td>\n",
       "      <td>-0.709107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.602498</td>\n",
       "      <td>-0.246532</td>\n",
       "      <td>-0.979358</td>\n",
       "      <td>-0.204187</td>\n",
       "      <td>-0.526367</td>\n",
       "      <td>-0.827878</td>\n",
       "      <td>-0.502985</td>\n",
       "      <td>-0.602489</td>\n",
       "      <td>-0.034590</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82727</th>\n",
       "      <td>-0.306909</td>\n",
       "      <td>-0.511138</td>\n",
       "      <td>-0.481141</td>\n",
       "      <td>-0.354039</td>\n",
       "      <td>-0.699833</td>\n",
       "      <td>-0.261245</td>\n",
       "      <td>-0.593566</td>\n",
       "      <td>-0.448724</td>\n",
       "      <td>-0.466063</td>\n",
       "      <td>-0.439775</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.301994</td>\n",
       "      <td>-0.213983</td>\n",
       "      <td>-0.554476</td>\n",
       "      <td>-0.471314</td>\n",
       "      <td>-0.551549</td>\n",
       "      <td>-0.566068</td>\n",
       "      <td>-0.703196</td>\n",
       "      <td>-0.538955</td>\n",
       "      <td>-0.453680</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82728 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "0     -0.046412 -0.058844  0.030492 -0.045302 -0.047853 -0.017467  0.049574   \n",
       "1     -0.046412 -0.058844  0.030492 -0.045302 -0.047853 -0.017467  0.049574   \n",
       "2     -0.046412 -0.058844  0.030492 -0.045302 -0.047853 -0.017467  0.049574   \n",
       "3     -0.046412 -0.058844  0.030492 -0.045302 -0.047853 -0.017467  0.049574   \n",
       "4     -0.046412 -0.058844  0.030492 -0.045302 -0.047853 -0.017467  0.049574   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "82723 -0.681225 -0.631664 -0.586629 -0.279244 -0.570045 -0.778755 -0.579645   \n",
       "82724 -0.752199 -0.457726 -0.231432 -0.328189 -0.429773 -0.638683 -0.743695   \n",
       "82725 -0.493848 -0.774413 -0.506389 -0.262213 -0.488300 -0.342439 -0.640493   \n",
       "82726 -0.410911 -0.462803 -0.540691 -0.747069 -0.337355 -0.321866 -0.348446   \n",
       "82727 -0.306909 -0.511138 -0.481141 -0.354039 -0.699833 -0.261245 -0.593566   \n",
       "\n",
       "            7         8         9    ...       91        92        93   \\\n",
       "0     -0.033913 -0.039866 -0.073236  ...  0.117293  0.031330 -0.265421   \n",
       "1     -0.033913 -0.039866 -0.073236  ...  0.089552 -0.358520  0.476823   \n",
       "2     -0.033913 -0.039866 -0.073236  ... -0.236721 -0.386960  0.214320   \n",
       "3     -0.033913 -0.039866 -0.073236  ...  0.284572  0.157956 -0.099907   \n",
       "4     -0.033913 -0.039866 -0.073236  ... -0.172661  0.090018  0.142202   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "82723 -0.531065 -0.553003 -0.606099  ... -0.263636 -0.434946 -0.607003   \n",
       "82724 -0.711249 -0.358762 -0.610126  ... -0.475021 -0.280397 -0.720837   \n",
       "82725 -0.601936 -0.553273 -1.082474  ... -0.492404 -0.310275 -0.677233   \n",
       "82726 -0.647528 -0.268311 -0.709107  ... -0.602498 -0.246532 -0.979358   \n",
       "82727 -0.448724 -0.466063 -0.439775  ... -0.301994 -0.213983 -0.554476   \n",
       "\n",
       "            94        95        96        97        98        99   100  \n",
       "0     -0.020640 -0.166901  0.272434  0.110138  0.171606  0.299765  0.0  \n",
       "1     -0.439907  0.063418  0.117955  0.029408 -0.054011 -0.026943  0.0  \n",
       "2      0.207976  0.147840  0.355381 -0.277013  0.094609  0.033371  0.0  \n",
       "3      0.066470  0.001940  0.125655 -0.291628 -0.342115 -0.107380  0.0  \n",
       "4      0.089949  0.180742 -0.046197  0.052328 -0.031697 -0.077126  0.0  \n",
       "...         ...       ...       ...       ...       ...       ...  ...  \n",
       "82723 -0.691970 -0.211970 -0.240839 -0.734272 -0.311152 -0.195251  1.0  \n",
       "82724 -0.410277 -0.291110 -0.442867 -0.514432 -0.602070 -0.171334  1.0  \n",
       "82725 -0.554982 -0.310899 -0.708503 -0.535820 -1.008005 -0.373079  1.0  \n",
       "82726 -0.204187 -0.526367 -0.827878 -0.502985 -0.602489 -0.034590  1.0  \n",
       "82727 -0.471314 -0.551549 -0.566068 -0.703196 -0.538955 -0.453680  1.0  \n",
       "\n",
       "[82728 rows x 101 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='enhanced_final_new_par_50_space_1.csv'\n",
    "file_path = os.path.join(base_dir,'data','split',ltype, file_name)\n",
    "output_path = file_path\n",
    "enhanced_df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
