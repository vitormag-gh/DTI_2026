{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend as K\n",
    "\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def build_encoder(latent_dim=20):\n",
    "    encoder_inputs = layers.Input(shape=(100,)) #change here features*2\n",
    "    x = layers.Dense(256, activation='relu')(encoder_inputs)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    z_mean = layers.Dense(latent_dim)(x)\n",
    "    z_log_var = layers.Dense(latent_dim)(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    encoder = models.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "    return encoder\n",
    "\n",
    "def build_decoder(latent_dim=20):\n",
    "    latent_inputs = layers.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(64, activation='relu')(latent_inputs)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    decoder_outputs = layers.Dense(100, activation='linear')(x) #change here features*2\n",
    "    decoder = models.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "    return decoder\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        # Initialize trackers for monitoring losses\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # Return list of metrics to be updated during training\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(z)\n",
    "        # Compute KL divergence loss even during inference to track loss correctly\n",
    "        kl_loss = -0.5 * tf.reduce_mean(\n",
    "            1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\n",
    "        # Only add KL loss during training\n",
    "        if training:\n",
    "            self.add_loss(kl_loss)\n",
    "        return reconstructed\n",
    "\n",
    "    def train_step(self, data):\n",
    "    # Unpack the data\n",
    "        x = data[0] if isinstance(data, tuple) else data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(x, training=True)\n",
    "            reconstruction = self.decoder(z, training=True)\n",
    "\n",
    "            # If  data is flat (e.g., shape=(batch_size, features)), adjust axis accordingly\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(x, reconstruction), axis=-1\n",
    "            )\n",
    "            reconstruction_loss = tf.reduce_sum(reconstruction_loss)  # Sum over all dimensions\n",
    "\n",
    "            kl_loss = -0.5 * tf.reduce_mean(\n",
    "                1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1\n",
    "            )\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        return {'loss': total_loss, 'reconstruction_loss': reconstruction_loss, 'kl_loss': kl_loss}\n",
    "\n",
    "# Example usage:\n",
    "latent_dim = 16  \n",
    "encoder = build_encoder(latent_dim)\n",
    "decoder = build_decoder(latent_dim)\n",
    "vae = VAE(encoder, decoder)\n",
    "#vae.compile(optimizer='adam')\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relative paths. # Set directory paths for later use.\n",
    "# Get the directory of the script file\n",
    "base_dir = os.getcwd()\n",
    "base_dir\n",
    "ligants_type=['enzyme','GPCR','ion_channel','nuclear_receptor']\n",
    "ltype=ligants_type[2]\n",
    "file_name='final_new_par_NNMF_50.csv'\n",
    "file_path = os.path.join(base_dir,'data','split',ltype, file_name)\n",
    "output_path = file_path\n",
    "data_frame = pd.read_csv(file_path, header=None, skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include instances with label 1 (interactions)\n",
    "# Separate features and labels\n",
    "filtered_df = data_frame[data_frame.iloc[:, -1] == 1]  # All rows, all columns except the last one\n",
    "features_new = filtered_df.iloc[:, :-1]     # All rows, just the last column\n",
    "\n",
    "# Convert features DataFrame to a NumPy array if necessary\n",
    "x_train = features_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1476, 101)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para\n",
    "epochs=4\n",
    "batch_size=82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "18/18 [==============================] - 1s 2ms/step - loss: 0.5379 - reconstruction_loss: 0.4961 - kl_loss: 0.0114\n",
      "Epoch 2/4\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4216 - reconstruction_loss: 0.3904 - kl_loss: 0.0116\n",
      "Epoch 3/4\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3856 - reconstruction_loss: 0.3555 - kl_loss: 0.0290\n",
      "Epoch 4/4\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.3751 - reconstruction_loss: 0.3529 - kl_loss: 0.0258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c69e13dea0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "vae.fit(x_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include instances with label 1 (interactions)\n",
    "filtered_df = data_frame[data_frame.iloc[:, -1] == 1]\n",
    "\n",
    "# Separate features\n",
    "features_new = filtered_df.iloc[:, :-1]  # Assuming the last column is the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = features_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 716us/step\n"
     ]
    }
   ],
   "source": [
    "z_mean, z_log_var, z = vae.encoder.predict(x_new)\n",
    "# Now, z contains the latent representations of  filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 731us/step\n"
     ]
    }
   ],
   "source": [
    "reconstructed_new = vae.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0    1    2    3    4    5         6    7    8    9   ...   90  \\\n",
      "0     0.000001  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...  0.0   \n",
      "1     0.000001  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...  0.0   \n",
      "2     0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...  0.0   \n",
      "3     0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...  0.0   \n",
      "4     0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...  0.0   \n",
      "...        ...  ...  ...  ...  ...  ...       ...  ...  ...  ...  ...  ...   \n",
      "1471  0.000000  0.0  0.0  0.0  0.0  0.0  0.000097  0.0  0.0  0.0  ...  0.0   \n",
      "1472  0.000000  0.0  0.0  0.0  0.0  0.0  0.000097  0.0  0.0  0.0  ...  0.0   \n",
      "1473  0.000000  0.0  0.0  0.0  0.0  0.0  0.000097  0.0  0.0  0.0  ...  0.0   \n",
      "1474  0.000001  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...  0.0   \n",
      "1475  0.000001  0.0  0.0  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  ...  0.0   \n",
      "\n",
      "       91        92   93        94   95   96        97        98        99  \n",
      "0     0.0  3.979434  0.0  0.455377  0.0  0.0  0.000000  0.000000  0.100458  \n",
      "1     0.0  0.000000  0.0  0.455542  0.0  0.0  0.000009  0.035147  0.102933  \n",
      "2     0.0  0.000000  0.0  0.455542  0.0  0.0  0.000009  0.035147  0.102933  \n",
      "3     0.0  0.000000  0.0  0.000000  0.0  0.0  0.000402  0.000000  0.000000  \n",
      "4     0.0  0.000000  0.0  0.000000  0.0  0.0  0.000489  0.000000  0.000000  \n",
      "...   ...       ...  ...       ...  ...  ...       ...       ...       ...  \n",
      "1471  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000  0.000000  0.000000  \n",
      "1472  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000  0.000000  0.000000  \n",
      "1473  0.0  0.000000  0.0  0.455542  0.0  0.0  0.000009  0.035147  0.102933  \n",
      "1474  0.0  3.979434  0.0  0.455377  0.0  0.0  0.000000  0.000000  0.100458  \n",
      "1475  0.0  0.000000  0.0  0.455542  0.0  0.0  0.000009  0.035147  0.102933  \n",
      "\n",
      "[1476 rows x 100 columns]\n",
      "            0         1         2         3         4         5         6   \\\n",
      "0    -0.103633  0.537927  0.307721 -0.524982 -0.573096 -0.842427 -0.470250   \n",
      "1    -0.221411  0.571787  0.518317 -0.339802 -0.444134 -0.479660 -0.444461   \n",
      "2     0.072201  0.239301  0.284505 -0.576310 -0.368644 -0.660404 -0.403455   \n",
      "3     0.280037  0.391957  0.286961 -0.450765 -0.743511 -1.079902 -0.553522   \n",
      "4     0.226580  0.482498  0.366701 -0.269267 -1.203532 -1.215584 -1.121308   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1471 -0.385307  0.359662  0.587596 -0.322720 -0.562056 -0.506832 -0.240375   \n",
      "1472 -0.082025  0.478950  0.371385 -0.351455 -0.566605 -0.959701 -0.526708   \n",
      "1473  0.152177  0.903406  0.422239 -0.730849 -0.981262 -1.384514 -1.022473   \n",
      "1474  0.327114  0.488454  0.380143 -0.477217 -0.434179 -0.679537 -0.604640   \n",
      "1475 -0.109789  0.518253  0.664142 -0.651538 -0.564886 -0.741412 -0.384762   \n",
      "\n",
      "            7         8         9   ...        90        91        92  \\\n",
      "0    -0.368201  0.164712  0.119853  ... -0.406583 -0.636139  0.483447   \n",
      "1    -0.037358  0.318593  0.210779  ... -0.495007 -0.315443  0.307611   \n",
      "2    -0.369000  0.244358  0.364121  ... -0.527135 -0.349347  0.097012   \n",
      "3    -0.066083  0.213450  0.067472  ... -0.235770 -0.365850  0.218065   \n",
      "4    -0.807296  0.581099  0.222833  ... -0.609328 -0.700005  0.304258   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1471 -0.761252  0.299235  0.263524  ... -0.614835 -0.573484 -0.113716   \n",
      "1472 -0.810610  0.066596  0.081781  ... -0.683241 -0.511166  0.476807   \n",
      "1473 -0.839736  0.584717 -0.008372  ... -0.835557 -0.726099  0.838467   \n",
      "1474 -0.533230  0.307526  0.014379  ... -0.526364 -0.525037  0.468025   \n",
      "1475 -0.409528  0.118591  0.172688  ... -0.622292 -0.390703  0.427335   \n",
      "\n",
      "            93        94        95        96        97        98        99  \n",
      "0    -0.546807  0.110442 -0.584639 -0.397673 -0.385557 -0.711293 -0.342193  \n",
      "1    -0.362484  0.332685 -0.273009 -0.478761 -0.589241 -0.462893 -0.367750  \n",
      "2    -0.320928  0.137036 -0.794496 -0.617382 -0.528268 -0.550326 -0.208302  \n",
      "3    -0.366467 -0.137946 -0.648309 -0.289637 -0.692245 -0.790207 -0.544739  \n",
      "4    -0.855834  0.429490 -0.647379 -1.031878 -0.661754 -1.229188 -0.624794  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "1471 -0.292729  0.000527 -0.250618 -0.491112 -0.447774 -0.846750 -0.252795  \n",
      "1472 -0.690091 -0.028124 -1.032117 -0.694640 -0.601981 -0.684267 -0.407895  \n",
      "1473 -0.736631  0.488959 -0.510515 -1.034778 -0.532715 -0.821890 -0.406863  \n",
      "1474 -0.343055  0.184621 -0.308218 -0.458396 -0.647606 -0.738930  0.016674  \n",
      "1475 -0.756287  0.411852 -0.647140 -0.663404 -0.917958 -0.563777 -0.353453  \n",
      "\n",
      "[1476 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the reconstructed data to a DataFrame\n",
    "reconstructed_df = pd.DataFrame(reconstructed_new)\n",
    "\n",
    "# Display the first few rows of the reconstructed DataFrame\n",
    "print(pd.DataFrame(x_new))\n",
    "print(reconstructed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0 -0.103633  0.537927  0.307721 -0.524982 -0.573096 -0.842427 -0.470250   \n",
      "1 -0.221411  0.571787  0.518317 -0.339802 -0.444134 -0.479660 -0.444461   \n",
      "2  0.072201  0.239301  0.284505 -0.576310 -0.368644 -0.660404 -0.403455   \n",
      "3  0.280037  0.391957  0.286961 -0.450765 -0.743511 -1.079902 -0.553522   \n",
      "4  0.226580  0.482498  0.366701 -0.269267 -1.203532 -1.215584 -1.121308   \n",
      "\n",
      "        7         8         9    ...       91        92        93        94   \\\n",
      "0 -0.368201  0.164712  0.119853  ... -0.636139  0.483447 -0.546807  0.110442   \n",
      "1 -0.037358  0.318593  0.210779  ... -0.315443  0.307611 -0.362484  0.332685   \n",
      "2 -0.369000  0.244358  0.364121  ... -0.349347  0.097012 -0.320928  0.137036   \n",
      "3 -0.066083  0.213450  0.067472  ... -0.365850  0.218065 -0.366467 -0.137946   \n",
      "4 -0.807296  0.581099  0.222833  ... -0.700005  0.304258 -0.855834  0.429490   \n",
      "\n",
      "        95        96        97        98        99   100  \n",
      "0 -0.584639 -0.397673 -0.385557 -0.711293 -0.342193    1  \n",
      "1 -0.273009 -0.478761 -0.589241 -0.462893 -0.367750    1  \n",
      "2 -0.794496 -0.617382 -0.528268 -0.550326 -0.208302    1  \n",
      "3 -0.648309 -0.289637 -0.692245 -0.790207 -0.544739    1  \n",
      "4 -0.647379 -1.031878 -0.661754 -1.229188 -0.624794    1  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "# Add a new column 'Label' with all values set to 1\n",
    "reconstructed_df[100] = 1\n",
    "\n",
    "# Display the first few rows to verify the new column\n",
    "print(reconstructed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1247/1247 [==============================] - 1s 557us/step\n"
     ]
    }
   ],
   "source": [
    "num_samples_to_generate = 39888  # The number of new rows want to generate\n",
    "\n",
    "# Generate random samples from the latent space\n",
    "latent_dim = 16  # Ensure this matches the latent dimension size of  VAE\n",
    "z_new_samples = np.random.normal(size=(num_samples_to_generate, latent_dim))\n",
    "\n",
    "# Use the decoder to generate new data\n",
    "new_data_generated = vae.decoder.predict(z_new_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.69774914,  0.4741873 ,  0.10174187, ..., -0.4961947 ,\n",
       "        -0.52582306, -0.3121771 ],\n",
       "       [ 0.00816039,  0.19777365,  0.3355031 , ..., -0.5325238 ,\n",
       "        -0.4979144 , -0.5786872 ],\n",
       "       [-0.02794106,  0.18283619,  0.5500798 , ..., -0.6530952 ,\n",
       "        -0.7283457 , -0.29689863],\n",
       "       ...,\n",
       "       [ 0.5801007 ,  0.5647589 ,  0.37657687, ..., -0.7875252 ,\n",
       "        -0.6218484 , -0.62546796],\n",
       "       [ 0.0514942 ,  0.16818334,  0.3657479 , ..., -0.3961527 ,\n",
       "        -0.3736639 , -0.44073653],\n",
       "       [-0.07328035,  0.5365022 ,  0.25343615, ..., -0.24855587,\n",
       "        -0.43090078, -0.6993154 ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the generated data to a DataFrame\n",
    "new_data_df = pd.DataFrame(new_data_generated)\n",
    "\n",
    "# Add a column 'Label' with all values set to 1\n",
    "new_data_df[100] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_df = pd.concat([data_frame, new_data_df], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.610382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82723</th>\n",
       "      <td>0.350601</td>\n",
       "      <td>0.554283</td>\n",
       "      <td>0.383642</td>\n",
       "      <td>-0.390014</td>\n",
       "      <td>-0.595315</td>\n",
       "      <td>-0.673903</td>\n",
       "      <td>-0.559212</td>\n",
       "      <td>-0.772193</td>\n",
       "      <td>0.272257</td>\n",
       "      <td>0.180662</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.427087</td>\n",
       "      <td>0.342019</td>\n",
       "      <td>-0.447427</td>\n",
       "      <td>0.042554</td>\n",
       "      <td>-0.354853</td>\n",
       "      <td>-0.650851</td>\n",
       "      <td>-0.439533</td>\n",
       "      <td>-0.552443</td>\n",
       "      <td>-0.362309</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82724</th>\n",
       "      <td>0.639235</td>\n",
       "      <td>0.854969</td>\n",
       "      <td>0.640124</td>\n",
       "      <td>-0.730812</td>\n",
       "      <td>-0.648968</td>\n",
       "      <td>-0.908939</td>\n",
       "      <td>-0.655599</td>\n",
       "      <td>-0.752058</td>\n",
       "      <td>0.164801</td>\n",
       "      <td>0.018587</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.603367</td>\n",
       "      <td>0.858650</td>\n",
       "      <td>-0.557059</td>\n",
       "      <td>0.328288</td>\n",
       "      <td>-0.458486</td>\n",
       "      <td>-0.987577</td>\n",
       "      <td>-1.172547</td>\n",
       "      <td>-1.060778</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82725</th>\n",
       "      <td>0.580101</td>\n",
       "      <td>0.564759</td>\n",
       "      <td>0.376577</td>\n",
       "      <td>-0.527779</td>\n",
       "      <td>-0.282143</td>\n",
       "      <td>-1.135035</td>\n",
       "      <td>-0.318924</td>\n",
       "      <td>-1.017934</td>\n",
       "      <td>0.045957</td>\n",
       "      <td>-0.113918</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.335162</td>\n",
       "      <td>0.410498</td>\n",
       "      <td>-0.915534</td>\n",
       "      <td>0.019921</td>\n",
       "      <td>-0.490301</td>\n",
       "      <td>-0.595338</td>\n",
       "      <td>-0.787525</td>\n",
       "      <td>-0.621848</td>\n",
       "      <td>-0.625468</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82726</th>\n",
       "      <td>0.051494</td>\n",
       "      <td>0.168183</td>\n",
       "      <td>0.365748</td>\n",
       "      <td>-0.122101</td>\n",
       "      <td>-0.359340</td>\n",
       "      <td>-0.939162</td>\n",
       "      <td>-0.619560</td>\n",
       "      <td>-0.520777</td>\n",
       "      <td>0.553453</td>\n",
       "      <td>0.257805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.571778</td>\n",
       "      <td>0.159481</td>\n",
       "      <td>-0.445224</td>\n",
       "      <td>0.223576</td>\n",
       "      <td>-0.461257</td>\n",
       "      <td>-0.577598</td>\n",
       "      <td>-0.396153</td>\n",
       "      <td>-0.373664</td>\n",
       "      <td>-0.440737</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82727</th>\n",
       "      <td>-0.073280</td>\n",
       "      <td>0.536502</td>\n",
       "      <td>0.253436</td>\n",
       "      <td>-0.260704</td>\n",
       "      <td>-0.603051</td>\n",
       "      <td>-0.590912</td>\n",
       "      <td>-0.231210</td>\n",
       "      <td>-0.252133</td>\n",
       "      <td>0.102903</td>\n",
       "      <td>0.248786</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.396283</td>\n",
       "      <td>0.118735</td>\n",
       "      <td>-0.520027</td>\n",
       "      <td>-0.117427</td>\n",
       "      <td>-0.311703</td>\n",
       "      <td>-0.327879</td>\n",
       "      <td>-0.248556</td>\n",
       "      <td>-0.430901</td>\n",
       "      <td>-0.699315</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82728 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "0      0.000001  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1      0.000001  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2      0.000001  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3      0.000001  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4      0.000001  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "82723  0.350601  0.554283  0.383642 -0.390014 -0.595315 -0.673903 -0.559212   \n",
       "82724  0.639235  0.854969  0.640124 -0.730812 -0.648968 -0.908939 -0.655599   \n",
       "82725  0.580101  0.564759  0.376577 -0.527779 -0.282143 -1.135035 -0.318924   \n",
       "82726  0.051494  0.168183  0.365748 -0.122101 -0.359340 -0.939162 -0.619560   \n",
       "82727 -0.073280  0.536502  0.253436 -0.260704 -0.603051 -0.590912 -0.231210   \n",
       "\n",
       "            7         8         9    ...       91        92        93   \\\n",
       "0      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1      0.000000  0.000000  0.000000  ...  0.000000  0.000000  1.610382   \n",
       "2      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "3      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "4      0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "82723 -0.772193  0.272257  0.180662  ... -0.427087  0.342019 -0.447427   \n",
       "82724 -0.752058  0.164801  0.018587  ... -0.603367  0.858650 -0.557059   \n",
       "82725 -1.017934  0.045957 -0.113918  ... -0.335162  0.410498 -0.915534   \n",
       "82726 -0.520777  0.553453  0.257805  ... -0.571778  0.159481 -0.445224   \n",
       "82727 -0.252133  0.102903  0.248786  ... -0.396283  0.118735 -0.520027   \n",
       "\n",
       "            94        95        96        97        98        99   100  \n",
       "0      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  \n",
       "1      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  \n",
       "2      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  \n",
       "3      0.000000  0.000000  0.030178  0.000000  0.000000  0.000000  0.0  \n",
       "4      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  \n",
       "...         ...       ...       ...       ...       ...       ...  ...  \n",
       "82723  0.042554 -0.354853 -0.650851 -0.439533 -0.552443 -0.362309  1.0  \n",
       "82724  0.328288 -0.458486 -0.987577 -1.172547 -1.060778  0.002433  1.0  \n",
       "82725  0.019921 -0.490301 -0.595338 -0.787525 -0.621848 -0.625468  1.0  \n",
       "82726  0.223576 -0.461257 -0.577598 -0.396153 -0.373664 -0.440737  1.0  \n",
       "82727 -0.117427 -0.311703 -0.327879 -0.248556 -0.430901 -0.699315  1.0  \n",
       "\n",
       "[82728 rows x 101 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='enhanced_VAE_final_new_par_50_NNMF_space_2.csv'\n",
    "file_path = os.path.join(base_dir,'data','split',ltype, file_name)\n",
    "output_path = file_path\n",
    "enhanced_df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
