{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "C:\\Users\\riskf\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend as K\n",
    "\n",
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def build_encoder(latent_dim=20):\n",
    "    encoder_inputs = layers.Input(shape=(100,)) #change here features*2\n",
    "    x = layers.Dense(256, activation='relu')(encoder_inputs)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    z_mean = layers.Dense(latent_dim)(x)\n",
    "    z_log_var = layers.Dense(latent_dim)(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    encoder = models.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "    return encoder\n",
    "\n",
    "def build_decoder(latent_dim=20):\n",
    "    latent_inputs = layers.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(64, activation='relu')(latent_inputs)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    decoder_outputs = layers.Dense(100, activation='linear')(x) #change here features*2\n",
    "    decoder = models.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "    return decoder\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        # Initialize trackers for monitoring losses\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # Return list of metrics to be updated during training\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstructed = self.decoder(z)\n",
    "        # Compute KL divergence loss even during inference to track loss correctly\n",
    "        kl_loss = -0.5 * tf.reduce_mean(\n",
    "            1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\n",
    "        # Only add KL loss during training\n",
    "        if training:\n",
    "            self.add_loss(kl_loss)\n",
    "        return reconstructed\n",
    "\n",
    "    def train_step(self, data):\n",
    "    # Unpack the data\n",
    "        x = data[0] if isinstance(data, tuple) else data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(x, training=True)\n",
    "            reconstruction = self.decoder(z, training=True)\n",
    "\n",
    "            # If  data is flat (e.g., shape=(batch_size, features)), adjust axis accordingly\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                keras.losses.binary_crossentropy(x, reconstruction), axis=-1\n",
    "            )\n",
    "            reconstruction_loss = tf.reduce_sum(reconstruction_loss)  # Sum over all dimensions\n",
    "\n",
    "            kl_loss = -0.5 * tf.reduce_mean(\n",
    "                1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1\n",
    "            )\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        return {'loss': total_loss, 'reconstruction_loss': reconstruction_loss, 'kl_loss': kl_loss}\n",
    "\n",
    "# Example usage:\n",
    "latent_dim = 16  \n",
    "encoder = build_encoder(latent_dim)\n",
    "decoder = build_decoder(latent_dim)\n",
    "vae = VAE(encoder, decoder)\n",
    "#vae.compile(optimizer='adam')\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relative paths. # Set directory paths for later use.\n",
    "# Get the directory of the script file\n",
    "base_dir = os.getcwd()\n",
    "base_dir\n",
    "ligants_type=['enzyme','GPCR','ion_channel','nuclear_receptor']\n",
    "ltype=ligants_type[3]\n",
    "file_name='final_new_par_50.csv'\n",
    "file_path = os.path.join(base_dir,'data','split',ltype, file_name)\n",
    "output_path = file_path\n",
    "data_frame = pd.read_csv(file_path, header=None, skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include instances with label 1 (interactions)\n",
    "# Separate features and labels\n",
    "filtered_df = data_frame[data_frame.iloc[:, -1] == 1]  # All rows, all columns except the last one\n",
    "features_new = filtered_df.iloc[:, :-1]     # All rows, just the last column\n",
    "\n",
    "# Convert features DataFrame to a NumPy array if necessary\n",
    "x_train = features_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 101)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para\n",
    "epochs=4\n",
    "batch_size=45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "2/2 [==============================] - 1s 6ms/step - loss: 0.2081 - reconstruction_loss: 0.1985 - kl_loss: 0.0077\n",
      "Epoch 2/4\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1390 - reconstruction_loss: 0.0799 - kl_loss: 0.0056\n",
      "Epoch 3/4\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1180 - reconstruction_loss: 0.1105 - kl_loss: 0.0066\n",
      "Epoch 4/4\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0877 - reconstruction_loss: 0.0649 - kl_loss: 0.0074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c61e125630>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "vae.fit(x_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include instances with label 1 (interactions)\n",
    "filtered_df = data_frame[data_frame.iloc[:, -1] == 1]\n",
    "\n",
    "# Separate features\n",
    "features_new = filtered_df.iloc[:, :-1]  # Assuming the last column is the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = features_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "z_mean, z_log_var, z = vae.encoder.predict(x_new)\n",
    "# Now, z contains the latent representations of  filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "reconstructed_new = vae.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6   \\\n",
      "0  -0.111270  0.008626 -0.112308 -0.022436  0.084521  0.016578 -0.158669   \n",
      "1   0.404820  0.118141  0.452118 -0.074957 -0.062593  0.706790 -0.101757   \n",
      "2   0.404820  0.118141  0.452118 -0.074957 -0.062593  0.706790 -0.101757   \n",
      "3   0.404820  0.118141  0.452118 -0.074957 -0.062593  0.706790 -0.101757   \n",
      "4   0.404820  0.118141  0.452118 -0.074957 -0.062593  0.706790 -0.101757   \n",
      "..       ...       ...       ...       ...       ...       ...       ...   \n",
      "85 -0.197877  0.131798  0.284894  0.033694 -0.090001 -0.126484  0.254990   \n",
      "86 -0.197877  0.131798  0.284894  0.033694 -0.090001 -0.126484  0.254990   \n",
      "87 -0.197877  0.131798  0.284894  0.033694 -0.090001 -0.126484  0.254990   \n",
      "88  0.075678 -0.031658  0.055676 -0.030348 -0.079173 -0.121744  0.058323   \n",
      "89 -0.011902 -0.035561 -0.130223 -0.044128  0.034009 -0.115561 -0.062005   \n",
      "\n",
      "          7         8         9   ...        90        91        92        93  \\\n",
      "0  -0.079974  0.223279  0.033481  ... -0.144936  0.225076 -0.126947  0.231843   \n",
      "1   0.483554 -0.278148  0.072824  ...  0.023572 -0.018210 -0.094529 -0.008272   \n",
      "2   0.483554 -0.278148  0.072824  ... -0.043584  0.042791 -0.079722  0.102271   \n",
      "3   0.483554 -0.278148  0.072824  ...  0.017208  0.162473  0.010227  0.198440   \n",
      "4   0.483554 -0.278148  0.072824  ... -0.043584  0.042791 -0.079722  0.102271   \n",
      "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
      "85  0.138324  0.064390  0.127990  ...  0.233541 -0.148027 -0.218500 -0.124377   \n",
      "86  0.138324  0.064390  0.127990  ...  0.233541 -0.148027 -0.218500 -0.124377   \n",
      "87  0.138324  0.064390  0.127990  ...  0.233541 -0.148027 -0.218500 -0.124377   \n",
      "88  0.023643  0.034901 -0.192891  ... -0.035847  0.105424 -0.120578 -0.221069   \n",
      "89  0.187097 -0.069255 -0.092248  ...  0.157739 -0.129385 -0.018702  0.038323   \n",
      "\n",
      "          94        95        96        97        98        99  \n",
      "0   0.183467 -0.001382 -0.264238  0.032023 -0.107314 -0.019040  \n",
      "1  -0.045378 -0.252298  0.047064 -0.177535  0.144204  0.012367  \n",
      "2   0.001523 -0.077309 -0.041517 -0.067451  0.027401 -0.037864  \n",
      "3   0.050993  0.095779  0.112381  0.160828  0.057924 -0.072772  \n",
      "4   0.001523 -0.077309 -0.041517 -0.067451  0.027401 -0.037864  \n",
      "..       ...       ...       ...       ...       ...       ...  \n",
      "85 -0.055650 -0.062886  0.037402  0.001940 -0.039698 -0.040340  \n",
      "86 -0.055650 -0.062886  0.037402  0.001940 -0.039698 -0.040340  \n",
      "87 -0.055650 -0.062886  0.037402  0.001940 -0.039698 -0.040340  \n",
      "88 -0.220299  0.027060  0.100073  0.090513 -0.080443 -0.032378  \n",
      "89  0.225399 -0.187833  0.103845  0.162003 -0.191234  0.005783  \n",
      "\n",
      "[90 rows x 100 columns]\n",
      "          0         1         2         3         4         5         6   \\\n",
      "0  -0.292419  0.100761 -0.214540 -0.128120 -0.137349 -0.083648 -0.214622   \n",
      "1  -0.506139  0.182735  0.253912 -0.123106 -0.391820  0.032372 -0.244451   \n",
      "2  -0.194849  0.033693  0.098197 -0.049577 -0.142657 -0.002021  0.179296   \n",
      "3  -0.011516  0.053434  0.277638 -0.008508 -0.308292  0.111951 -0.076099   \n",
      "4  -0.084857 -0.038653  0.220638  0.118545 -0.233726  0.280457  0.009732   \n",
      "..       ...       ...       ...       ...       ...       ...       ...   \n",
      "85 -0.302931  0.106155 -0.078703 -0.115097 -0.657390 -0.029044  0.022880   \n",
      "86  0.203406  0.225585  0.148088 -0.294241 -0.210325  0.094133  0.133121   \n",
      "87 -0.291335  0.057899  0.172125 -0.093609 -0.163854  0.068418 -0.000685   \n",
      "88 -0.144072  0.097677  0.208208  0.013700 -0.311138  0.102057 -0.086634   \n",
      "89 -0.154760  0.013262  0.203998  0.058197 -0.182868  0.321223 -0.316775   \n",
      "\n",
      "          7         8         9   ...        90        91        92        93  \\\n",
      "0   0.227798 -0.326102  0.353781  ... -0.060838 -0.225842 -0.064208  0.219204   \n",
      "1   0.696048 -0.802705  0.280618  ... -0.061945 -0.425340 -0.179115  0.410294   \n",
      "2   0.272113 -0.335388  0.105428  ... -0.129571 -0.134091 -0.149261  0.085183   \n",
      "3   0.197168 -0.169586  0.176682  ... -0.024660 -0.353359 -0.398614  0.051616   \n",
      "4   0.372805 -0.400499  0.080946  ...  0.155218 -0.512369 -0.484125  0.040205   \n",
      "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
      "85  0.104558 -0.557513  0.336034  ... -0.069381 -0.276421 -0.226300  0.287427   \n",
      "86  0.328044 -0.543427  0.013853  ...  0.134534 -0.582163 -0.211666  0.107803   \n",
      "87  0.310732 -0.302797  0.173538  ... -0.062226 -0.231258 -0.376475  0.029083   \n",
      "88  0.182865 -0.515210  0.161643  ... -0.083235 -0.383187 -0.154559  0.053885   \n",
      "89  0.129754 -0.243370  0.239853  ...  0.025073 -0.115209 -0.314548  0.397618   \n",
      "\n",
      "          94        95        96        97        98        99  \n",
      "0   0.185292 -0.310074 -0.005344  0.219437 -0.398108  0.077507  \n",
      "1   0.269959 -0.050262 -0.388709 -0.011691 -0.495919 -0.207595  \n",
      "2  -0.097674 -0.091558 -0.090584  0.038999 -0.129367 -0.201971  \n",
      "3   0.004061  0.182673 -0.416026 -0.135109 -0.135762 -0.406018  \n",
      "4   0.159244  0.185630 -0.321324 -0.099785 -0.136805 -0.307824  \n",
      "..       ...       ...       ...       ...       ...       ...  \n",
      "85 -0.208462 -0.269020  0.001415 -0.193826 -0.395629 -0.022917  \n",
      "86 -0.400034  0.002741 -0.499868 -0.266510 -0.146042 -0.482202  \n",
      "87  0.051152  0.021519 -0.313274 -0.113996 -0.068659 -0.549243  \n",
      "88  0.067843 -0.327218  0.042827  0.264996 -0.154984 -0.129691  \n",
      "89 -0.051790  0.174393 -0.322652 -0.107657 -0.108526 -0.214088  \n",
      "\n",
      "[90 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the reconstructed data to a DataFrame\n",
    "reconstructed_df = pd.DataFrame(reconstructed_new)\n",
    "\n",
    "# Display the first few rows of the reconstructed DataFrame\n",
    "print(pd.DataFrame(x_new))\n",
    "print(reconstructed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0 -0.292419  0.100761 -0.214540 -0.128120 -0.137349 -0.083648 -0.214622   \n",
      "1 -0.506139  0.182735  0.253912 -0.123106 -0.391820  0.032372 -0.244451   \n",
      "2 -0.194849  0.033693  0.098197 -0.049577 -0.142657 -0.002021  0.179296   \n",
      "3 -0.011516  0.053434  0.277638 -0.008508 -0.308292  0.111951 -0.076099   \n",
      "4 -0.084857 -0.038653  0.220638  0.118545 -0.233726  0.280457  0.009732   \n",
      "\n",
      "        7         8         9    ...       91        92        93        94   \\\n",
      "0  0.227798 -0.326102  0.353781  ... -0.225842 -0.064208  0.219204  0.185292   \n",
      "1  0.696048 -0.802705  0.280618  ... -0.425340 -0.179115  0.410294  0.269959   \n",
      "2  0.272113 -0.335388  0.105428  ... -0.134091 -0.149261  0.085183 -0.097674   \n",
      "3  0.197168 -0.169586  0.176682  ... -0.353359 -0.398614  0.051616  0.004061   \n",
      "4  0.372805 -0.400499  0.080946  ... -0.512369 -0.484125  0.040205  0.159244   \n",
      "\n",
      "        95        96        97        98        99   100  \n",
      "0 -0.310074 -0.005344  0.219437 -0.398108  0.077507    1  \n",
      "1 -0.050262 -0.388709 -0.011691 -0.495919 -0.207595    1  \n",
      "2 -0.091558 -0.090584  0.038999 -0.129367 -0.201971    1  \n",
      "3  0.182673 -0.416026 -0.135109 -0.135762 -0.406018    1  \n",
      "4  0.185630 -0.321324 -0.099785 -0.136805 -0.307824    1  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "# Add a new column 'Label' with all values set to 1\n",
    "reconstructed_df[100] = 1\n",
    "\n",
    "# Display the first few rows to verify the new column\n",
    "print(reconstructed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 654us/step\n"
     ]
    }
   ],
   "source": [
    "num_samples_to_generate = 1224  # The number of new rows want to generate\n",
    "\n",
    "# Generate random samples from the latent space\n",
    "latent_dim = 16  # Ensure this matches the latent dimension size of  VAE\n",
    "z_new_samples = np.random.normal(size=(num_samples_to_generate, latent_dim))\n",
    "\n",
    "# Use the decoder to generate new data\n",
    "new_data_generated = vae.decoder.predict(z_new_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09123705,  0.06339117, -0.17144644, ..., -0.0630437 ,\n",
       "        -0.50806636, -0.13034306],\n",
       "       [ 0.08614964,  0.2854382 ,  0.1268754 , ..., -0.12161686,\n",
       "        -0.05624686, -0.4340832 ],\n",
       "       [-0.19427133, -0.22305417,  0.36385834, ..., -0.34575555,\n",
       "        -0.55573475, -0.41676787],\n",
       "       ...,\n",
       "       [-0.3581043 ,  0.30615392,  0.30374143, ...,  0.25461277,\n",
       "        -0.13223541, -0.47395644],\n",
       "       [-0.07534185,  0.19252378, -0.09778434, ...,  0.02933992,\n",
       "        -0.35277668, -0.06226281],\n",
       "       [-0.03117191, -0.03090625,  0.00302742, ..., -0.00437047,\n",
       "        -0.11266375, -0.26539537]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the generated data to a DataFrame\n",
    "new_data_df = pd.DataFrame(new_data_generated)\n",
    "\n",
    "# Add a column 'Label' with all values set to 1\n",
    "new_data_df[100] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_df = pd.concat([data_frame, new_data_df], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.111270</td>\n",
       "      <td>0.008626</td>\n",
       "      <td>-0.112308</td>\n",
       "      <td>-0.022436</td>\n",
       "      <td>0.084521</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>-0.158669</td>\n",
       "      <td>-0.079974</td>\n",
       "      <td>0.223279</td>\n",
       "      <td>0.033481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283005</td>\n",
       "      <td>0.085423</td>\n",
       "      <td>-0.062640</td>\n",
       "      <td>0.161380</td>\n",
       "      <td>-0.122537</td>\n",
       "      <td>0.115114</td>\n",
       "      <td>-0.053795</td>\n",
       "      <td>-0.214284</td>\n",
       "      <td>0.233027</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.111270</td>\n",
       "      <td>0.008626</td>\n",
       "      <td>-0.112308</td>\n",
       "      <td>-0.022436</td>\n",
       "      <td>0.084521</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>-0.158669</td>\n",
       "      <td>-0.079974</td>\n",
       "      <td>0.223279</td>\n",
       "      <td>0.033481</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018210</td>\n",
       "      <td>-0.094529</td>\n",
       "      <td>-0.008272</td>\n",
       "      <td>-0.045378</td>\n",
       "      <td>-0.252298</td>\n",
       "      <td>0.047064</td>\n",
       "      <td>-0.177535</td>\n",
       "      <td>0.144204</td>\n",
       "      <td>0.012367</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.111270</td>\n",
       "      <td>0.008626</td>\n",
       "      <td>-0.112308</td>\n",
       "      <td>-0.022436</td>\n",
       "      <td>0.084521</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>-0.158669</td>\n",
       "      <td>-0.079974</td>\n",
       "      <td>0.223279</td>\n",
       "      <td>0.033481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042791</td>\n",
       "      <td>-0.079722</td>\n",
       "      <td>0.102271</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>-0.077309</td>\n",
       "      <td>-0.041517</td>\n",
       "      <td>-0.067451</td>\n",
       "      <td>0.027401</td>\n",
       "      <td>-0.037864</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.111270</td>\n",
       "      <td>0.008626</td>\n",
       "      <td>-0.112308</td>\n",
       "      <td>-0.022436</td>\n",
       "      <td>0.084521</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>-0.158669</td>\n",
       "      <td>-0.079974</td>\n",
       "      <td>0.223279</td>\n",
       "      <td>0.033481</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120547</td>\n",
       "      <td>0.099485</td>\n",
       "      <td>-0.063370</td>\n",
       "      <td>0.007632</td>\n",
       "      <td>0.123424</td>\n",
       "      <td>0.068034</td>\n",
       "      <td>-0.028188</td>\n",
       "      <td>-0.256661</td>\n",
       "      <td>0.122674</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.111270</td>\n",
       "      <td>0.008626</td>\n",
       "      <td>-0.112308</td>\n",
       "      <td>-0.022436</td>\n",
       "      <td>0.084521</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>-0.158669</td>\n",
       "      <td>-0.079974</td>\n",
       "      <td>0.223279</td>\n",
       "      <td>0.033481</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080258</td>\n",
       "      <td>-0.229467</td>\n",
       "      <td>0.045752</td>\n",
       "      <td>-0.064296</td>\n",
       "      <td>0.134913</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.054669</td>\n",
       "      <td>-0.196582</td>\n",
       "      <td>-0.041674</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>-0.346970</td>\n",
       "      <td>0.252749</td>\n",
       "      <td>0.043169</td>\n",
       "      <td>0.038911</td>\n",
       "      <td>-0.546259</td>\n",
       "      <td>0.029881</td>\n",
       "      <td>-0.065755</td>\n",
       "      <td>0.435748</td>\n",
       "      <td>-0.454515</td>\n",
       "      <td>0.079702</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.581142</td>\n",
       "      <td>-0.323180</td>\n",
       "      <td>0.058032</td>\n",
       "      <td>0.143102</td>\n",
       "      <td>0.117994</td>\n",
       "      <td>-0.191738</td>\n",
       "      <td>0.060826</td>\n",
       "      <td>-0.030575</td>\n",
       "      <td>-0.436335</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>-0.366686</td>\n",
       "      <td>-0.029260</td>\n",
       "      <td>0.026956</td>\n",
       "      <td>0.075629</td>\n",
       "      <td>-0.184772</td>\n",
       "      <td>-0.112145</td>\n",
       "      <td>-0.129582</td>\n",
       "      <td>0.202685</td>\n",
       "      <td>-0.137362</td>\n",
       "      <td>0.136930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192703</td>\n",
       "      <td>-0.278295</td>\n",
       "      <td>0.225270</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>0.019151</td>\n",
       "      <td>-0.165369</td>\n",
       "      <td>0.046116</td>\n",
       "      <td>-0.168530</td>\n",
       "      <td>-0.170307</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>-0.358104</td>\n",
       "      <td>0.306154</td>\n",
       "      <td>0.303741</td>\n",
       "      <td>-0.078911</td>\n",
       "      <td>-0.223747</td>\n",
       "      <td>-0.293677</td>\n",
       "      <td>-0.188593</td>\n",
       "      <td>0.754108</td>\n",
       "      <td>-0.529041</td>\n",
       "      <td>0.165997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.438769</td>\n",
       "      <td>-0.420876</td>\n",
       "      <td>0.244431</td>\n",
       "      <td>-0.054379</td>\n",
       "      <td>-0.016737</td>\n",
       "      <td>-0.254082</td>\n",
       "      <td>0.254613</td>\n",
       "      <td>-0.132235</td>\n",
       "      <td>-0.473956</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>-0.075342</td>\n",
       "      <td>0.192524</td>\n",
       "      <td>-0.097784</td>\n",
       "      <td>-0.149718</td>\n",
       "      <td>-0.100732</td>\n",
       "      <td>0.233271</td>\n",
       "      <td>-0.234603</td>\n",
       "      <td>0.288299</td>\n",
       "      <td>-0.368860</td>\n",
       "      <td>0.305713</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.268126</td>\n",
       "      <td>0.007388</td>\n",
       "      <td>0.092949</td>\n",
       "      <td>0.402296</td>\n",
       "      <td>-0.275853</td>\n",
       "      <td>-0.165124</td>\n",
       "      <td>0.029340</td>\n",
       "      <td>-0.352777</td>\n",
       "      <td>-0.062263</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>-0.031172</td>\n",
       "      <td>-0.030906</td>\n",
       "      <td>0.003027</td>\n",
       "      <td>0.191457</td>\n",
       "      <td>-0.305025</td>\n",
       "      <td>0.091230</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.286633</td>\n",
       "      <td>-0.188700</td>\n",
       "      <td>0.474923</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.220066</td>\n",
       "      <td>-0.110807</td>\n",
       "      <td>-0.044319</td>\n",
       "      <td>-0.249069</td>\n",
       "      <td>-0.109083</td>\n",
       "      <td>-0.223180</td>\n",
       "      <td>-0.004370</td>\n",
       "      <td>-0.112664</td>\n",
       "      <td>-0.265395</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2628 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0    -0.111270  0.008626 -0.112308 -0.022436  0.084521  0.016578 -0.158669   \n",
       "1    -0.111270  0.008626 -0.112308 -0.022436  0.084521  0.016578 -0.158669   \n",
       "2    -0.111270  0.008626 -0.112308 -0.022436  0.084521  0.016578 -0.158669   \n",
       "3    -0.111270  0.008626 -0.112308 -0.022436  0.084521  0.016578 -0.158669   \n",
       "4    -0.111270  0.008626 -0.112308 -0.022436  0.084521  0.016578 -0.158669   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2623 -0.346970  0.252749  0.043169  0.038911 -0.546259  0.029881 -0.065755   \n",
       "2624 -0.366686 -0.029260  0.026956  0.075629 -0.184772 -0.112145 -0.129582   \n",
       "2625 -0.358104  0.306154  0.303741 -0.078911 -0.223747 -0.293677 -0.188593   \n",
       "2626 -0.075342  0.192524 -0.097784 -0.149718 -0.100732  0.233271 -0.234603   \n",
       "2627 -0.031172 -0.030906  0.003027  0.191457 -0.305025  0.091230  0.001307   \n",
       "\n",
       "           7         8         9    ...       91        92        93   \\\n",
       "0    -0.079974  0.223279  0.033481  ...  0.283005  0.085423 -0.062640   \n",
       "1    -0.079974  0.223279  0.033481  ... -0.018210 -0.094529 -0.008272   \n",
       "2    -0.079974  0.223279  0.033481  ...  0.042791 -0.079722  0.102271   \n",
       "3    -0.079974  0.223279  0.033481  ... -0.120547  0.099485 -0.063370   \n",
       "4    -0.079974  0.223279  0.033481  ... -0.080258 -0.229467  0.045752   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2623  0.435748 -0.454515  0.079702  ... -0.581142 -0.323180  0.058032   \n",
       "2624  0.202685 -0.137362  0.136930  ... -0.192703 -0.278295  0.225270   \n",
       "2625  0.754108 -0.529041  0.165997  ... -0.438769 -0.420876  0.244431   \n",
       "2626  0.288299 -0.368860  0.305713  ... -0.268126  0.007388  0.092949   \n",
       "2627  0.286633 -0.188700  0.474923  ... -0.220066 -0.110807 -0.044319   \n",
       "\n",
       "           94        95        96        97        98        99   100  \n",
       "0     0.161380 -0.122537  0.115114 -0.053795 -0.214284  0.233027  0.0  \n",
       "1    -0.045378 -0.252298  0.047064 -0.177535  0.144204  0.012367  0.0  \n",
       "2     0.001523 -0.077309 -0.041517 -0.067451  0.027401 -0.037864  0.0  \n",
       "3     0.007632  0.123424  0.068034 -0.028188 -0.256661  0.122674  0.0  \n",
       "4    -0.064296  0.134913  0.000163  0.054669 -0.196582 -0.041674  0.0  \n",
       "...        ...       ...       ...       ...       ...       ...  ...  \n",
       "2623  0.143102  0.117994 -0.191738  0.060826 -0.030575 -0.436335  1.0  \n",
       "2624 -0.002098  0.019151 -0.165369  0.046116 -0.168530 -0.170307  1.0  \n",
       "2625 -0.054379 -0.016737 -0.254082  0.254613 -0.132235 -0.473956  1.0  \n",
       "2626  0.402296 -0.275853 -0.165124  0.029340 -0.352777 -0.062263  1.0  \n",
       "2627 -0.249069 -0.109083 -0.223180 -0.004370 -0.112664 -0.265395  1.0  \n",
       "\n",
       "[2628 rows x 101 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='enhanced_final_new_par_50_space_1.csv'\n",
    "file_path = os.path.join(base_dir,'data','split',ltype, file_name)\n",
    "output_path = file_path\n",
    "enhanced_df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
